% --- Inicjalizacja dokumentu --------------------------------------------------

\documentclass[12pt,a4paper,titlepage,twoside]{mwart}
\usepackage{latexsym}
\usepackage{polski}
%\usepackage{array}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{a4wide}
\usepackage{fancyhdr}
\usepackage{tabularx}
%\usepackage{enumitem}
\usepackage[iso]{isodateo}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{graphicx}
\pagestyle{fancy}
\lstset{language=[ANSI]C,frame=single,captionpos=b,xleftmargin=20mm,xrightmargin=20mm,tabsize=4}

\pdfcompresslevel9

% --- Zdefiniowanie autora i tytułu --------------------------------------------
\author{Krystian Bacławski}
\title{Wielowątkowy zarządca pamięci dzielonej}
\date{Październik 2007}

\frenchspacing

\begin{document}

\maketitle
\cleardoublepage

% --- Abstrakt -----------------------------------------------------------------

\begin{abstract}
\vspace{2ex}
\begin{center}
\begin{tabularx}{0.75\textwidth}{X}
Najefektywniejszą metodą komunikacji między dwoma niezależnymi ścieżkami
wykonania instrukcji jest wykorzystanie pamięci współdzielonej (ang.
\textit{shared memory}). Procesy są to ścieżki wykonania kodu, które posiadają
niezależne przestrzenie adresowe, a~utworzenie przestrzeni dzielonej między
nimi wymaga odpowiednich mechanizmów systemu operacyjnego. Taki rodzaj pamięci
nie podlega zarządzaniu w ramach menadżera pamięci standardowej biblioteki
języka C. Jednak forma komunikacji między dwoma procesami może angażować
wykorzystanie dynamicznej struktury danych korzystającej z procedur
analogicznych do \texttt{malloc} i \texttt{free}. Istnieje tylko jedna
publicznie dostępna biblioteka o otwartych źródłach realizująca to zadanie --
\texttt{libmm}. Niestety allokator tam użyty cechuje niska wydajność operacji i
duża fragmentacja. Celem tej pracy jest implementacja wydajnego mechanizmu
zarządzania przestrzenią udostępnianą w ramach pamięci dzielonej. 
\end{tabularx}
\end{center}
\end{abstract}

\cleardoublepage

% --- Spis treści --------------------------------------------------------------

\tableofcontents
\cleardoublepage

% ------------------------------------------------------------------------------

\setlength{\parindent}{0pt}
\setlength{\parskip}{1.2ex plus 0.5ex minus 0.2ex}

\section{Wstęp}

Algorytmy zarządzania stertą towarzyszą informatyce od samych jej początków.
Menadżerów pamięci zaczęto używać, kiedy pojawiły się pierwsze dynamiczne
struktury danych, takie jak listy i drzewa, a sama pamięć była na tyle duża by
zmieścić w niej większe zadania.

Ponieważ istnieje wiele wariantów problemu zarządzania pamięcią, należy
zawięzić co jest rozumiane przez ten termin. W tej pracy tematem rozważań
będzie niskopoziomowy menadżer pamięci bez odśmiecania -- taki jaki znamy z
biblioteki standardowej języka C. Udostępnia on co najmniej dwie operacje:
\texttt{malloc} i \texttt{free}. Raz przydzielony blok pamięci nie może się
przemieszczać, ani być w jakikolwiek inny sposób modyfikowany przez algorytm
zarządcy. Zagadnienie te zostanie dokładniej opisane w dziale
\hyperlink{Teoria}{\textbf{Teoretyczne podstawy}}. Zostaną tam również
wytłumaczone pewne terminy, które wydają się być niejasne i często, być może bez
świadomości czytelnika, są używane zamiennie.

Problem allokacji pamięci jest od strony teoretycznej bardzo dobrze zbadany.
Większość badań została przeprowadzona na przełomie lat 60-tych i 70-tych
ubiegłego wieku. Skupiały się one głównie na analizie nieużytków powstałych w
wyniku przeprowadzenia ciągu operacji na zarządzanym obszarze. Określiły górną
granicę na fragmentację pamięci. Przeprowadzone wtedy badania odzwierciedlały
główne problemy z jakimi borykano się wtedy w zadaniach obliczeniowych. Pamięć
była bardzo kosztownym zasobem i było jej stosunkowo mało, więc poświęcano
wydajność operacji przydzielania i zwalniania bloku na rzecz ogólnej ilości
składowanych danych.

Mimo, że minęło około 50 lat od pojawienia się pierwszych algorytmów
zarządzania stertą, dziedzina ta nadal nie jest wyczerpująco poznana od strony
praktycznej. Przyczyną tego jest nieustanna ewolucja sprzętu i zmiana realiów,
jeśli chodzi o koszt zasobów.

W ciągu ostatnich dwudziestu lat upowszechnił się w procesorach mechanizm
stronicowania, pamięć podręczna i wielopotokowość. Od pięciu lat następuje
dynamiczny rozwój procesorów wielordzeniowych. Za tymi zmianami próbują nadążyć
systemy operacyjne udostępniając programom efektywne, lecz stosunkowo
niskopoziomowe interfejsy --~w~ramach których nie mieszczą się niestety
menadżery pamięci przestrzeni użytkownika.

Ponieważ operacje zarządcy sterty są bardzo często wykorzystywane, to
efektywność aplikacji pośrednio zależy od ich wydajności. Zależności te są o
wiele bardziej złożone niż się wydaje. Miejsce przydziału bloku, sposób
wykorzystania pamięci dostarczanej przez system operacyjny, przystosowanie do
wielowątkowości i inne aspekty, mogą mieć wpływ nie tylko na wydajność operacji
\texttt{malloc} i \texttt{free}. Umiejętna implementacja korzystająca ze
specyfiki architektury ma również wpływ na prędkość algorytmów korzystających z
allokatora. Innymi słowy -- nie sposób zbudować wydajny algorytm zarządzania
pamięcią nie znając dobrze specyfiki architektury sprzętowej i zachowań systemu
operacyjnego. Zagadnienia z tym związane poruszono w rozdziale
\hyperlink{Architektura}{\textbf{Podstawy architektury pamięci}}.

System \texttt{Linux} posiada stosunkowo dobre algorytmy zarządzania stertą,
zarówno te działające w przestrzeni użytkownika (biblioteka \texttt{GNU libc} i
\texttt{glib2}) jak i w przestrzeni jądra (\texttt{slab allocator}). Niestety
nie są to ani algorytmy uniwersalne, ani łatwo modyfikowalne na potrzeby
programisty. Dobry algorytm zarządzania pamięcią musi charakteryzować się niską
fragmentacją, krótkim zamortyzowanym czasem przypadającym na jedną operację i
wykorzystaniem zjawiska lokalności. Znajomość budowy dobrze znanych algorytmów
wydaje się być niezbędna do tego, by przeanalizować rozwój allokatorów i tym
samym rzucić światło na podstawy nowo konstruowanego menadżera. Kilka
podstawowych strategi przydziału bloków zostało zaprezentowanych w rozdziale
\hyperlink{Klasyka}{\textbf{Klasyczne menadżery pamięci}}.

Większość analiz teoretycznych przeprowadzonych na menadżerach pamięci
określała zachowania algorytmów dla losowych ciągów danych. Dane w znaczeniu
tej klasy problemów to wielkość bloku i długość czasu jego życia -- czyli ilość
operacji od momentu zarezerwowania bloku do jego zwolnienia. O ile testy
zachowania menadżera pamięci na losowych danych mają sens, to w praktyce mają
niewielkie znaczenie. Testy takie mogą pomóc wychwytywać pewnego rodzaju
anomalie, czy po prostu błędy, dla ciągów danych, które w praktyce zdarzają się
bardzo rzadko.

Okazuje się, że programy korzystają z menadżera pamięci w pewien określony
sposób, zdradzając przy tym ściśle określone wzorce. Allokatory można testować
jako samodzielne programy i jako elementy innych programów. Często do testów
wybiera się pewien zbiór aplikacji i obserwuje czas działania w zależności od
algorymu allokatora.

Systemy uniksowe dzięki mechanizmowi przesłaniania symboli bibliotecznych
umożliwiają zmuszanie programów do korzystania z menadżera pamięci spoza
biblioteki standardowej. Dzięki temu można generować tzw. ślady wykonania
programu i analizować w jaki sposób korzystał z wywołań \texttt{malloc} i
\texttt{free}. Posiadając ślady można próbować generować testy składające się
na pseudolosowe ciągi operacji z uwzględnieniem zachowań pewnej przebadanej
liczby programów. Można także optymalizować allokator bezpośrednio pod daną
aplikację. Ciekawą i mało zbadaną dziedziną badań jest generowanie i analiza
śladów dla aplikacji wielowątkowych.

O testowaniu, technikach generowania śladów, doborze miarodajnych aplikacji do
testów traktuje rozdział \hyperlink{Testowanie}{\textbf{Metody testowania
wydajności}}.

Pamięć dzielona jest to spójny obszar pamięci umiejscowiony w przestrzeni
adresowej kilku ścieżek wykonania instrukcji nazywanych procesami lub wątkami.
Istotne jest zrozumienie różnic między tymi dwoma klasami obiektów.

Wątki działają wewnątrz jednego procesu. Dzielą między siebie przestrzeń
adresową procesu w ramach którego powstały. Wątki angażują zdecydowanie mniej
zasobów niż procesy. Ich wadą jest to, że potencjalnie są bardzo niebezpieczne.
Potencjalny błąd w jednym wątku może zniszczyć dane innych wątków. Czasem, ze
wzgędów bezpieczeństwa i poufności danych, nie można dzielić całej przestrzeni
adresowej.

Procesy, w odróżnieniu od wątków, posiadają własne niezależne przestrzenie
adresowe. Separują własne zasoby od innych procesów. Zarządzaniem dostępu do
pewnych zasobów zlecają systemowi operacyjnemu -- zapewniając duży stopień
poufności danych. Czasem jednak muszą się ze sobą komunikować. Wydaje się, że
najwydajnieszym sposobem na szybką wymianę danych między procesami jest
dzielenie pewnego obszaru pamięci. Stworzenie pamięci dzielonej między
procesami wymaga specjalnych mechanizmów systemu operacyjnego.

Autor pracy w trakcie swojej kariery programistycznej natknął się na problem
efektywnego współdzielenia prostej struktury danych (tablicy haszującej) między
procesami serwera \textit{Apache} w systemie \texttt{Linux}.  Należy się tu
krótkie wyjaśnienie jak przebiega procedura obsługi połączenia \verb+HTTP+ w
tym serwerze. Za odbieranie połączeń odpowiada główny proces działający z
prawami administratora. Celem zwiększenia bezpieczeństwa i odporności na błędy
główny proces wykonuje swoją kopię przy pomocy procedury \verb+fork+, a
następnie deleguje obsługę pewnej ilości połączeń do dziecka.  Proces potomny
startuje z uprawnieniami administratora i szybko je porzuca, gdyż obsługa
połączenia może być potencjalnie niebezpieczna. Dziecko obsługuje połączenia,
które zostały mu przydzielone, a następnie kończy swoje działanie.  Taka
architektura separacji zadań dobrze sprawdza się w praktyce, czyniąc
\textit{Apache} jednym z bezpieczniejszych serwerów \texttt{HTTP}.

Zadanie programistyczne polegało na zaimplementowaniu modułu serwera
\textit{Apache} zabraniającego dostępu użytkownikom (określonym adresom
\texttt{IP}) do stron internetowych na podstawie pewnych kryteriów. Każde
obsłużenie połączenia musiało zmieniać parametry używane jako kryterium
akceptacji żądań klientów. W trakcie testów mających określić miejsce
przechowywania danych o połączeniach wybrano pamięć dzieloną, ze względu na
najmniejszy narzut obliczeń wymaganych do obsługi żądania. Główny proces
serwera rezerwował pewien obszar pamięci współdzielonej, która była
przekazywana w niezmienionej postaci do procesów potomnych -- co gwarantuje
procedura \verb+fork+. Dzięki temu wszystkie procesy potomne mogły się ze soba
w efektywny sposób komunikować.

Nowoczesny algorytm zarządzania pamięcią jest tworem hybrydowym i z reguły
posiada pięć rozróżnialnych podsystemów. Zarządzanie stronami to najbardziej
niskopoziomowy element całego menadżera. Odpowiada za pobieranie, zwalnianie i
buforowanie stron pamięci. Istnieją trzy pomniejsze algorytmy zarządzania
blokami o odpowiednich rozmiarach -- podział ten jest stosowany ze względu na
odmienne preferencje programów co do określonych rozmiarów allokacji. Ostatnim
elementem jest właściwy menadżer pamięci, który używa wyżej wymienionych
elementów i realizuje pewną strategię zarządzania blokami i obszarami pamięci.

W rozdziale \hyperlink{Implementacja}{\textbf{Implementacja}} autor przedstawił
założenia, które poczynił implementując własny menadżer pamięci. Został tam
zaprezentowany standardowegy zarządca sterty dla systemu operacyjnego
\texttt{Linux}, który był podstawą określającą interfejs programisty i
zachowanie poszczególnych operacji. Opisane zostały poszczególne składowe
algorytmu, ogólna strategia zarządzania oraz ewentualne modyfikacje i
rozszerzenia mające na celu zwiększenie wydajności.

W rozdziale \hyperlink{Podsumowanie}{\textbf{Podsumowanie i kierunek dalszych
badań}} zostały przedstawione potencjalne zastosowania wielowątkowego menadżera
pamięci poza wspomnianym przypadkiem modułu dla serwera \textit{Apache}. Autor
przedstawił też możliwą ścieżkę ewolucji dla poczynionych badań i
implementacji.

\newpage

% --=[ Wstęp teoretyczny ]=-----------------------------------------------------

\section{Teoretyczne podstawy}
\hypertarget{Teoria}{}

Menadżery pamięci są algorytmami tak powszechnymi, że niemal nie zauważa się ich
istnienia. Programiści traktują wywołania funkcji realizujących przydzielanie i
zwalnianie obszarów za czarne skrzynki -- nie wiedząc, że wewnątrz tkwią często
zaawansowane algorytmy. Z reguły są one dość dobrze przetestowane i sprawują
się dobrze w większości przypadków. Niestety bywają sytuacje kiedy działają
skrajenie nieefektywnie.  Słowo \textit{efektywnie} w kontekście allokatorów
pamięci może być rozumiane na kilka sposóbów.

Algorytm może być \textit{efektywny} pamięciowo, co znaczy że:
\begin{itemize}
\item zużywa niewiele pamięci na własne wewnętrzne pomocnicze struktury danych,
\item charakteryzuje się niewielką fragmentacją wewnętrzą i zewnętrzną.
\end{itemize}
Tematyka efektywności wykorzystania pamięci została szczegółowo omówiona w
przekrojowej pracy na temat allokatorów pamięci \cite{paul95dynamic}.

Allokator może być \textit{efektywny} wydajnościowo, co znaczy że:
\begin{itemize}
\item program z niego korzystający spędza mało czasu rezerwując i zwalniając
pamięć,
\item rzadko korzysta z wywołań systemowych celem pobrania lub zwolnienia stron
pamięci,
\item w przypadku programów wielowątkowych wątki rzadko się nawzajem blokują
wykorzystując zarządcę pamięci -- allokator charakteryzuje się niską
rywalizacją o blokady (ang. \textit{lock contention}) niezbędne do utrzymania
spójności wewnętrznych struktur.
\end{itemize}

Celem tego rodziału jest przedstawienie podstawowych koncepcji związanych z
algorytmami zarządzania pamięcią niezbędne do zrozumienia treści kolejnych
rozdziałów. 

\subsection{Intuicyjna definicja problemu}

Algorytm zarządzania pamięcią to algorytm \textit{on-line}. Oznacza to, że dane
wejściowe traktuje on jak żądania, które należy obsłużyć natychmiastowo. Nie
może odwlekać ich obsłużenia -- w szczególności zacząć obsługiwać następne
żądanie przed spełnieniem bieżącego. Algorytmy \textit{on-line} charakteryzują
się również tym, że nie znają one przyszłości -- w sensie nie znają danych
jakie będą przetwarzać w następnym kroku. Optymalizacja takich algorytmów może
bazować tylko i wyłącznie na wiedzy, którą zdołały posiąść -- czyli na
podstawie żądań, które obsłużyły.

Menadżer pamięci to algorytm, który zarządza zasobem jakim jest pewien obszar
pamięci. W szczególności -- obszar ten może być niespójny. Poszczególne części
takiej przestrzeni pamięci mogą mieć różne właściwości wynikające z
architektury sprzętowej. Zarządzany obszar może się dynamicznie zmieniać swój
rozmiar czy strukturę dostosowując się do wymagań pamięciowych aplikacji
korzystającej z allokatora. Menadżer sterty odpowiada za wykorzystanie całej
pamięci, którą posiada w przydzielonym mu obszarze.

Program korzystający z allokatora pobiera i zwalnia obiekty zwane
\textit{blokami pamięci}. Do obowiązków menadżera należy utrzymywanie listy
bloków i pamiętanie, które są zajęte, a które wolne. Algorytm wyznacza
położenie danego bloku tylko raz -- tj. nie może go przemieszczać, ani zmieniać
danych w nim zawartych, jeśli blok został już przydzielony.

Blok jest spójnym obszarem pamięci o następujących właściwościach:

\begin{tabularx}{\textwidth}{@{\hspace{4ex}}lX@{}}
	\texttt{położenie}	& adres pamięci, w którym się zaczyna \\
	\texttt{wielkość}	& ilość zajmowanej przestrzeni mierzona w bajtach \\
	\texttt{narodziny}	& kwant czasu, w którym zarządca oddaje blok na użytek programu \\
	\texttt{śmierć}		& kwant czasu, w którym program oddaje blok na użytek zarządcy \\
	\texttt{właściciel}	& proces lub wątek, któremu ten blok został przypisany \\
\end{tabularx}

Zarządca odpowiada na co najmniej dwa typy żądań programu:

\begin{tabularx}{\textwidth}{@{\hspace{4ex}}lX@{}}
	\texttt{malloc} & które zwraca adres bloku pamięci o żądanym
	rozmiarze lub informuje, że żądanie nie mogło zostać spełnione. \\

	\texttt{free} & które oddaje obszar zajmowany przez blok pamięci o
	podanym adresie do ponownego użycia przez algorytm zarządcy. \\
\end{tabularx}

Taka definicja odpowiada temu co znane jest dla większości programistów
używających języków imperatywnych takich jak \verb#C#, \verb#C++# czy
\verb#Pascal#.

\subsection{Fragmentacja}

Fragmentacja jest zjawiskiem wynikającym z nieefektywnego zarządzania pamięcią.
Jest miarą ilości przestrzeni, której nie można wykorzystać do obsłużenia żądań
programu. Innymi słowy jest to pamięć, która jest wolna, ale z jakiś powodów
nie może być oddana na użytek programu.

Fragmentacja wewnętrzna jest mniej groźna, lecz trudniejsza w minimalizacji. W
większości przypadków jest ona wynikiem poczynienia pewnych założeń w działaniu
allokatora. Rezerwowane bloki pamięci są z reguły większe, niżby wynikało to z
wartości przekazywanej do funkcji \texttt{malloc}. Procesory działają
wydajniej, a czasami wręcz wymagają\footnote{Procesory \texttt{PowerPC} przy
próbie odczytu słów danych o parzystej długości spod nieparzystych adresów
zgłaszają przerwanie sprzętowe.}, by słowa danych były odczytywane z adresów
podzielnych przez ich długość. Większość menadżerów pamięci za jednostkę
allokacji przyjmuje $8$ bajtów, co odpowiada rozmiarowi najdłuższej danej
całkowitej oznaczanej w języku \verb+C+ jako \verb+long long int+. W związku z
tym każdy blok ma adres początku podzielny przez $8$, co implikuje również 
podzielność rozmiaru bloku przez~$8$.

Wydaje się, że fragmentacja wewnętrzna jest nie do uniknięcia. Algorytm
zarządzania pamięcią nie wie nic na temat struktur, które będzie przechowywał w
blokach. Nie może zatem wiedzieć nic na temat tego przez jaką liczbę ma być
podzielny adres bloku. Na szczęście fragmentacja wewnętrzna nie jest dużym
problemem, gdyż dotyczy niewielkich objętościowo fragmentów pamięci.

Znacznie poważniejszym problemem jest fragmentacja zewnętrzna. Powstaje ona na
skutek wykonania pewnego ciągu operacji, które skutkują powstaniem wolnych
bloków o rozmiarach nie pozwalających na ich użycie przy obsłudze kolejnych
żądań.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{frag-zew}
\caption{Powstawanie fragmentacji zewnętrznej.}
\end{figure}

Na przedstawionym wyżej rysunku ostatnia operacja zakończyła się niepowodzeniem
mimo, że łączna ilość wolnej pamięci wynosi $64$. Rezerwując obszar o wielkości
$8$ allokator nie wiedział nic na temat przyszłych operacji. Nie mógł zatem
przewidzieć, że lepiej będzie umiejscowić ten blok w adresie \verb+@64+.
Niestety nie istnieje algorytm zapobiegający takim sytuacjom. Okazuje się, że
dla każdego algorytmu zarządzania pamięcią istnieje taki ciąg operacji
\texttt{malloc} i \texttt{free} by fragmentacja pochłoneła stosunkowo duże
obszary pamięci czyniąc z nich nieużytki. Na szczęście w praktyce fragmentacja
zewnętrzna nie osiąga tak niepokojących rozmiarów -- głównie dzięki temu, że
zachowania programów są dość regularne i często powtarzalne, co uwzględnia się
przy budowie algorytmów.

Na początku lat 70 przeprowadzono szereg badań mających na celu określić jaka
ilość pamięci jest potrzebna na wykonanie dowolnego ciągu operacji
\texttt{malloc} i \texttt{free}. W~pracy \cite{robson74bounds} (będącej
kontynuacją \cite{robson71estimate}) Robson pokazał, że górna granica ilości
użytej pamięci na wykonanie dowolnego ciągu operacji przydziału oraz zwolnienia
bloku dla strategii \textit{First-Fit}\footnote{Z listy wolnych bloków
wybierany jest pierwszy satysfakcjonujący żądanie.} wynosi $O(M \cdot
\log_{2}(n))$, gdzie $n$~to długość największego bloku, a $M$~to maksymalna
ilość zajętych bloków. W kolejnej swojej pracy \cite{robson77worst} Robson
pokazał górne ograniczenie na ilość zużytej pamięci przez strategię
\textit{Best-Fit}\footnote{Z listy wolnych bloków wybierany jest najmniejszy
możliwy blok satysfakcjonujący żądanie.}, która okazuję się być znacznie
większa niż w przypadku \textit{First-Fit} i wynosi $O(M \cdot n)$. Analiza
oszacowania górnej granicy ilości zużytej pamięci dla metody \textit{First-Fit}
działającej w środowisku wielowątkowym ukazała się pracy \cite{luby94tight} i
jest taka sama jak dla przypadku jednowątkowego.

\subsection{Wersje problemu zarządzania pamięcią}

Z problemem zarządzania pamięcią analogicznym to zdefinowanego w poprzednim
paragrafie można się spotkać na wielu szczeblach działania systemu
operacyjnego. W jądrze Linuksa są co najmniej dwa menadżery pamięci o rożnych
zastosowaniach i właściwościach. Istnieje cała gama allokatorów działających w
przestrzeni użytkownika.

\paragraph{Standardowa biblioteka POSIX.}

Najbardziej znany programistom interfejs zarządcy pamięci wywodzi się z języka
\verb+C+. Jest to allokator ogólnego przeznaczenia dla procesów i wątków
działających w przestrzeni użytkownika. Posiada pewien z góry ustalony
interfejs, który został dokładnie omówiony w rozdziale \ref{PosixMalloc}.
Ponieważ jest to najczęściej wykorzystywany allokator istnieje wiele projektów
mających na celu zwiększenie wydajności tego mechanizmu.

W~chwili obecnej standardowa biblioteka \verb+C+ dla systemu Linux korzysta z
allokatora \textit{Doug Lea's Malloc} (w skrócie \textit{dlmalloc}) opisanego w
pracy \cite{douglea96malloc}. W trakcie swojego instnienia allokator ten
przeszedł szereg modyfikacji: zwiększenie lokalności odwołań do pamięci,
usprawnienie heurystyk przygotowujących bloki na potrzeby przyszłych wywołań,
odroczone scalanie bloków, intesywne sprawdzanie spójności zarządzanej pamięci
celem znajdywania błędów popełnionych przez programistę i ograniczone wspracie
dla wielowątkowości (znane jako \textit{ptmalloc}).

Lukę w wydajnych allokatorach dla programów wielowątkowych wypełnił
\textit{Hoard} opisany w pracy \cite{berger00hoard}. Opisano tam efektywny
sposób na zmniejszenie konkurencji między wątkami, poprzez przypisanie im
prywatnych obszarów pamięci. Zwrócono tam uwagę na zjawisko fałszywego
współdzielenia pamięci przez różne procesory i podano sposób na poradzenie
sobie z tym problemem. Allokator o podobnych właściwościach do \textit{Hoard}
został zaimplementowany na potrzeby projektu systemu operacyjnego
\textit{FreeBSD} -- \textit{jemalloc} został opisany w pracy
\cite{evans06scalable}.

Ideę prywatnych stert z allokatora \textit{Hoard} wozwinięto w
\textit{tcmalloc} wykonanym przez pracowników firmy Google opisanym w pracy
\cite{ghemawat07tcmalloc}. Zamiast semaforów, korzystających z systemu
operacyjnego, zastosowano tam blokady pętlowe (ang.  \textit{spin locks}).
Zaprezenowano tam efektywniejszą organizację wolnych obszarów pamięci
minimalizującą ilość odwołań do systemu operacyjnego.  Obecnie
\textit{tcmalloc} wydaje się być najwydajniejszym publicznie dostępnym
allokatorem pamięci ogólnego przeznaczenia.

\paragraph{Zarządzenie stronami pamięci.}

Większość ówczesnych komputerów ma pewne mechanizmy zarządzania pamięcią
zaimplementowane sprzętowo. Tworzono je z myślą o systemach operacyjnych i
zwiększeniu wydajności programów. Jądro nadbudowuje nad tymi mechanizmami
warstwę abstrakcji uwalniając zwykłego programistę od pewnych ograniczeń, ale
również pułapek wydajnościowych.

Jądro systemu uniksowego nie udostępnia procesom przestrzeni użytkownika
mechanizmu zarządzania pamięcią dla bloków różnej długości. Dostarcza zamiast
tego nieco bardziej niskopoziomy interfejs pobierania lub zwalaniania pewnej
ilości całych stron pamięci (najczęściej są to 4\verb+KiB+ bloki). Z punktu
widzenia procesora taki blok to najmniejsza jednostka pamięci, której
właściwości jest w stanie kontrolować. Jądro systemu zarządza pamięcią fizyczną
tworząc wirtualną przestrzeń adresową na potrzeby procesu -- do tego celu
najczęściej używa się zmodyfikowanych systemów partnerskich (ang. \textit{buddy
systems}). Szczegółowy opis zarządzania pamięcią fizyczną w systemie
\textit{Linux} został zawarty w publicznie dostępnej książce
\cite{gorman04linuxvm}.

\paragraph{Zarządzenie obiektami w jądrze.}

Jądro systemu wykorzystuje na swoje potrzeby pewne struktury danych o ustalonej
wielkości rekordów. Wydzielenie funkcjonalności, jaką jest rezerwacja bloków
ustalonej długości, z ogólnego allokatora pamięci daje możliwość wielu
optymalizacji. Znając dobrze architekturę sprzętową można zadbać wtedy o
zwiększenie szybkości dostępu do poszczególnych bloków pamięci.

W pracy \cite{bonwick94slab} skupiono się na efektywnym wykorzystaniu pamięci
podręcznej do konstrukcji rekordów. Opis bazuje na wewnętrznym menadżerze
pamięci systemu operacyjnego \textit{SunOS 5.4}, będącego przodkiem systemu
\textit{Solaris}. W pracy tej przedstawiono zastosowanie kolorowania stron
pamięci do równomiernego obciążenia szyny pamięci. Zaprezentowano strukturę
danych \textit{slab} służącą do przechowywania obiektów ustalonej długości.
Allokator o podobnej strukturze został zaimplementowany w systemie
\textit{Linux} i zaprezentowany w pracy \cite{fitzgibbons00linux}.

\newpage

% --=[ Podstawy architektury pamięci ]=-----------------------------------------

\section{Podstawy architektury pamięci}
\hypertarget{Architektura}{}

Przed przystąpieniem do realizacji jakiegokolwiek algorytmu zarządzania stertą
należy dokładnie przeanalizować strukturę pamięci. Struktura pamięci to pojęcie
bardzo ogólne określające kilka aspektów -- począwszy od sprzętowych po
wywołania systemowe umożliwiające pobieranie oraz zwalnianie obiektów. Dopiero
mając na uwadze wszystkie zagadnienia związane z organizacją pamięci można
planować efektywny pod względem szybkości jak i zajmowanego miejsca menadżer
pamięci.

W tym rozdziale zostaną omówione podstawy i pojęcia związane z:
\begin{itemize}
\item organizacją sprzętową pamięci dla architektury sprzętowej Intel IA-32,
\item przestrzeni adresowej programu i jej obłożenia w systemie Linux,
\item interfejsem rezerwacji i zwalnianiem stron w systemach uniksowych,
\item zagadnieniami wydajności pamięci w systemach jedno- i wieloprocesorowych,
\item metodami synchronizacji dla programów wielowątkowych.
\end{itemize}

Część z tych zagadnien w przystępny sposób opisuje praca \cite{pas02memory}
skierowana do programistów kodujących aplikacje korzystające w intensywny
sposób z pamięci RAM.

\subsection{Stronicowanie}

Pamięć fizyczna jest to rodzaj pamięci widziany bezpośrednio przez procesor.
Podstawową jednostką zarządzania tym rodzajem pamięci jest strona, będąca
obszarem o następujących własnościach:

\begin{itemize}
\item pewnej z góry ustalonej wielkości (w przypadku procesorów Intel
IA-32 jest to 4KiB lub 4MiB),
\item adres jej początku jest podzielny przez długość strony,
\item posiada zestaw uprawnień (do odczytu, do zapisu, itd.)
\end{itemize}

Nad pamięcią fizyczną system operacyjny, korzystając z jednostki zarządzania
pamięcią procesora, buduje warstwę zwaną pamięcią logiczną. Zadanie to jest
realizowane przez mechanizm translacji adresów -- często określany także
mechanizmem stronicowania. Do translacji adresów procesor wykorzystuje opis
pamięci logicznej składający się na wielopoziomowe tablice deskryptorów stron.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{stronicowanie}
\caption{Schemat translacji adresu dla architektury Intel IA-32}
\end{figure}

Procesor posiada rejestr PDBR, w którym składuje wskaźnik o adresie wyrównanym
do granicy 4096 bajtów, do katalogu stron. Każda pozycja w katalogu stron to 32
bitowe słowo. Zawiera ono 20 starszych bitów określających fizyczny adres
początku tablicy stron i 12 młodszych bitów na dodatkowe dane. Analogicznie
jest z deskryptorem strony, przy starsze 20 bitów podaje fizyczny adres
początku strony.

Kiedy program odwołuje się do pamięci logicznej procesor wykonuje następujące kroki:
\begin{enumerate}
\item rozbija adres na 3 części: 10-bitowy indeks w katalogu stron (PDE), 10-bitowy
indeks w tablicy stron (PTE) i 12 bitowy indeks wewnątrz strony (PO),
\item wyszukuje deskryptor katalogu zestawiając górne 20 bitów rejestru PDBR z
indeksem PDE -- wyznaczając adres fizyczny początku katalogu stron,
\item wyszukuje deskryptor strony zestawiając górne 20 bitów wyznaczające
początek tablicy stron z indeksem PTE -- adres fizyczny początku strony,
\item zestawia górne 20 bitów adresu fizycznego strony z indeksem PO i
realizuje operację odczytu lub zapisu danych.
\end{enumerate}

Przy pomocy młodszych 12 bitów w deskryptorze strony realizuje się w systemach
różne mechanizmy. Najbardziej znanymi mechanizmami są:
\begin{itemize}
\item \textit{ochrona pamięci} -- deskryptory stron przechowują bity uprawnień do
czytania, pisania, wykonywania zawartości -- procesor sprawdza te bity w
trakcie translacji adresu i w przypadku błędu dostępu generuje błąd
stronicowania (ang. \textit{Page Fault}),
\item \textit{pamięć wirtualna} -- dodatkowe bity w deskryptorze oznaczają czy
strona znajduje się w pamięci fizycznej -- system operacyjny może dane strony
przemieszczać do pamięci zewnętrznej i na odwrót, obsługując odpowiednio błąd
stronicowania,
\item \textit{mapowanie pamięci} -- mechanizm analogiczny do pamięci wirtualnej
może służyć do mapowania plików na strony, dzięki temu programista może mieć
swobodny dostęp do pliku,
\item \textit{pamięć dzielona} -- system operacyjny umieszcza w pamięci logicznej kilku
procesów te same strony pamięci fizycznej.
\end{itemize}

Zasadniczo dwóch terminów: \textit{pamięć logiczna} i \textit{pamięć wirtualna}
mówiąc o mechaniźmie stronicowania często się nie rozróżnia i będę ich używać
zamiennie.

Nie sposób też pominąć istotną przewagę stronicowania nad innymi metodami
sprzętowego zarządzania pamięcią. Mechanizm ten umożliwia systemowi
operacyjnemu organizowanie rozrzuconych w pamięci fizycznej stron w jeden
spójny obszar w pamięci logicznej.

\subsection{Pamięć podręczna}

W tematyce związanej z architekturami systemów komputerowych często pojawia się
termin \textit{piramidy pamięci}. Porusza on zależność ilości pamięci od jej
wydajności. I tak najszybsze są w podanej kolejności: rejestry procesora,
pamięć cache, pamięć RAM, pamięć zewnętrzna (np.: twarde dyski). Niestety w
wyżej wymienionej kolejności rośnie również ilość danych, które te źródła
pamięci mogą przechowywać.

Pamięć podręczna (ang. \textit{cache}) jest kilkukrotnie szybsza od procesora.
Przechowuje najczęściej używane obszary, zakładając, że program przetwarzając
dane wykazuje pewną lokalność dostępów do poszczególnych komórek.

Pamięć podręczna przechowuje fragmenty pamięci RAM zwane liniami, którym
przyporządkowane są dodatkowe informacje niezbędne do funkcjonowania pewnych
szczególnych operacji dostępu. Kontroler szyny sprowadza i wydala z pamięci
podręcznej całe linie.

Podstawowymi właściwościami pamięci podręcznej są:
\begin{itemize}
\item szybkość -- ile cykli trzeba czekać na sprowadzenie danych jednostki
obliczeniowej procesora,
\item architektura -- bezpośrednio mapowana, wielodrożna, w pełni asocjacyjna,
\item ilość -- im szybsza pamięć podręczna tym jej mniej. 
\end{itemize}

Pamięć cache jest dla programisty do pewnego stopnia przezroczysta. Nie jest to
obszar bezpośrednio dostępny, a raczej bufor dla danych z pamięci RAM. Stosując
odpowiednie instrukcje można wymusić na kontrolerze szyny by sprowadził do
pamięci podręcznej linie o określonych adresach, bądź też wymusił wydalenie do
pamięci pewnych linii. Metody te w języku angielski noszą nazwę
\textit{prefetching} i \textit{cache invalidation}.

Zjawiskiem niepożądanym z punktu widzenia wydajności są sytuacje, kiedy
procesor próbuje korzystać z danych, które nie są w żadnej linii pamięci
podręcznej -- w języku angielskim nazywa się je \textit{cache miss}. W takim
przypadku procesor zamraża wykonywanie instrukcji do momentu kiedy dane będą
dostępne -- może się to wiązać z koniecznością wymiany pewnej linii tzn.
zapisania jej wartości do pamięci RAM, a następnie sprowadzenia w to miejsce
innego obszaru. Pesymistyczny wariant to wiele cykli mocy obliczeniowej
procesora zmarnowanych na oczekiwanie.

Powrócmy na chwilę do stronicowania. Jeśli dobrze się przypatrzeć mechanizmowi
to widać, że jest on kosztowny w sensie ilości operacji na pamięci. Każdy zapis
czy odczyt wymusza na procesorze dodatkowe dwie operacje dostępu do pamięci
celem obliczenia adresu fizycznego. Strony przechowujące katalogi i tablice
deskryptorów mogą być buforowane i z reguły umożliwia się ich składowanie w
pamięci podręcznej. Sytuacja, w której każdy odczyt pamięci przechowującej
deskryptory generuje \textit{cache miss} powoduje jeszcze większy spadek
wydajności. Dlatego jednostka zarządzania pamięcią posiada własną pamięć
podręczną nazywaną \textit{Table Lookaside Buffer}. Przechowuje ona pewną ilość
(z reguły kilkaset) deskryptorów stron umożliwiających natychmiastowe
obliczenie adresu fizycznego. Sytuacja, w której TLB nie przechowuje informacji
o stronie, do której odwołanie jest potrzebne, by dostarczyć dane dla
instrukcji, nazywa się \textit{TLB miss}.

\subsection{Przestrzeń adresowa w Linuksie}

Przestrzeń adresowa procesu to wszystkie komórki pamięci, które można
zaadresować w jednej chwili, ale nie koniecznie mieć do nich dostęp (w takim
przypadku wystąpi przerwanie naruszenia ochrony pamięci). W systemach
32-bitowych proces dysponuje przestrzenią adresową 4GB. Oznacza to nie ilość
pamięci fizycznej jaka maksymalnie może być dostępna dla procesu, a wielkość
danych, do których procesor może mieć dostęp w sposób bezpośredni, adresując
komórki pamięci. To rozróżnienie jest istotne, gdyż mechanizm stronicowania
jest bardzo elastyczny i umożliwia odwzorowanie przestrzeni adresowej na pamięć
zewnętrzną, pliki, pamięć urządzeń wejścia-wyjścia, itd.

\begin{figure}[h]
\centering
\includegraphics[height=0.5\textwidth]{linux-layout}
\caption{Obłożenie przestrzeni adresowej procesu w systemie Linux}
\end{figure}

Najnowsze systemy komputerowe mimo ograniczenia na przestrzeń adresową potrafią
umożliwić procesowi dostęp do większej ilości pamięci fizycznej niż wynosi
wielkość przestrzeni adresowej. Oczywiście mechanizm ten nie jest przezroczysty
dla programisty i wymusza używanie techniki zwanej przesuwającym się oknem
(ang. \textit{sliding window}) lub przełączaniem banków (ang. \textit bank
switching) -- kawałkiem przestrzeni adresowej, w którym widać fragment jakiejś
większej pamięci.

W systemach uniksowych oczywiście nie cała przestrzeń adresowa jest dostępna
dla procesu, jej część zajmuje jądro systemu. W tym fragmencie przestrzeni
jądro udostępnia swoje publiczne struktury, może mapować bufory, dane otrzymane
od urządzeń wejścia-wyjścia, itd.

Na przestrzeń adresową procesu użytkownika w systemie Linux składają się
następujące obszary:

\begin{center}
\begin{tabular}{|ccc|p{0.5\linewidth}|}
\hline
\textsc{początek} & & \textsc{koniec} & \textsc{znaczenie} \\
\hline
\hline
\texttt{0x00000000} & -- & \texttt{0x07ffffff} & Obszar wyłapywania złych wskaźników -- dostęp zawsze zabroniony.\\
\hline
\texttt{0x08000000} & -- & \texttt{0x08xxxxxx} & Tu wczytywana jest sekcja \texttt{text} pliku ELF. Miejsce na kod i zainicjalizowane dane.\\
\hline
\texttt{0x08xxxxxx} & -- & \texttt{?}          & Obszar sterty. Może zmieniać rozmiar przy pomocy procedury brk.\\
\hline
\texttt{?}          & -- & \texttt{0xBFxxxxxx} & Obszar dla wywołania systemowego mmap. Tu będą mapowane pliki i inne obiekty.\\
\hline
\texttt{0xBFxxxxxx} & -- & \texttt{0xBFFFFFFF} & Stos programu.\\
\hline
\texttt{0xC0000000} & -- & \texttt{0xFFFFFFFF} & Przestrzeń na użytek jądra systemu -- do komunikacji z procesem.\\
\hline
\end{tabular}
\end{center}

\subsection{Metody rezerwacji stron w Linuksie}

Jądro linuksa nie udostępnia programom wywołań systemowych pełniących rolę
funkcji \texttt{malloc} i \texttt{free}. Zarządzanie ma o wiele bardziej
niskopoziomową postać. Linux umożliwia wyłącznie pobieranie i zwracanie pewnej
ilości stron poprzez umieszczanie ich w przestrzeni adresowej w obszarach do
tego zarezerwowanych. Menadżer pamięci musi być zatem zaimplementowany przez
pewną bibliotekę wgrywaną przez program w czasie startu.

\subsubsection{Wywołanie systemowe \texttt{brk}}

Pierwszym i historycznie najstarszym wywołaniem jądra do przydzielania pamięci
procesowi jest procedura \texttt{brk} i nakładka \texttt{sbrk}.

\vspace{4ex}

\begin{lstlisting}[caption={Prototypy procedur \texttt{brk} i \texttt{sbrk}.}]
int   brk(void *end_data_segment);
void *sbrk(intptr_t increment);
\end{lstlisting}

Procedura \texttt{brk} zmienia położenie wierzchołka sterty na zadany adres, o
ile ma on sens -- w przypadku sukcesu zwraca $0$, w przeciwnym razie zwraca $-1$.

Procedura \texttt{sbrk} przesuwa położenie wierzchołka sterty o zadaną ilość
bajtów przy czym wielkość ta może być ujemna. Zwraca nowy adres wierzchołka
sterty lub adres o wartości $-1$ w przypadku błędu.

Obie funkcje są dostępne w większości systemów uniksowych. Zostały jednak
usunięte ze standardu POSIX.1 i nie należy ich używać, jeśli kod ma być
przenośny między różnymi platformami. Innymi słowy tą metodę pozyskiwania
pamięci uważa się z przestarzałą i nie zaleca jej używania.

Wywołanie \texttt{brk} ma też oczywistą wadę, powodującą nieefektywne
wykorzystanie pamięci. Przypuścmy, że program wykonuje ciąg operacji:

\begin{enumerate}
\item zarezerwuj obszar $A$ o rozmiarze $n$,
\item zarezerwuj obszar $B$ o rozmiarze $m$ o wiele mniejszym niż $n$,
\item zwolnij obszar $A$,
\item zarezerwuj obszar $C$ o rozmiarze $n + m$.
\end{enumerate}

Widać, że każda rezerwacja obszaru będzie musiała przesunąć wierzchołek sterty.
Strony związane z obszarem $A$ nie mogą być zwrócone do systemu i ponownie
wykorzystanie do utworzenia obszaru $C$. Używanie tego mechanizmu do rezerwacji
dużych bloków jest nieefektywne i może powodować powstawanie nieużytków.

\subsubsection{Wywołanie systemowe \texttt{mmap}}

Historycznie nowszą, a jednocześnie zalecaną, metodą rezerwacji i zwalniania
spójnego obszaru stron pamięci stanowią wywołania \texttt{mmap} i
\texttt{munmap}. Zaletą tej metody pobierania pamięci z systemu operacyjnego
jest możliwość skonstruowania lepszej metody radzenia sobie z nieużytkami.
Zmapowany spójny obszar pamięci może być odmapowany fragmentarycznie. Jeśli
tylko pojawi się wystarczająco długi niewykorzystywany obszar rozpoczynający
się w adresie podzielnym przez rozmiar strony, program może go zwrócić do
systemu. 

Poniżej zostaną przedstawione i wyjaśnione parametry procedur dla przypadku
przydziału i zwalniania pamięci wirtualnej.

\vspace{4ex}
\begin{lstlisting}[caption={Prototypy procedur \texttt{mmap} i \texttt{munmap}.}]
void *mmap(void *start, size_t length, int prot,
           int flags, int fd, off_t offset);
int munmap(void *start, size_t length);
\end{lstlisting}

Argumenty procedury \texttt{mmap} posiadają następujące znaczenie w przypadku
żądania o przydział stron procesowi:
\begin{center}
\begin{tabular}{|l|p{0.75\linewidth}|}
\hline
\textsc{argument} & \textsc{znaczenie} \\
\hline
\hline
\verb+start+  & Adres, pod który powinny być zmapowane nowe strony. Jeśli równy
\texttt{NULL}, jądro samo wybierze odpowiednie miejsce w przestrzeni adresowej.
W przeciwnym wypadku będzie starało się wykorzystać ten argument jako początek
mapowania. Zaleca się ustawienie na \texttt{NULL}.\\
\hline
\verb+length+ & Rozmiar bloku pamięci -- musi być podzielny przez długość strony. \\
\hline
\verb+prot+   & Uprawnienia określające dostęp do stron. Jeśli proces chce
czytać i zapisywać do tego obszaru, argument musi mieć wartość
\verb+PROT_READ|PROT_WRITE+. \\
\hline
\verb+flags+  & Flaga \verb+MAP_ANONYMOUS+ powoduje zmapowanie pamięci
wirtualnej zamiast pliku. Zawartość pamięci będzie wyzerowana. \\
\hline
\verb+fd+     & Uchwyt pliku -- obowiązuje jedynie w przypadku mapowania pliku.
Ustawić na $-1$ dla zgodności z innymi systemami. \\
\hline
\verb+offset+ & Offset względem początku pliku -- jego wartość jest ignorowana. \\
\hline
\end{tabular}
\end{center}

W zależności od wartości \texttt{flags} wywołanie \texttt{mmap} może
przydzielać strony o różnych właściwościach. Objawiają się one w momencie
wywołania procedury systemowej \texttt{fork}, która tworzy potomków procesu.

\begin{center}
\begin{tabular}{|l|p{0.75\linewidth}|}
\hline
\textsc{flaga} & \textsc{znaczenie} \\
\hline
\verb+MAP_PRIVATE+ & Mapowanie prywatne. Proces posiada zmapowane strony na
własność. Wykorzystywany jest mechanizm \texttt{copy-on-write}. Jeśli
którykolwiek z potomków lub rodzic będzie chciał zmodyfikować stronę, to
dostanie jej prywatną kopię na własny użytek. \\
\hline
\verb+MAP_SHARED+  & Mapowanie dzielone. Proces dzieli zmapowany obszar pamięci
między wszystkie procesy potomne stworzone. Wszystkie procesy widzą ten sam
obszar pamięci wirtualnej i mogą się przez ten fragment pamięci komunikować. \\
\hline
\end{tabular}
\end{center}

Poniżej zamieszczono listing prostego programu pobierający stronę pamięci z
systemu operacyjnego na własny użytek.

\vspace{2ex}
\begin{lstlisting}[caption={Przykład pobrania i zwolnienia jednej strony.},xleftmargin=3ex,xrightmargin=3ex]
void *area = mmap(NULL, getpagesize(), PROT_READ|PROT_WRITE,
                  MAP_ANONYMOUS|MAP_PRIVATE, -1, 0);

if (area != NULL)
    munmap(area, getpagesize());
\end{lstlisting}

Ważną przewagą wywołania systemowego \texttt{mmap}, w stosunku do \texttt{brk},
jest to, że korzystanie z tej metody pobierania pamięci nie powoduje konfliktów z
menadżerem pamięci znajdującym się w bibliotece \texttt{libc}. Dzięki temu
można w obrębie jednej przestrzeni adresowej korzystać z wielu niezależnych
algorytmów rezerwacji bloków.

\subsection{Fałszywe współdzielenie}

Mikroprocesor wielordzeniowy nie jest już dziś niczym egzotycznym. Kiedyś były
składnikami wyłącznie maszyn pełniących rolę serwerów bądź stacji roboczych do
obliczeń naukowych. Większość architektur wieloprocesorowych lub
wielordzeniowych zakłada dostęp do pamięci systemowej, która jest dzielona
między procesorami. Procesory wykorzystują część pamięci na własne obliczenia,
część przeznaczają na wymianę danych między sobą, czy komunikację i synchronizację.
Każdy procesor posiada również własną pamięć podręczną.

Może się zdarzyć, że procesory będą chciały się ze sobą skomunikować przy
pomocy pewnego fragmentu pamięci. Proces taki pociąga za sobą wymianę linii
pamięci podręcznej między rdzeniami. Dostęp przez dwa procesory do komórki
pamięci $n$, która przechowuje pewną strukturę, może mieć następującą postać:

\begin{enumerate}
\item procesory $A$ i $B$ przechowują we swoich pamięciach podręcznych
bieżącą zawartość $n$,
\item procesor $A$ przygotowuje dane dla $B$ i aktualizuje zawartość $n$,
\item protokół uspójniania pamięci podręcznej informuje $B$, że posiada
nieaktualną wersję linii zawierającej $n$,
\item $B$ żąda odczytu komórki $n$,
\item $A$ synchronizuje zawartość linii przechowującej $n$ z pamiecią
systemową,
\item $B$ pobiera linię przechowującą $n$ do swojej pamięci podręcznej,
\item $B$ posiada aktualną wersję linii przechowującej $n$ i może operować na
jej zawartości.
\end{enumerate}

Proces ten jest dość czasochłonny, ale w przypadku komunikacji
międzyprocesorowej niezbędny.

Może się jednak zdarzyć, że jedna linia pamięci podręcznej przechowuje kilka
struktur, lecz nie służą one do wymiany danych między procesorami -- są
prywatnymi danymi pewnych wątków obliczeń działających na odrębnych procesorach.
Zjawisko takie określa się mianem fałszywego współdzielenia (ang. \textit{false
sharing}). Jest ono bardzo niepożądane, a w przypadku kiedy obejmuje duże
obszary pamięci, prowadzi do poważnego obniżenia wydajności związanego z
masowym przepływem danych między pamięciami podręcznymi procesorów. Sytuację
taką określa się mianem zaśmiecania pamięci podręcznej (ang. \textit{cache
trashing}), które, w dosłownym tego słowa sensie, rujnuje wydajność programu
działającego na architekturze wieloprocesorowej.

\subsection{Synchronizacja}

Sposób synchronizacji między poszczególnymi ścieżkami wykonania kodu może być
realizowany na wiele sposobów. Używane do tego instrumenty mogą się różnić
wydajnością i elastycznością. Podstawowym środkiem służącym do synchronizacji
wątków czy procesów są blokady, które mogą nakazywać systemowi operacyjnemu
wywłaszczenie programu i tym samym użycie mocy obliczeniowej na inne zadania.
Blokad y używa się do obrony zasobów przed modyfikacją przez więcej niż jedną
ściężkę wykonania kodu. Zwrócenie sterowania do jądra systemu jest opłacalne,
jeśli przewiduje się, że program będzie oczekiwał na zwolnienie blokady przez
dłuższy moment czasu. Odpowiedni dobór środków synchronizacji przy konstrukcji
allokatora mającego działać w środowisku wielowątkowym może mieć dużym wpływ na
jego wydajność.

\paragraph{Semafory POSIX.} Są środkiem do synchronizacji wielu procesów w
systemach zgodnych ze standardem \texttt{POSIX}. Występują w dwóch formach --
jako semafory z nazwą i semafory anonimowe. Druga forma może posłużyć jako
forma synchronizacji między procesami tylko, jeśli semafor anonimowy umieści
się w pamięci dzielonej. Pełna implementacja tego mechanizmu jest dostępna w
systemie \texttt{Linux} od wersji 2.6. Semafory \texttt{POSIX} w przypadku
wykrycia blokady wywłaszczają program.

\paragraph{Semafory binarne dla wątków POSIX.} (ang. \textit{pthread mutexes})
Są środkiem synchronizacji między wątkami. W systemie \texttt{Linux} są
zaimplementowane przy użyciu wywołania systemowego \verb+futex(7)+ -- podobnie
jak semafory \texttt{POSIX}. Dzięki temu część operacji (np.: sprawdzenie stanu
blokady) przebiega w przestrzeni użytkownika i jest stosunkowo szybka. W
przypadku blokady sterowanie jest kierowane do systemu operacyjnego. 

\paragraph{Blokady pętlowe.} (ang. \textit{spin locks}) Są używane tam, gdzie
programista spodziewa się szybkiego zwolnienia blokady. Taka sytuacja może się
często zdarzać dla systemów wieloprocesorowych, kiedy chronione zasoby są
niewielkich rozmiarów. W takim przypadku opłaca się przeczekać kilkadziesiąt
nawet do kilkuset cykli procesora w przestrzeni użytkownika. Koszt
wywłaszczenia programu jest o wiele większy. Blokady pętlowe są bezużyteczne w
przypadku systemów z jednym procesorem i należy ich unikać.

\paragraph{Atomowe instrukcje procesora.} Do realizacji blokad pętlowych
niezbędne są instrukcje procesora, które dają gwarancję wyłącznego dostępu do
wybranych lokacji w pamięci. Najczęściej spotykanymi atomowymi operacjami są:
\texttt{test-and-set}, \texttt{compare-and-swap}, \texttt{fetch-and-add}.
Znajdują one także zastosowanie przy budowie równoległych struktur danych bez
blokad (ang. \textit{lock free}).

\paragraph{Mechanizm konstruowania obiektów synchronizacji w przestrzeni
użytkownika.} Celem zwiększenia wydajności operacji na semaforach programiści
systemu \texttt{Linux} wprowadzili w wersji 2.6 nowe wywołanie systemowe
\verb+futex(7)+ (ang. \textit{Fast Userspace muTexes}). Główną motywacją do
stworzenia tego wywołania było przerzucenie odpowiedzialności na program
użytkownika za obsługę części operacji na semaforach -- a tym samym
zmniejszenie ilości wywołań systemowych, które są stosunkowo kosztowne. Przy
okazji \texttt{Linux} zyskał potężne narzędzie do konstrukcji dowolnych
obiektów służących do synchronizacji wątków i procesów. Przy pomocy procedury
\verb+futex(2)+ można np.: napisać hybrydową wersję blokowania, która przez
pewien okres czasu czeka na zwolnienie zasobu w przestrzeni użytkownika i w
przypadku przekroczenia limitu czasowego oddaje sterowanie do przestrzeni
jądra.

\newpage

% --=[ Omówienie klasycznych mechanizmów ]=-------------------------------------

\section{Klasyczne mechanizmy}
\hypertarget{Klasyka}{}

Istnieje szereg schematów zarządzania pamięcią o dobrze zbadanych
właściwościach. Można je potraktować jako punkt wyjściowy do tworzenia
hybrydowych menadżerów pamięci.

Do głównych zadań algorytmu allokatora należy wyznaczanie pozycji bloków przy
próbie minimalizacji efektu fragmentacji. Wybór adresu początku bloku jest
jedyną decyzją jaką może podejmować menadżer pamięci. Sposób w jaki to robi
nazywa się \textit{polityką wyznaczania położenia bloku}. Projektowanie
menadżera pamięci składa się na trzy etapy:

\begin{description}

\item[Nakreślenie strategii.] \textit{Strategia} określa cele jakie mają być
spełnione w ramach pewnej \textit{polityki}. \textit{Strategia} może być
idealistyczna i brzmieć np.: ``wyznaczaj pozycję bloków w takich sposób, by ich
rezerwacja nie indukowała fragmentacji w trakcie kolejnych operacji
allokatora'', co z natury \textit{on-line} algorytmu zarządzania pamięcią jest
nieosiągalne.  \textit{Strategia} może powstać w wyniku obserwacji
rzeczywistych ciągów operacji dla allokatora.

\item[Określenie polityki.] \textit{Polityka} jest w pewnym sensie
skonkretyzowaną instancją starającą się zaspokoić cele wyznaczone przez
\textit{strategię}. Może być to pseudokod lub inna forma myśli dająca się
przekształcić bezpośrednio w \textit{mechanizm}. W wyniku skonkretyzowania
pewne właściwości \textit{strategii} mogą zostać porzucone, jako zbyt kosztowne
lub zbyt skomplikowane by zawrzeć jej koncepcje w \textit{polityce}.

\item[Implementacja mechanizmu.] \textit{Mechanizmem} można określić kompletny
algorytm spełniający specyfikację wyznaczoną przez pewną \textit{politykę
wyznaczania pozycji bloku}. \textit{Mechanizm} to zbiór struktur danych i
operacji na nich służących do przydzielania i zwalniania bloków pamięci.
Programista wykorzystuje \textit{mechanizm} odwołując się do niego poprzez
pewien określony interfejs.

\end{description}

\subsection{Listy wolnych bloków}

Najczęściej wykorzystywanym mechanizmem wśród menadżerów pamięci są warianty
listy wolnych bloków implementujące różne polityki. Z reguły listy są
organizowane w pamięci używając techniki znaczników granicznych (ang.
\textit{boundary tags}) opisane przez Kuntha w książce
\cite{knuth73fundamental}. Znaczniki są częścią bloku -- leżą bezpośrednio
przed adresem zwracanym przez procedurę rezerwującą blok. Znaczniki to rekord
przechowujący co najmniej wielkość bloku i flagę zajętości. Kiedy blok jest
wolny bezpośrednio za zacznikami, a czasem również na samym końcu,
przechowywane są pola struktury utrzymującej porządek wolnych bloków według
zasad określonych przez pewną politykę. Najczęściej wykorzystywaną strukturą
danych jest lista dwukierunkowa, która niestety wypada bardzo źle pod względem
wydajności. Ponieważ znaczniki poszczególnych bloków są od siebie znacznie
oddalone, lokalność odwołań do pamięci jest dość znikoma -- powodując znacznie
obciążenie przepustowości szyny danych. Dodatkowo menadżer używający listy może
wymagać liniowego czasu względem ilości wszystkich bloków do wykonania operacji
przydziału lub zwolnienia.

Celem poprawienia czasu działania poszczególnych żądań zamiast list
dwukierunkowych stosuje się np. drzewa kartezjańskie opisane w pracy
\cite{vuillemin80unifying}. Są to drzewa, które są uporządkowane dwuwymiarowo.
Utrzymują porządek kopcowy ze względu na wielkość bloku, a porządek
\textit{in-order} ze względu na adres początku bloku. Pierwszy allokator
wykorzystujący te drzewa został opisany w pracy \cite{stephenson83fastfits}.

Tam gdzie porządek względem adresów nie jest konieczny, interesującym wydaje
się być wykorzystanie zbalansowanych drzew. Przemawia za tym niewielka
pesymistyczna złożoność czasowa operacji wyszukiwania i tym samym zmniejszenie
ilości odwołań do komórek, które z dużym prawdopodobieństwem znajduje się poza
pamięcią podręczną. Słabo zbadaną strukturą danych pod względem wykorzystania w
allokatorach pamięci jest \textit{splay tree}, która może się bardzo dobrze
sprawować w praktyce.

\paragraph{Podział i scalanie.} Są to techniki, które służą kontroli do
fragmentacji. Przypuśćmy, że znaleziony przez algorytm wolny blok jest dużo
większy od żądanego rozmiaru. Allokator może wtedy podzielić blok na dwie
części. Pierwszą część może wtedy zwrócić jako żądany blok, a drugą wstawić na
listę wolnych bloków. Kiedy menadżer dostaje pewien blok do zwolnienia, może
zadecydować, aby scalić go z okolicznymi wolnymi blokami. \textit{Podział i
scalanie} są przedmiotem rozmaitych polityk np.:

\vspace{-1ex}

\begin{description}
\item[Polityka buforowania.] Wynika z następującej strategii: ``jeśli program
zwolnił obszar o rozmiarze $n$, to być może zaraz będzie potrzebował bloku o
identycznym rozmiarze''. Strategia ta może się przyczynić do zwiększenia
wydajności allokatora w przypadku operacji intensywnie modyfikujących
dynamiczną strukturę danych, a wymagającą użycia menadżera pamięci. Polityka do
zrealizowania tej strategii polega na zorganizowania bufora, do którego na
jakiś okres czasu trafiają zwolnione bloki. Jeśli blok nie został w określonym
czasie zarezerwowany to trafia na listę wolnych bloków i zostaje scalony.
Polityka taka gwarantuje zapobiega swego rodzaju ``czkawce'' polegającej na
częstym scalaniu i podziale tego samego bloku. Dodatkowo polityka ta sprzyja
lokalności odwołań do pamięci, gdyż z dużym prawdopodobieństwem ostatnio
zwolnione bloki znajdują się w pamięci podręcznej procesora.
\vspace{1ex}

\item[Polityka gorliwego podziału.] Motywowana jest strategią brzmiącą: ``jeśli
program zrezerwował blok o niewielkim rozmiarze $n$, to najprawdopodobniej
zaraz będzie żądął bloku o podobnym rozmiarze''. Strategia taka sprawdza się w
przypadku, kiedy program szybko buduje dużą strukturę danych. Polityka
relizująca tą strategię zapewnia, że przy żądaniach o odpowiednim rozmiarze
(dla struktur o rozsądnym rozmiarze rekordu) zostanie znaleziony odpowiednio
większy wolny blok pamięci. Zostanie on podzielony na pewną ilość wolnych
bloków o żądanym rozmiarze. Pierwszy z tych bloków zostanie zwrócony jako
rezultat operacji \texttt{malloc}, a reszta trafi do podręcznego bufora
allokatora, omówionego w \textit{polityce buforowania}. Technika ta została
użyta w dlmalloc \cite{douglea96malloc} i określana jest tam mianem
\textit{pre-splitting}. Dokładniejszy opis implementacji takiej strategii można
znaleźć w pracy \cite{weinstock88quickfit}.
\vspace{1ex}

\item[Polityka leniwego scalania.] Może być wynikiem stosowania następującej
strategii: ``wykorzystuj moc obliczeniową tylko wtedy, kiedy jest to
rzeczywiście potrzebne''. Polityka wynikająca z tej strategii może np. scalać
tylko wtedy, kiedy uzna że wolne bloki po scaleniu mogą posłużyć do spełnienia
żądania. Może też po prostu odraczać scalanie bloków do kolejnej operacji
przydziału pamięci, które być może musi przejrzeć wszystkie pozycje na liście.
\end{description}

\paragraph{Best-fit.}

Polityka \textit{best-fit} -- czyli polityka najlepszego dopasowania -- polega
na przydzielaniu takiego bloku, którego rozmiar jest najmniejszym możliwym
spełniającym żądanie \texttt{malloc}. Mimo, że teoretycznie jest to polityka
powodująca największą fragmentację, to w praktyce nie obserwuje się takich
anomalii. Na dodatek jej stosowanie często powoduje mniejszą fragmentację niż
\textit{first-fit} o lepszych teoretycznie właściwościach. Polityka
\textit{best-fit} wynika z następujących dwóch strategii:
\vspace{-1ex}

\begin{description}
\item[Strategia minimalizacji pozostałości.] Mimo, że brzmi mało konkretnie i
nie jest jasne czemu dokładnie ma służyć, to przyczyniła się do powstania wielu
istotnych polityk. \textit{Best-fit} spełnia założenia tej strategii. Zauważmy,
że wybór najmniejszego możliwego bloku, a następnie jego podział na część
mającą posłużyć jako rezultat operacji \texttt{malloc}, implikuje powstanie
pewnego obszaru za przydzielonym blokiem (o ile znaleziony wolny blok nie jest
dokładnie tych samej wielkości co żądany). Obszar ten, będący pozostałością po
podziale, jest najmniejszym z możliwych jakie mogły powstać. Zatem jeśli się
okaże, że został nieużytkiem, to będzie miał minimalny rozmiar.
\vspace{1ex}

\item[Strategia ochrony dużych obszarów.] Służy polityce, która preferuje
dzielić bloki w obszarach, które w przyszłości nie będą mogły być elastycznie
używane.
\end{description}

\paragraph{First-fit.}

Polityka pierwszego dopasowania (ang. \textit{first-fit}) polega na
przydzieleniu pierwszego bloku, który spełnia rozmiar żądania. Reszta powstała
w wyniku podziału znalezionego bloku zostaje wstawiona na listę wolnych bloków.
Wadą tej polityki jest tendencja do generowania dużej ilości małych bloków na
samym początku listy i w efekcie długi czas wyszukiwania dużych bloków.

\paragraph{Polityka, a porządek listy wolnych bloków.}

W przypadku obu polityk wyboru położenia bloku (tj. \textit{best-fit} i
\textit{first-fit}) fregmentacja, którą powstaje w wyniku działania allokatora
w istotny sposób zależy od tego, w jaki sposób zorganizowany jest porządek na
liście wolnych bloków. W pracy \cite{johnstone98memory} przeprowadzono
gruntowne badania nt.  fragmentacji dla porządku \texttt{AO} (ang.
\textit{address ordered}), \texttt{FIFO}\footnote{Porządek kolejkowy --
pierwszy na wejściu, pierwszy na wyjściu.} (ang.  \textit{first in, first
out}), \texttt{LIFO}\footnote{Porządek stosowy -- ostatni na wejściu, pierwszy
na wyjściu.} (ang.  \textit{last in, first out}). Okazuje się, że praktycznych
zastosowaniach polityka \textit{best-fit} w połączeniu z listą uporządkowaną
względem adresów lub stosowo charakteryzuje się najmniejszą fragmentacją.
\vspace{-1ex}

\begin{description}

\item[Porządek LIFO.] Lista bloków przechowuje na początku ostatnio zwolnione
bloki. W łatwy sposób można rozszerzyć ten pomysł o właściwości
\textit{polityki buforowania}, jeśli tylko nie będzie się scalać pewnej ilości
bloków z początku listy. Polityka ta charakteryzuje się dużą lokalnością
odwołań. Ponieważ na czele listy znajdują się ostanio używane bloki, to z dużym
prawdopodobieństwem znajdują się one również w pamięci podręcznej procesora.

\vspace{1ex}

\item[Porządek FIFO.] Ostatnio zwolnione bloki będą umiejscawiane na końcu
kolejki. Cały zarządzany obszar będzie cyklicznie przeglądany. Trudno
stwierdzić praktyczną przydatność takiej polityki. Wydaje się ona być mało
interesująca ze względu na niską lokalność odwołań i empirycznie udowodnioną
dużą fragmentacją.

\vspace{1ex}

\item[Porządek AO.] Lista jest uporządkowana w naturalny sposób -- względem
adresu początku bloków. Polityka ta zdradza tendencję do umieszczania zajętych
bloków w obrębie początku zarządzanego obszaru. Charakteryzuje się dobrym
zachowaniem lokalności i małą fragmentacją w przypadku, kiedy zwalnianie bloki
tworzą spójny obszar pamięci. Oszacowanie fragmentacji w przypadku śmierci
dużej ilości obiektów nierównomiernie rozmieszczonych w pamięci nie jest dobrze
zbadane.
\end{description}

\subsection{Posegregowane listy wolnych bloków}

Prostym i efektywnym rozszerzeniem mechanizmu omówionego w poprzednim punkcie
jest tablica list. Każdy element takiej tablicy przechowuje wskaźnik do listy
wolnych bloków o określonej wielkości. Kiedy blok jest zwalniany umieszcza się
go na liście odpowiadającej rozmiarowi zwalnianiego bloku. Kiedy program chce
zarezerwować pamięć, wtedy bloków o żądanej wielkości szuka się na odpowiedniej
liście. Jeśli lista jest pusta, to allokator przy pomocy odpowiednich działań
musi pobrać wolną pamięć, stworzyć nowe bloki i uzupełnić pustą listę.  Należy
jeszcze zauważyć, że o ile bloki z danej listy są uporządkowane względem
wielkości, to wcale nie muszą zajmować spójnego obszaru pamięci.

Z oczywistych względów tablica przechowująca wskaźniki nie może być zbyt duża.
Dlatego ogranicza się liczbę dopuszczalnych wielkości bloków. Do danej listy
przyporządkowuje się wszystkie żądania z danego przedziału wielkości,
zaokrąglając żądany rozmiar w górę. Niestety, przyczynia się to do zwiększenia
fragmentacji wewnętrznej. Z tego względu mechanizmu tego nie stosuje się do
obsługi wszystkich żądań, a tylko z zadanego przedziału wielkości -- z reguły
od kilkudziesięciu bajtów do kilkunastu kilobajtów.

\begin{description}
\item[Wersja uproszczona.] Nie angażuje ona procedur podziału i scalania
bloków do ograniczania problemu fragmentacji. Gdy na danej liście zabraknie
bloków, to allokator pobiera spójny obszar o długości kilku stron od systemu
operacyjnego, dzieli je na wolne bloki i wstawia na listę. Warto zauważyć, że
takie działanie zwalnia allokator z obowiązku pamiętania długości bloku w
obszarze przez niego zajmowanym. Zamiast tego, wielkość można przypisać do
obszaru okupowanego przez bloki o danym rozmiarze. Jest w miarę oczywiste, że
polityka taka prowadzi do implementacji szybkiego algorytmu -- zarówno w
trakcie przydziału jak i zwalniania pamięci koszt jest stały. Wadą tego
podejścia jest potencjalnie duża fragmentacja, która nie podlega kontroli.
Pewnym podejściem do ograniczenia problemu fragmentacji jest sprawdzanie, czy w
obszarze zajmowanym przez bloki danej wielkości istnieje co najmniej jedna
nieużywana strona. Można ją wtedy wyciągnąć z tego obszaru i użyć do
uzupełnienia listy bloków o innym rozmiarze.
\vspace{1ex}

\item[Wersja pełna.] Zasadnicza różnica między wersją pełną, a uproszczoną,
tkwi w metodzie tworzenia nowych bloków. Kiedy lista przechowująca bloki o
rozmiarze z danego zakresu jest pusta, przeszukuje się listę dla bloków o
większym rozmiarze. Jeśli tam znajdzie się blok to zostaje on podzielony.
Powstałe w wyniku podziału mniejsze bloki umieszcza się na odpowiednich
listach. W trakcie zwalniania bloku następuje jego scalenie z sąsiadami i
umieszczenie na odpowiedniej liście. Łączenie jest operacją kosztowną i może
prowadzić do tzw. ``czkawki'', dlatego zazwyczaj stosuje się \textit{politykę
leniwego scalania}. W przeciwieństwie do wersji uproszczonej, bloki o
określonym zakresie rozmiaru mogą zajmować dowolne obszary pamięci.  Warto
zauważyć, że mechanizm ten aproksymuje politykę \textit{best-fit}, niezależnie
od polityki stosowanej względem poszczególnych list.

\end{description}

\subsection{Inne algorytmy}

Wiele algorytmów zarządzania pamięcią jest efektem modyfikacji mechanizmów
przedstawionych w poprzednich punktach. Często dokonywanymi zmianami jest
stosowanie struktur danych pozwalających skrócić czas poszukiwania bloku o
określonych właściwościach. Istnieją jeszcze dwa mechanizmy istotnie różne od
omówionych wcześniej i warte komentarza:

\begin{description}

\item[Systemy partnerskie.] Znane jako \textit{buddy system}, są szczególnym
wariantem list wolnych bloków implementujących efektywną, lecz ograniczoną
formę scalania i podziału. Na $i$-tej liście przechowywane są bloki, których
długość jest sumą wielkości bloków z poprzednich list -- zazwyczaj z
$(i-1)$-tej. Szybki podział i scalanie opierają się na prostym sposobie
wyznaczania pozycji bloków, operującym jedynie na wartości adresów.  Bloki o
danej wielkości muszą mieć adres podzielny przez określoną wielkość.  Scalanie
odbywa się jedynie na przyległych blokach o takim samym rozmiarze --
określanych mianem partnerów lub bliźniaków. Adres pierwszego bloku musi być
podzielny przez rozmiar bloku, który powstałby w wyniku scalenia bliźniaków.
Intuicyjnie patrząc -- przestrzeń zarządzana przez \textit{buddy system} jest w
rekurencyjnie podzielona na dwie części o ustalonych rozmiarach -- najczęściej
są to potęgi dwójki. Efektywną implementację binarnych systemów bliźniaczych
zaprezentowano w pracy \cite{demaine99fast}.

\vspace{1ex}

\item[Mapy bitowe.] Mapa bitowa (ang. \textit{bitmap}) jest wektorem bitów.
Każdemu bitowi można przypisać odpowiedzialność za stan danego bloku z obszaru
odpowiadającemu wektorowi. Metodę tą rzadko się spotyka w allokatorach pamięci
mimo, że w niektórych przypadkach mogłyby pomóc redukować fragmentację
wewnętrzną. Mapy bitowe mogłyby też posłużyć do zwiększania lokalności
referencji, poprzez umieszczenie informacji o zajętości bloków w jednym
obszarze pamięci.

\end{description}

\newpage

% --=[ Testowanie właściwości ]=------------------------------------------------

\section{Testowanie}
\hypertarget{Testowanie}{}

W trakcie omawiania allokatorów w poprzednich rozdziałach często padało
stwierdzenie, że pewnych teoretycznych właściwości menadżerów pamięci nie
obserwuje się w praktyce. Istnieje duża rozbieżność między tym w jaki sposób
zachowują się allokatory w rzeczywistych zastosowaniach i pesymistycznymi
przypadkami określonymi przez teorię. Warto zwrócić uwagę na to, że często
proste modyfikacje, czy dodatkowe heurystyki, potrafią całkowicie zmienić
właściwości teoretyczne menadżera pamięci. Trudno powiedzieć z czego wynika tak
duża rozbieżność. Może to mieć źródło w fakcie, że w istocie allokatory są zbyt
skromnie przebadane od strony teoretycznej. Może to wynikać z braku dobrze
zdefiniowanych środków do modelowania pewnych zachowań.  Menadżery pamięci to z
reguły algorytmy hybrydowe inaczej traktujące poszczególne wielkości bloków --
ze względu na to ich teoretyczna analiza może okazać się bardzo kłopotliwa i
nader skomplikowana. Ostanim i najbardziej prawdopodobnym wyjaśnieniem rozważanej
rozbieżności jest to, że przekrój programów wykorzystujących menadżery pamięci
zachowuje się w mało losowy sposób, za który odpowiadają pewne wzorce
programistyczne.

\subsection{Badane właściwości}

Menadżery pamięci warto i należy intensywnie badać. Istnieje duża gama zachowań
programów korzystających z allokatorów. Można się spodziewać, że będą istotne
różnice we wzorcach wykorzystania tych algorytmów w przypadku: aplikacji z
interfejsami graficznymi, serwerów usług sieciowych, programów do obliczeń
naukowych, aplikacji do modelowania geometrii, itd. Dobry ogólny menadżer
pamięci powinien sprawować się dobrze w każdym z tych przypadków.

Złą wiadomością jest to, że algorytmy allokatorów są bardzo ciężkie do analizy
w~praktyce. Fragmentację należy mierzyć na pewnym zbiorze programów. Niestety
nie ma ustalonego korpusu, który byłby standardem do porównywania wyników.  W
artykułach poruszających tematykę wydajności i fragmentacji często pojawiają
się te same programy służące do pomiarów, jednak część z nich nie jest
publicznie dostępna lub jest płatna. Trudno też uznawać ten zbiór za
reprezentatywny.

Kolejnym problemem jest fakt, że badanie allokatorów ze względu na wydajność
traci sens, jeśli wydzielić je ze środowiska lub programu, w którym działają.
Efektywność aplikacji w dużym stopniu zależy od tego, jak allokator rozmieści
bloki w pamięci. Lokalność referencji to na tyle istotne zagadnienie, że
programista świadomie i poprawnie posługujący się mechanizmami współczesnych
procesorów jest w stanie przyśpieszyć swój program nawet o rząd wielkości.
Menadżer pamięci powinen maksymalizować lokalność odwołań, zwalniając
programistę z pamiętania o niskopoziomowych aspektach związanych z hierarchią
pamięci.

Przed wdrożeniem kompletnego menadżera pamięci do szerszego zastosowania należy
go gruntownie przetestować pod względem poszczególnych właściwości:

\paragraph{Poprawność.} Allokator w pełni odpowiada za bloki pamięci, które
przydziela i zwalnia. Każdy błąd w menadżerze bezpośrednio oddziaływuje na
program, który z niego korzysta. W związku z tym algorytm musi być intensywnie
przetestowany względem wszystkich przypadków na jakie pozwala semantyka
operacji rezerwowania i zwalniania bloku. Niedopuszczalne jest, by narażać
programy korzystające z menadżera na utratę danych. Allokatory są klasą
algorytmów, którą wyjątkowo ciężko się odpluskwia. Nie można zdać się na
narzędzia do znajdowania błędów odwołań do pamięci, bo w większości przypadków
działają one jako nakładka przechwytująca wywołania procedur \texttt{malloc} i
\texttt{free}. Poprawność można badać przy pomocy testów losowych -- jest wtedy
pewność, że w dość krótkim czasie zostaną osiągnięte stany, które w praktyce
zdarzają się niezwykle rzadko. Taki typ błędów jest szczególnie niebezpieczny,
gdyż za usterkę z reguły obwinia się wtedy nie allokator, a~program z niego
korzystający.

\paragraph{Fragmentacja.} Pamięć RAM w dzisiejszych czasach jest zasobem
stosunkowo tanim. Niemniej trzeba go wykorzystywać z rozsądkiem -- wydaje się,
że straty większe niż 10\% -- 15\% są już martnorawstwem. Fragmentacja była
zawsze głównym celem badań allokatorów i często minimalizowano ją kosztem
wydajności. Ze względów ekonomicznych w dzisiejszych czasach można już kłaść na
to mniejszy nacisk. Istnieje dość szeroki wachlarz publicznie dostępnych
programów, którymi porównuje się menadżery pamięci -- aplikacje te zostaną
omówione w kolejnym podrozdziale. Fragmentację można mierzyć na różne sposoby:

\begin{enumerate}

\item Wyznacza się stosunek największego wolnego bloku do sumy wszystkich
wolnych bloków. Podaje się minimum tej wartości na przestrzeni czasowej
wykonania programu. Im bliższy jedności ten stosunek, tym większa część wolnej
pamięci jest skumulowana w pojedyńczym bloku.

\vspace{1ex}

\item Na całej przestrzeni czasowej programu wyznacza się stosunek dwóch
wartości -- maksymalnej wielkości bloków będących w użyciu i maksymalnej ilości
pamięci używanej przez allokator. Obliczane maksima mogą przypadać na różne
chwile. Wyznaczona wartość daje orientacyjne pojęcie o efektywności użycia
pamięci w najbardziej obciążającym momencie.

\end{enumerate}

Inne sposoby mierzenia fragmentacji, wraz z argumentacją na temat ich
użyteczności, zostały dokładnie omówione w pracy \cite{johnstone98memory}.
Problem fragmentacji w systemach komputerowych ze stronicowaniem ma nieco inną
specyfikę niż w rozważaniach teoretycznych. Najmniejszą jednostką pamięci jaką
otrzymuje allokator od systemu to strona -- obszar o długości 4\texttt{KiB}.
Dopóki istnieje co najmniej jeden używany blok wewnątrz strony, to nie może być
ona zwolniona.  Dochodzi wtedy do sytuacji, gdzie pojedyńczy nawet bardzo mały
blok powstrzymuje allokator przed zwolnieniem całkiem dużego obszaru. Warto
rozszerzyć testy uwzględniając właśnie takie anomalie. W pracy na temat
menadżera pamięci \texttt{jemalloc} \cite{evans06scalable} zastosowano ciekawą
metodę wizualizacji użycia przestrzeni adresowej programu przez allokator
pamięci.

\paragraph{Wydajność.} W inżynierii oprogramowania często spotyka się
stwierdzenie, że za 90\% czasu wykonania programu odpowiada 10\% kodu. Nie musi
być to prawdą, jednak słaba wydajność menadżera pamięci może przyczyniać się do
powstawania tak negatywnego efektu. Dzisiejsze programy wykorzystują allokatory
bardzo intensywnie -- wywołując procedury \texttt{malloc} i \texttt{free} setki
tysięcy, czy nawet miliony razy na sekundę. Optymalizacja szybkości menadżera
pamięci wymaga głębokiej wiedzy na temat architektury sprzętowej pamięci oraz
systemu operacyjnego. Wydajność można mierzyć kierując się różnymi kryteriami:

\begin{enumerate}
\item Czas poświęcony na wykonanie procedury \texttt{malloc} i \texttt{free}.
Uśredniony, minimalny, maksymalny w zależności od wielkości bloków.

\item W przypadku środowisk wielowątkowych -- ilość czasu spędzanego w
oczekiwaniu na zwolnienie blokady.

\item Ilość wywołań systemowych i ilość czasu w nich spędzonego.

\item Czas wykonania ustalonego zbioru programów używających danego allokatora.
\end{enumerate}

\paragraph{Lokalność.}

\begin{description}
\item[Pamięć podręczna.]
\item[Stronicowanie.]
\item[Warunki niskiej dostępności pamięci fizycznej.]
\end{description}

\paragraph{Skuteczność w wykrywaniu błędów.}

\subsection{Programy wspomagające testowanie.}

\subsection{Narzędzie \texttt{traces}.}

\newpage

% --=[ Implementacja ]=---------------------------------------------------------

\section{Implementacja}
\hypertarget{Implementacja}{}

\subsection{Założenia}

\newpage

\subsection{Interfejs standardowego allokatora}

\label{PosixMalloc}

Programiści, korzystający z menadżera sterty w standardowej bibliotece języka
C, są przyzwyczajeni do tego, że posiadają pewien dobrze znany mechanizm
udostępniający pewną funkcjonalność.

W związku z tym implementacja ogólnego menadżera pamięci powinna być możliwie
jak najbardziej zbliżona pod względem zachowania do tej określonej w
standardzie \texttt{POSIX}.

\subsubsection{Zgodność ze standardem \texttt{POSIX}}

\paragraph{Procedura malloc.}

Funkcja \texttt{malloc} zwraca wskaźnik do bloku pamięci o rozmiarze
\texttt{size} bajtów lub wartość \texttt{NULL} w przeciwnym wypadku.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{malloc}.}]
void * malloc (size_t size);
\end{lstlisting}

Zwrócony wskaźnik w systemach $32$-bitowych musi być podzielny przez $8$, a w
systemach $64$-bitowych przez $16$. W przypadku błędu zmienna systemowa
\texttt{errno} musi być ustawiona na wartość \texttt{ENOMEM}. Zarezerwowana
pamięć ma nieokreśloną zawartość. Nadpisanie obszaru znajdującego się
bezpośrednio przed jak i za przydzielonym blokiem najprawdopodobniej uszkodzi
prywatne struktury danych allokatora pamięci -- co doprowadzi do nieokreślonego
zachowania menadżera pamięci.

\paragraph{Procedura calloc.}

Funkcja \texttt{calloc} zwraca wskaźnik do wyzerowanego bloku pamięci będącego
w stanie pomieścić tablicę \texttt{count} elementów o rozmiarze
\texttt{eltsize} lub wartość \texttt{NULL} w przeciwnym wypadku.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{calloc}.}]
void * calloc (size_t count, size_t eltsize);
\end{lstlisting}

Procedura ta zachowuję się podobnie jak \texttt{malloc}, poza gwarancją
zainicjalizowania obszaru zerami. Implementacja tego wywołania może, ale nie
musi, korzystać wewnętrznie z wywołania \texttt{malloc}.

\paragraph{Procedura realloc.}

Funkcja \texttt{realloc} zmienia rozmiar bloku wskazywanego przez argument
\texttt{ptr} na \texttt{newsize} bajtów. Jeśli zwrócony adres jest równy
\texttt{ptr} oznacza to, że zarządcy pamięci udało się zmienić rozmiar bloku w
miejscu. W przeciwnym wypadku procedura \texttt{realloc} rezerwuje nowy blok o
rozmiarze \texttt{newsize}, kopiuje do niego zawartość bloku wskazywanego przez
\texttt{ptr} po czym zwalnia stary obszar.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{realloc}.}]
void * realloc (void *ptr, size_t newsize);
\end{lstlisting}

Jeśli \texttt{realloc} zwróci wskaźnik równy \texttt{NULL}, wtedy stary obszar
wskazywany przez \texttt{ptr} zostaje w nienaruszonym stanie, a zmienna
systemowa \texttt{errno} ma wartość \texttt{ENOMEM}.

Funkcja \texttt{realloc} działa jak \texttt{malloc(newsize)}, jeśli argument
\texttt{ptr} jest równy \texttt{NULL}, lub jako \texttt{free(ptr)}, jeśli
argument \texttt{newsize} jest równy $0$.

\paragraph{Procedura posix\_memalign.}

Funkcja \texttt{posix\_memalign} rezerwuje blok pamięci o adresie podzielnym
przez argument \texttt{alignment} (liczba ta musi być potęgą dwójki) oraz przez
\texttt{sizeof(void *)} i o rozmiarze \texttt{size}. Zarezerwowany blok pamięci
umieszczany jest w komórce pamięci wskazywanej przez \texttt{memptr} i funkcja
zwraca $0$. W przypadku błędu funkcja zwraca: \texttt{EINVAL} jeśli
\texttt{alignment} nie spełnia zadanych kryteriów lub \texttt{ENOMEM} jeśli nie
ma wystarczającej ilości pamięci.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{posix\_memalign}, \texttt{memalign} i \texttt{valloc}.},xleftmargin=0cm,xrightmargin=0cm]
int posix_memalign (void **memptr, size_t alignment, size_t size);
void * memalign (size_t boundary, size_t size);
void * valloc (size_t size);
\end{lstlisting}

Funkcja \texttt{memalign} działa analogicznie do \texttt{posix\_memalign} --
przy czym adres jest podzielny tylko przez \texttt{boundary} (będące potęgą
dwójki), a początek zarezerwowanego bloku jest zwracany przez wartość funkcji.
W przypadku błędu adres jest równy \texttt{NULL} i ustawiana jest zmienna
systemowa \texttt{errno}.

Funkcja \texttt{valloc} jest prostą nakładką na \texttt{memalign}, gdzie
wartość argumentu \texttt{boundary} jest równa długości strony, którą można
sprawdzić używając funkcji \texttt{getpagesize()}.

Warto również zauważyć, że w systemach \textit{BSD} pamięć rezerwowana przez te
procedury nie może być zwalniania przez procedurę \texttt{free}.

\paragraph{Procedura free.}

Funkcja \texttt{free} zwalnia blok pamięci, czyniąc przestrzeń przez niego
wykorzystywaną zdatną do ponownego użycia.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{free} i \texttt{cfree}.}]
void free (void *ptr);
void cfree (void *ptr);
\end{lstlisting}

Funkcja \texttt{cfree} jest synonimem \texttt{free} i istnieje wyłącznie ze
względów historycznych -- dla kompatybilności z systemem \textit{SunOS}.

Dostęp do bloku pamięci po jego zwolnieniu mimo, że jest operacją błędną to
często jest możliwy. Istnieją narzędzia wykrywające takie anomalie. Deallokacja
bloku pamięci uszkadza jego zawartość.

Program nie musi zwalniać wszystkiej pamięci przed zakończeniem swego
działania. Automatyczne zarządzanie zasobami odda wykorzystaną przez proces
pamięć na użytek systemu operacyjnego.

Jeśli wskaźnik \texttt{ptr} nie podaje początku bloku pamięci, czyli wartości
zwróconej przez jakieś wywołanie \texttt{malloc}, lub podaje obszar już raz
zwolniony, to zachowanie menadżera pamięci jest nieustalone i może
zakończyć się przerwaniem działania programu.

Jeśli wskaźnik \texttt{ptr} jest równy wartości \texttt{NULL}, to procedura
\texttt{free} nie wykonuje żadnej operacji.

\subsubsection{Rozszerzenia \texttt{GNU}}

\vspace{2ex}
\begin{lstlisting}[caption={Prototypy pozostałych procedur i zmiennych.}]
int mallopt (int param, int value);
int mcheck (void (*abortfn)(void));
struct mallinfo mallinfo (void);
\end{lstlisting}

\newpage

\subsection{Menadżer stron -- \texttt{PAGEMAN}}

Pobieranie i zwalnianie stron pamięci przy pomocy wywołania systemowego jest
zadaniem czasochłonnym. Wymaga ono przebudowania pewnych struktur jądra oraz
przeładowania katalogów i tablic deskryptorów. W systemach wieloprocesorowych
taki proces może trwać wiele tysięcy cykli, gdyż dodatkowo wiąże się z
uspójnieniem zawartości bufora \texttt{TLB}. Taki zabieg może wygenerować w
rezultacie kilkaset tysięcy dostępów do obszarów składujących tablice
deskryptorów, których potencjalnie brak w pamięci podręcznej lub linie je
przechowujące są oznaczone jako nieaktualne.

Każdą nieużywaną stronę zamiast odsyłać od razu do systemu operacyjnego można
przechowywać w jakiejś strukturze danych i bez udziału systemu przydzielić
powtórnie, do jednego z podrzędnych zarządców pamięci. Oczywiście nie można w
nieskończoność kumulować nieużyków -- musi istnieć jakieś zdarzenie generujące
ich oddawanie do systemu. Takim wyzwalaczem może być przekroczenie pewnej
sumarycznej objętości nieużywanych stron np.: $2$ \verb+MiB+, albo próba
rezerwacji dużego spójnego obszaru pamięci np.: powyżej $64$ stron.

Przestrzeń adresowa i pamięć wirtualna należąca do procesu jest wspólna dla
wszystkich wątków działających w jego obrębie. Zatem struktura przechowująca
nieużytki będzie dzielona między wątki. Dostęp do takiego zasobu będzie musiał
angażować pewne środki synchronizacji tj. semafory binarne lub blokady pętlowe.
By zmniejszyć rywalizację o dostęp do struktury zasobu stosuje się
dwupoziomowość. Istnieje jedna globalna lista nieużytków i jedna lokalna dla
każdego z wątków. Obie mają różne kryteria odśmiecania, lista globalna może je
zmieniać w zależności od ilości działających wątków. Komunikacja między
komponentami przebiega od lokalnego menadżera, przez globalny, aż do wywołań
systemu operacyjnego.

Można się spodziewać, że w większości przypadków wątek budujący jakieś
dynamiczne struktury danych będzie sam na nich operował, co najwyżej
prezentując wyniki innym wątkom. Innymi słowy większość operacji \verb+free+
wątek będzie wykonywał na blokach, które sam zarezerwował. Oczywiście nie może
być to założeniem, ale praktyka pokazuje, że zachowanie sprzeczne z opisanym
wyżej przyczynia się do wielu błędów i programiści pisząc programy unikają
takich zachowań.

Kiedy wątek kończy swoje działanie powinien zadbać o to, by pamięć, którą
zarządza korzystając z prywatnych struktur, oddać na użytek globalnej listy
nieużytków lub menadżera osieroconych bloków -- takich, które nie posiadają
właściciela.

Kłopotliwym wywołaniem systemowym w przypadku wielowątkowych aplikacji jest
\texttt{fork}. Procedura ta klonuje proces, w obrębie którego może działać
wiele wątków. Proces klonujący nazywa się rodzicem, a proces sklonowany --
dzieckiem.  Dziecko posiada przestrzeń adresową i większość struktur danych
identycznych jak rodzic. Niestety wątki nie są klonowane w stanie aktywnym, do
procesu potomnego przechodzi tylko wątek, który wywołał funkcję \verb+fork+.
Rodzi to dość subtelny problem -- blokady założone w przestrzeni adresowej
rodzica nie mogą być zwolnione w dziecku, gdyż wątki odpowiedzialne za to
zadanie nie istnieją. Za obsłużenie tej niewygodnej operacji odpowiada
procedura \verb+pthread_at_fork+, przy pomocy której można zarejestrować
wywołania, które nastąpią bezpośrednio przez wykonaniem \verb+fork+ i
bezpośrednio po wykonaniu \verb+fork+ w procesach rodzica i dziecka.

Jako strukturę danych do implementacji menadżera stron użyto tablicy list wraz
z obiektami służącymi do synchronizacji wątków.

\begin{figure}[h]
\centering
\includegraphics[width=0.60\textwidth]{pageman}
\caption{Graficzna reprezentacja struktury danych \texttt{pageman}.}
\end{figure}

\subsubsection{Opis operacji}

\subsubsection{Możliwe optymalizacje}

Ciekawą i jednocześnie efektywną metodą na zwiększenie wydajności korzystania z
globalnej listy nieużytków byłaby implementacja współdzielonej listy bez
blokad. Implementacje takie bazują na operacji procesora \verb+CAS+ (ang.
\textit{compare-and-swap} -- porównaj i zamień). Dzięki temu można byłoby
wyeliminować kosztowną operację blokady semafora binarnego zabezpieczającego
dostęp do struktury i umożliwić wątkom jednoczesne operowanie na listach
wolnych obszarów.

A może uprządkowana lista obszarów względem roznących adresów?

Istotnym zagadnieniem jest też dobór progów odśmiecania list nieużytków.
Należałoby przeprowadzić empiryczne badania programów i spróbować wyłowić
często spotykane wzorce zachowań mogące pomóc w oszacowaniu wartości.

\newpage

\subsection{Zarządca dużych bloków -- \texttt{MMAPMAN-AO}}

Duże bloki, które z reguły wymagają przestrzeni o rozmiarze kilkunastu stron
pamięci i więcej, najefektywnie jest zarządzać niezależnie od mniejszych
bloków. Jest ku temu kilka istotnych powodów.

Z dużym prawdopodobieństwem bloki o dużych wielkościach będą wykorzystywane
przez program przez długi okres czasu. Takich obiektów będzie niewielka ilość w
porównaniu do bloków o mały rozmiarze. Narzut związany z generowanymi
nieużytkami jest dość mały. Nie istnieją zatem istotne argumenty za tym, żeby
przechowywać takie obiekty z blokami innych rozmiarów.

Do organizowania obszarów dla większych obiektów można wykorzystywać sprzętowe
strony większej wielkości np. $4$ \verb+MiB+. Dzięki temu intensywne
wykorzystywanie dużego obszaru może generować mniej \texttt{TLB miss},
przyczyniając się do poprawy wydajności programu.

Czasem zdarza się, że program żąda bloku pamięci o adresie podzielnym przez
określoną potegę dwójki przy pomocy funkcji \verb+memalign+. Implementacja tej
procedury przy pomocy zarządcy \texttt{mmapman-ao} jest bardzo efektywna.
Wszystkie nowo zarezerwowane obszary mają początek w adresie podzielnym przez
rozmiar wielokrotności strony -- więc część funkcjonalności wywołania
\verb+memalign+ dostajemy za darmo. Resztę można osiągnąć rezerwując
odpowiednio większą ilość stron i odmapowując od początku obszaru te strony,
których początki nie dzielą się przez zadaną liczbę.

Jeśli obszarami o rozmiarze $<$ $32$ \verb+KiB+ zajmuje się osobny zarządca, to
wielkość pól będzie mógł składować w danej typu \verb+int16_t+. Zyskujemy więc
również na efektywności wykorzystania pamięci.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{mmapman-ao}
\caption{Graficzna reprezentacja struktury danych \texttt{mmapman-ao}.}
\end{figure}

Struktura danych dla zarządcy jest zwykłą listą dwukierunkową przechowującą w
każdym rekordzie dodatkowe dane -- między innymi adres początku okupowanego
obszaru. Lista ta jest posortowana pod względem rosnących adresów.

Nagłówek (czy raczej stopka) obszaru zawiera następujące informacje:
\begin{center}
\begin{tabular}{|m{0.15\linewidth}|p{0.75\linewidth}|}
\hline
\textsc{pole} & \textsc{znaczenie} \\
\hline
\hline
\verb+pages+ & Ilość stron zajmowanych przez obszar. \\
\hline
\verb+size+	 & Ilość bajtów zajmowanych przez blok wewnątrz obszaru. \\
\hline
\verb+prev+	 & Poprzedni nagłówek na liście zarządcy \texttt{mmapman-ao}. \\
\hline
\verb+next+	 & Następny nagłówek na liście zarządcy \texttt{mmapman-ao}. \\
\hline
\end{tabular}
\end{center}

\subsubsection{Opis operacji}

Rezerwacja bloku (\verb+alloc+) o rozmiarze $Size$ polega na pobraniu obszaru od
menadżera stron, zainicjalizowaniu nagłówka i wstawieniu go na listę. Rozmiar
rezerwowanego obszaru jest wyrównywany do wielkości podzielnej przez długość
strony pamięci. Trzeba zadbać też o to, by na końcu obszaru znalazło się
wystarczająco dużo przestrzeni by przechować nagłówek. Łączna ilość pamięci
zajmowanej przez ten obszar to:
$\left\lceil\frac{Size + HeaderSize}{PageSize}\right\rceil$ stron.

Rezerwacja bloku o początku w adresie podzielnym przez potęgę dwójki
(\verb+alloc_aligned+) nie różni się od \verb+alloc+ dla granicy wyrównania
mniejszej, bądź równej wielkości strony. Dla większej wartości pobiera się 
$\left\lceil\frac{Size + Alignment + HeaderSize}{PageSize}\right\rceil$
stron, gdyż nie mamy wpływu na to w jakim dokładnie adresie zostanie zaczepiony
nowy obszar. Wyżej podana ilość gwarantuje, że wewnątrz obszaru znajdziemy
odpowiednią ilość miejsca pod adresem podzielnym przez granicę wyrównania.
Następnie należy zwolnić niepotrzebne strony z początku oraz z końca obszaru,
zinicjalizować nagłówek i wstawić obszar na listę.

Operacja \verb+realloc+ może powiększyć zarezerwowany obszar o nieużytek
występujący między końcem bloku, a początkiem nagłówka. Jeśli menadżer stron
umożliwia określanie początku adresu pobieranego obszaru, to można
zaimplementować procedurę \verb+expand_at_end+. Próbuje ona znaleźć określoną
ilość wolnych stron zaczynających się bezpośrednio za naszym obszarem. Jeśli
tak, to nowe strony są doczepiane do obszaru, zawartość nagłówka jest
aktualizowana i przenoszona w nowe miejsce. Należy zaktualizować wskaźniki w
sąsiadach nagłówka by odzwierciedlały jego nową pozycję. Kiedy \verb+realloc+
pomniejsza dany blok, sprawdzane jest czy w obszarze jest nieużytek o rozmiarze
co najmniej jednej strony. Jeśli tak, to wykorzystuje się procedurę
\verb+shrink_at_end+. Przenosi ona nagłówek na koniec pierwszej strony,
należącej do nieużytku, która jest go w stanie pomieścić. Następnie aktualizuje
dane w nagłówku, zwalnia zbędne strony i aktualizuje wskaźniki w sąsiadach
nagłówka.

\subsubsection{Możliwe optymalizacje}

Zdaje się, że jedyna możliwa ścieżka zwiększenia wydajności to zastąpienie
listy nagłówków przy pomocy zbalansowanego drzewa. Ze względu na to, że ilość
dużych bloków jest stosunkowo niewielka, taka optymalizacja jest nieopłacalna
pod względem złożoności czasowej. Natomiast ciekawe jest to, że w przypadku
operacji \verb+alloc+ zmniejszy się ilość dostępów do pamięci do logarytmicznej
wielkości, w mniejszym stopniu obciążając pamięć podręczną.

\newpage

\subsection{Zarządca małych bloków -- \texttt{HEAPBLKMAN}}

Zarządzanie małymi blokami wymaga określenia osobnej strategii. Uwarunkowane
jest to obserwacjami przeprowadzonymi na rzeczywistych programach.

Przede wszystkim należy się spodziewać, że program będzie masowo przydzielał
małe obszary pamięci -- z reguły robi to intensywnie operując na dynamicznych
strukturach danych. Wyobraźmy sobie program wczytujący dane do zbalansowanego
drzewa binarnego: w trakcie konstrukcji dość rzadko będzie zwalniał rekordy
będące węzłami drzewa (o ile w ogóle będzie to robił), następnie zostaną
przeprowadzone obliczenia, po czym całe drzewo zostanie zwolnione, a wynik
działania przekazany do następnej fazy obliczeń.

Ponieważ spodziewamy się dużej ilości bloków małego rozmiaru, narzut pamięci na
składowanie struktur potrzebnych dla zarządcy powinien być znikomy. Dobrze by
było, gdyby zarezerwowane bloki nie przechowywały żadnych informacji poza
danymi użytkownika. Można też z dużym prawdopodobieństwem stwierdzić, że
zwalniany blok pamięci znajduje się już w jakiejś linii pamięci podręcznej.
Pożądaną sytuacją byłoby, gdyby zaallokowany rekord bezpośrednio po oddaniu go
na użytek programu był dostępny w pamięci podręcznej.

Rezerwowane struktury są najprawdopodobniej wielkości podzielnej przez
\texttt{sizeof(long int)} lub \texttt{sizeof(long long int)}, czyli odpowiednio
$4$ lub $8$ bajtów. Jest to domyślna granica stosowana przez kompilatory.

Pozostaje jeszcze zdefiniowanie wielkości małego bloku. W mojej implementacji
występują trzy rodzaje wielkości małych bloków: $8$, $16$ i $24$. Bloki o
długości $n \in [1,8]$ są zaokrąglane do rozmiaru $8$ bajtów, $n \in [9,16]$ do
$16$ bajtów i $n \in [17,24]$ do $24$ bajtów.

Struktura danych odpowiedzialna za przechowywanie niewielkich bloków pamięci
jest to hybrydą stosu, listy dwukierunkowej i jednokierunkowej (która może być
zastąpiona zrównoważonym drzewem binarnym).

\begin{figure}[h]
\centering
\includegraphics[width=0.80\textwidth]{heapblkman}
\caption{Graficzna reprezentacja struktury danych \texttt{heapblkman}}
\end{figure}

Wartownik obszaru jest polem o długości jednego bloku, ale co najmniej długości
$16$ bajtów. Przechowuje następujące informacje:
\begin{center}
\begin{tabular}{|m{0.15\linewidth}|p{0.75\linewidth}|}
\hline
\textsc{pole} & \textsc{znaczenie} \\
\hline
\hline
\verb+flags+		& Zawiera flagi określające jakiego rozmiaru są bloki w tym
obszarze pamięci (tj. \verb+FLAG_L8+, \verb+FLAG_L16+ i \verb+FLAG_L24+) oraz
flagę wskazującą źródło allokacji następnych bloków (tj. \verb+FLAG_LRU+,
\verb+FLAG_STACK+). \\
\hline
\verb+blkcnt+		& Ilość wszystkich bloków. \\
\hline
\verb+stack+		& Numer bloku, w którym znajduje się wierzchołek stosu. \\
\hline
\verb+lru_first+	& Numer bloku przechowującego początek listy ostatnio
zwolnionych bloków pamięci. \\
\hline
\verb+lru_blkcnt+	& Ilość wszystkich bloków na liście ostatnio zwolnionych. \\
\hline
\verb+free+			& Numer bloku, w którym zaczyna się lista wolnych bloków,
posortowanych malejąco pod względem adresu. \\
\hline
\end{tabular}
\end{center}

Wolne bloki mają odpowiednią długość dla danego obszaru i zawierają następujące pola:

\begin{center}
\begin{tabular}{|m{0.15\linewidth}|p{0.75\linewidth}|}
\hline
\textsc{pole} & \textsc{znaczenie} \\
\hline
\hline
\verb+younger+	& Indeks bloku, który został zwolniony wcześniej, na liście ostatnio zwolnionych bloków. \\
\hline
\verb+older+	& Indeks bloku, który został zwolniony później, na liście ostatnio zwolnionych bloków. \\
\hline
\verb+prev+		& Indeks bloku o młodszym adresie na liście wolnych bloków. \\
\hline
\verb+next+		& Indeks bloku o starszym adresie na liście wolnych bloków. \\
\hline
\end{tabular}
\end{center}

Ponieważ w implementacji tej struktury danych użyto indeksów typu
\verb+uint16_t+, maksymalna ilość bloków w danym obszarze może wynieść $2^{16}
- 1 = 65535$. Limituje to maksymalną ilość pamięci zarządzanej w obrębie
jednego obszaru do odpowiednio dla bloków długości $8$ bajtów -- $512$
\verb+KiB+, dla $16$ bajtów -- $1$ \verb+MiB+ i dla $24$ bajtów -- $1.5$
\verb+MiB+. Indeksowanie bloków zaczyna się od liczby większej od zera, zaś
zero jako indeks oznacza koniec listy.

Powyżej wierzchołka stosu wszystkie wolne bloki są wolne, niezainicjalizowane i
ich zawartość jest nieustalona. Poniżej wierzchołka stosu wszystkie bloki muszą
być na obu listach i pole \verb+prev+ zawsze musi mieć mniejszą wartość niż
indeks bloku, w którym się znajduje.

\subsubsection{Opis operacji}

Zarezerwowanie (\verb+alloc+) bloku jest operacją działającą w czasie stałym i
może przebiegać dwoma torami:
\begin{itemize}
\item Jeśli bit \verb+FLAG_STACK+ jest zapalony oznacza to, że na stosie jest
co najmniej jeden wolny blok. Zwiększany jest indeks wierzchołka stosu i
zwracany odpowiedni adres. Jeśli stos został zapełniony bit \verb+FLAG_STACK+
zostaje zgaszony.
\item Jeśli bit \verb+FLAG_LRU+ jest zapalony, to na liście LRU znajduje się
co najmniej jeden wolny blok. Zostaje on usunięty z obu list i zostaje zwrócony
jego adres. Jeśli lista została opróżniona, bit \verb+FLAG_LRU+ zostaje
zgaszony.
\end{itemize}

Zwalnianie (\verb+free+) bloku również może przebiegać dwutorowo:
\begin{itemize}
\item Jeśli zwalniany blok ma indeks o jeden mniejszy niż wierzchołek stosu,
wtedy stos przesuwany jest na zwolniony blok i bit \verb+FLAG_STACK+ zostaje
zapalony. Następnie sprawdza się czy blok bezpośrednio leżący pod wierzchołkiem
stosu jest początkiem listy wolnych bloków. Jeśli tak to usuwany jest on z obu
list, wierzchołek stosu zostaje przesunięty o jeden blok w dół i operacja
zostaje powtórzona.
\item Jeśli zwalniany blok ma indeks co najmniej o dwa mniejszy niż wierzchołek
stosu, to blok jest dodawany na początek listy LRU i wstawiany na listę bloków
posortowanych pod względem malejących adresów. Bit \verb+FLAG_LRU+ jest
zapalany.
\end{itemize}

Pesymistyczna złożoność czasowa zwalniania bloku to $O(n)$, gdzie $n$ to
długość listy wolnych bloków.

W przypadku kiedy obie flagi \verb+FLAG_STACK+ i \verb+FLAG_LRU+ są zgaszone
miejsce w danym obszarze się wyczerpało i należy ten obszar powiększyć, o ile
istnieje taka możliwość (pole \verb+blkcnt+ nie przekroczy wartości $65535$).

Obszar można rozszerzyć przyłączając do jego końca nowe strony pamięci przy
użyciu procedury rozszerzania (\verb+expand_at_end+), która zwiększa ilość
dostępnych bloków poprzez wydłużenie obszar za wierzchołkiem stosu. Menadżer
pamięci korzystający z zarządcy małych bloków może również na zapas dodawać
strony do danego obszaru.

Kiedy obszar pamięci jest relatywnie długi i od końca wierzchołka stosu do
końca obszaru jest jedna lub więcej niewykorzystywanych stron pamięci istnieje
możliwość skurczenia obszaru (\verb+shrink_at_end+). Dzięki temu strony mogą
być użyte do innych celów lub zwrócone do systemu operacyjnego.

\subsubsection{Możliwe optymalizacje}

Z opisu tej struktury danych dość jasno widać, że działa ona najszybciej w
ciągu operacji \verb+alloc+, \verb+free+ o strukturze stosu. Zbyt
optymistycznym jest by zakładać, że zdecydowana większość programów tak się
zachowuje.

Jednym z pomysłów na zwiększenie wydajności zarządcy małych bloków jest
implementacja multibloków. Multiblok to zbiór przylegających do siebie wolnych
bloków. Taki obiekt zachowywał by się na liście LRU i liście wolnych bloków
posortowanych malejąco jak jeden wolny blok. Taka modyfikacja przyśpieszyłaby
operację zwalniania obszaru w pierwszym przypadku.

\newpage

\subsection{Zarządca pozostałych bloków -- \texttt{BLKMAN-AO}}

Obszary o rozmiarze $\ge 24B$ i $< 32KiB$.

\begin{figure}[h]
\centering
\includegraphics[width=0.90\textwidth]{blkman}
\caption{Graficzna reprezentacja struktury danych \texttt{blkman}}
\end{figure}

\subsubsection{Opis operacji}

\subsubsection{Możliwe optymalizacje}

\newpage

\subsection{Menadżer pamięci}

\newpage

% --=[ Wnioski ]=---------------------------------------------------------------

\section{Podsumowanie i kierunek dalszych badań}
\hypertarget{Podsumowanie}{}

Śmieci i inne pomysły, o których lepiej nie zapomnieć, a trzeba gdzieś umieścić:
\begin{itemize}
\item istotne dla wydajności dostępów do pamięci jest umieszczanie danych w
adresach o naturalnych wartościach tj. $32$-bitowe słowo powinno być pod
adresem podzielnym przez $4$,
\end{itemize}

\newpage

% --=[ Bibliografia ]=----------------------------------------------------------

\nocite{berger00hoard}
\nocite{berger01composing}
\nocite{berger02reconsidering}
\nocite{bonwick94slab}
\nocite{chilimbi00designing}
\nocite{demaine99fast}
\nocite{douglea96malloc}
\nocite{evans06scalable}
\nocite{feng05localityimproving}
\nocite{fitzgibbons00linux}
\nocite{ghemawat07tcmalloc}
\nocite{gorman04linuxvm}
\nocite{iyengar96scalability}
\nocite{johnstone98memory}
\nocite{luby94tight}
\nocite{pas02memory}
\nocite{paul95dynamic}
\nocite{robson71estimate}
\nocite{robson74bounds}
\nocite{robson77worst}
\nocite{stephenson83fastfits}
\nocite{vuillemin80unifying}
\nocite{weinstock88quickfit}

\bibliographystyle{alpha}
\bibliography{mgr}

\end{document}
