% --- Inicjalizacja dokumentu --------------------------------------------------

\documentclass[12pt,a4paper,titlepage,twoside]{mwart}
\usepackage{latexsym}
\usepackage{polski}
%\usepackage{array}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
%\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{a4wide}
\usepackage{fancyhdr}
\usepackage{tabularx}
%\usepackage{enumitem}
\usepackage[iso]{isodateo}
\usepackage{hyperref}
\usepackage{listings}
%\usepackage{subfigure}
\usepackage{graphicx}
\pagestyle{fancy}
\lstset{language=[ANSI]C,frame=single,captionpos=b,xleftmargin=20mm,xrightmargin=20mm,tabsize=4}

\pdfcompresslevel9

% --- Zdefiniowanie autora i tytułu --------------------------------------------
\author{Krystian Bacławski}
\title{Wielowątkowy zarządca pamięci dzielonej}
\date{Październik 2007}

\frenchspacing

\begin{document}

\maketitle
\cleardoublepage

% --- Abstrakt -----------------------------------------------------------------

\begin{abstract}
\vspace{2ex}
\begin{center}
\begin{tabularx}{0.75\textwidth}{X}
Najefektywniejszą metodą komunikacji między dwoma procesami jest wykorzystanie
pamięci współdzielonej (ang.  \textit{shared memory}). Procesy są to ścieżki
wykonania kodu, które posiadają niezależne przestrzenie adresowe, a~utworzenie
przestrzeni dzielonej między nimi wymaga odpowiednich mechanizmów systemu
operacyjnego. Taki rodzaj pamięci nie podlega zarządzaniu w ramach menedżera
pamięci standardowej biblioteki języka C. Jednak forma komunikacji między dwoma
procesami może angażować wykorzystanie dynamicznej struktury danych
korzystającej z procedur analogicznych do \texttt{malloc} i \texttt{free}.
Istnieje tylko jedna publicznie dostępna biblioteka o otwartym kodzie
realizująca to zadanie --- \texttt{libmm}. Niestety alokator tam użyty cechuje
niska wydajność operacji i duża fragmentacja. Celem tej pracy jest
implementacja wydajnego mechanizmu zarządzania przestrzenią udostępnianą w
ramach pamięci dzielonej. 
\end{tabularx}
\end{center}
\end{abstract}

\cleardoublepage

% --- Spis treści --------------------------------------------------------------

\tableofcontents
\cleardoublepage

% ------------------------------------------------------------------------------

\setlength{\parindent}{0pt}
\setlength{\parskip}{1.2ex plus 0.5ex minus 0.2ex}

\section{Wstęp}

Algorytmy zarządzania stertą towarzyszą informatyce od samych jej początków.
Menedżerów pamięci zaczęto używać, kiedy pojawiły się pierwsze dynamiczne
struktury danych, takie jak listy i drzewa, a sama pamięć była na tyle duża by
zmieścić w niej większe zadania.

Ponieważ istnieje wiele wariantów problemu zarządzania pamięcią, należy
zawęzić, co jest rozumiane przez ten termin. W tej pracy tematem rozważań
będzie niskopoziomowy menedżer pamięci bez odśmiecania --- taki jaki znamy z
biblioteki standardowej języka C. Udostępnia on co najmniej dwie operacje:
\texttt{malloc} i \texttt{free}. Raz przydzielony blok pamięci nie może się
przemieszczać, ani być w jakikolwiek inny sposób modyfikowany przez algorytm
zarządcy. Zagadnienia te zostanie dokładniej opisane w dziale
\hyperlink{Teoria}{\textbf{Teoretyczne podstawy}}. Zostaną tam również
wytłumaczone pewne terminy, które wydają się być niejasne i często --- być może
bez świadomości czytelnika --- są używane zamiennie.

Problem allokacji pamięci jest od strony teoretycznej bardzo dobrze zbadany.
Większość badań została przeprowadzona na przełomie lat 60-tych i 70-tych
ubiegłego wieku. Skupiały się one głównie na analizie nieużytków powstałych w
wyniku przeprowadzenia ciągu operacji na zarządzanym obszarze. Określiły górną
granicę na fragmentację pamięci. Przeprowadzone wtedy badania odzwierciedlały
główne problemy z jakimi borykano się wtedy w zadaniach obliczeniowych. Pamięć
była bardzo kosztownym zasobem i było jej stosunkowo mało, więc poświęcano
wydajność operacji przydzielania i zwalniania bloku na rzecz ogólnej ilości
składowanych danych.

Mimo, że minęło około 50 lat od pojawienia się pierwszych algorytmów
zarządzania stertą, dziedzina ta nadal nie jest wyczerpująco poznana od strony
praktycznej. Przyczyną tego jest nieustanna ewolucja sprzętu i zmiana realiów,
jeśli chodzi o koszt zasobów.

W ciągu ostatnich dwudziestu lat upowszechnił się w procesorach mechanizm
stronicowania, pamięć podręczna i wielopotokowość. Od pięciu lat następuje
dynamiczny rozwój procesorów wielordzeniowych. Za tymi zmianami próbują nadążyć
systemy operacyjne udostępniając programom efektywne, lecz stosunkowo
niskopoziomowe interfejsy ---~w~ramach których nie mieszczą się niestety
menedżery pamięci działające w przestrzeni użytkownika.

Ponieważ operacje zarządcy sterty są bardzo często wykorzystywane,
efektywność aplikacji pośrednio zależy od ich wydajności. Zależności te są o
wiele bardziej złożone niż się wydaje. Miejsce przydziału bloku, sposób
wykorzystania pamięci dostarczanej przez system operacyjny, przystosowanie do
wielowątkowości i inne aspekty, mogą mieć wpływ nie tylko na wydajność operacji
\texttt{malloc} i \texttt{free}. Umiejętna implementacja korzystająca ze
specyfiki architektury ma również wpływ na prędkość algorytmów korzystających z
alokatora. Innymi słowy --- nie sposób zbudować wydajny algorytm zarządzania
pamięcią nie znając dobrze specyfiki architektury sprzętowej i zachowań systemu
operacyjnego. Zagadnienia z tym związane poruszono w rozdziale
\hyperlink{Architektura}{\textbf{Podstawy architektury pamięci}}.

System \texttt{Linux} posiada stosunkowo dobre algorytmy zarządzania stertą,
zarówno te działające w przestrzeni użytkownika (biblioteka \texttt{GNU libc} i
\texttt{glib2}) jak i w przestrzeni jądra (\texttt{slab allocator}). Niestety
nie są to algorytmy ani uniwersalne, ani łatwo modyfikowalne na potrzeby
programisty. Dobry algorytm zarządzania pamięcią musi charakteryzować się niską
fragmentacją, krótkim zamortyzowanym czasem przypadającym na jedną operację i
wykorzystaniem zjawiska lokalności. Znajomość budowy dobrze znanych algorytmów
wydaje się być niezbędna do tego, by przeanalizować rozwój alokatorów i tym
samym rzucić światło na podstawy nowo konstruowanego menedżera. Kilka
podstawowych strategi przydziału bloków zostało zaprezentowanych w rozdziale
\hyperlink{Klasyka}{\textbf{Klasyczne menedżery pamięci}}.

Autor pracy w trakcie swojej kariery programistycznej natknął się na problem
efektywnego współdzielenia prostej struktury danych (tablicy haszującej) między
procesami serwera \textit{Apache} w systemie \texttt{Linux}.  Należy się tu
krótkie wyjaśnienie jak przebiega procedura obsługi połączenia \verb+HTTP+ w
tym serwerze. Za odbieranie połączeń odpowiada główny proces działający z
prawami administratora. Celem zwiększenia bezpieczeństwa i odporności na błędy
główny proces wykonuje swoją kopię przy pomocy procedury \verb+fork+, a
następnie deleguje obsługę pewnej ilości połączeń do dziecka.  Proces potomny
startuje z uprawnieniami administratora i szybko je porzuca, gdyż obsługa
połączenia może być potencjalnie niebezpieczna. Dziecko obsługuje połączenia,
które zostały mu przydzielone, a następnie kończy swoje działanie.  Taka
architektura separacji zadań dobrze sprawdza się w praktyce, czyniąc
\textit{Apache} jednym z bezpieczniejszych serwerów \texttt{HTTP}.

Zadanie programistyczne polegało na zaimplementowaniu modułu serwera
\textit{Apache} zabraniającego dostępu użytkownikom (określonym adresom
\texttt{IP}) do stron internetowych na podstawie pewnych kryteriów. Każde
obsłużenie połączenia musiało zmieniać parametry używane jako kryterium
akceptacji żądań klientów. W trakcie testów mających określić miejsce
przechowywania danych o połączeniach wybrano pamięć dzieloną, ze względu na
najmniejszy narzut obliczeń wymaganych do obsługi żądania. Główny proces
serwera rezerwował pewien obszar pamięci współdzielonej, która była
przekazywana w niezmienionej postaci do procesów potomnych --- co gwarantuje
procedura \verb+fork+. Dzięki temu wszystkie procesy potomne mogły się ze soba
w efektywny sposób komunikować.

Nowoczesny algorytm zarządzania pamięcią jest tworem hybrydowym i z reguły
posiada pięć rozróżnialnych podsystemów. Zarządzanie stronami to najbardziej
niskopoziomowy element całego menedżera. Odpowiada za pobieranie, zwalnianie i
buforowanie stron pamięci. Istnieją trzy pomniejsze algorytmy zarządzania
blokami o odpowiednich rozmiarach --- podział ten jest stosowany ze względu na
odmienne preferencje programów co do określonych rozmiarów allokacji. Ostatnim
elementem jest właściwy menedżer pamięci, który używa wyżej wymienionych
elementów i realizuje pewną strategię zarządzania blokami i obszarami pamięci.

W rozdziale \hyperlink{Implementacja}{\textbf{Implementacja}} autor przedstawił
założenia, które poczynił implementując własny menedżer pamięci. Został tam
zaprezentowany standardowy zarządca sterty dla systemu operacyjnego
\texttt{Linux}, który był podstawą określającą interfejs programisty i
zachowanie poszczególnych operacji. Opisane zostały poszczególne składowe
algorytmu, ogólna strategia zarządzania oraz ewentualne modyfikacje i
rozszerzenia mające na celu zwiększenie wydajności.

Większość analiz teoretycznych przeprowadzonych na menedżerach pamięci
określała zachowania algorytmów dla losowych ciągów danych. Dane w znaczeniu
tej klasy problemów to wielkość bloku i długość czasu jego życia --- czyli ilość
operacji od momentu zarezerwowania bloku do jego zwolnienia. O ile testy
zachowania menedżera pamięci na losowych danych mają sens, to w praktyce mają
niewielkie znaczenie. Testy takie mogą pomóc wychwytywać pewnego rodzaju
anomalie, czy po prostu błędy, dla ciągów danych, które w praktyce zdarzają się
bardzo rzadko.

Okazuje się, że programy korzystają z menedżera pamięci w pewien określony
sposób, zdradzając przy tym ściśle określone wzorce. Alokatory można testować
jako samodzielne programy i jako elementy innych programów. Często do testów
wybiera się pewien zbiór aplikacji i obserwuje czas działania w zależności od
algorymu alokatora.

Systemy uniksowe dzięki mechanizmowi przesłaniania symboli bibliotecznych
umożliwiają zmuszanie programów do korzystania z menedżera pamięci spoza
biblioteki standardowej. Dzięki temu można generować tzw. ślady wykonania
programu i analizować w jaki sposób korzystał z wywołań \texttt{malloc} i
\texttt{free}. Posiadając ślady można próbować generować testy składające się
na pseudolosowe ciągi operacji z uwzględnieniem zachowań pewnej przebadanej
liczby programów. Można także optymalizować alokator bezpośrednio pod daną
aplikację. Ciekawą i mało zbadaną dziedziną badań jest generowanie i analiza
śladów dla aplikacji wielowątkowych.

O testowaniu, technikach generowania śladów i doborze miarodajnych aplikacji do
testów traktuje rozdział \hyperlink{Testowanie}{\textbf{Metody testowania
wydajności}}.

Pamięć dzielona jest to spójny obszar pamięci umiejscowiony w przestrzeni
adresowej kilku ścieżek wykonania instrukcji nazywanych procesami lub wątkami.
Istotne jest zrozumienie różnic między tymi dwoma klasami obiektów.

Wątki działają wewnątrz jednego procesu. Dzielą między siebie przestrzeń
adresową procesu w ramach którego powstały. Wątki angażują zdecydowanie mniej
zasobów niż procesy. Ich wadą jest to, że potencjalnie są bardzo niebezpieczne.
Potencjalny błąd w jednym wątku może zniszczyć dane innych wątków. Czasem, ze
wzgędów bezpieczeństwa i poufności danych, nie można dzielić całej przestrzeni
adresowej.

Procesy, w odróżnieniu od wątków, posiadają własne niezależne przestrzenie
adresowe. Separują własne zasoby od innych procesów. Ograniczanie dostępu do
pewnych zasobów zlecają systemowi operacyjnemu --- zapewniając duży stopień
poufności danych. Czasem jednak muszą się ze sobą komunikować. Wydaje się, że
najwydajnieszym sposobem na szybką wymianę danych między procesami jest
dzielenie pewnego obszaru pamięci. Stworzenie pamięci dzielonej między
procesami wymaga specjalnych mechanizmów systemu operacyjnego.


W rozdziale \hyperlink{Podsumowanie}{\textbf{Podsumowanie i kierunek dalszych
badań}} zostały przedstawione potencjalne zastosowania wielowątkowego menedżera
pamięci poza wspomnianym przypadkiem modułu dla serwera \textit{Apache}. Autor
przedstawił też możliwą ścieżkę ewolucji dla poczynionych badań i
implementacji.

\newpage

% --=[ Wstęp teoretyczny ]=-----------------------------------------------------

\section{Teoretyczne podstawy}
\hypertarget{Teoria}{}

Menedżery pamięci są algorytmami tak powszechnymi, że niemal nie zauważa się ich
istnienia. Programiści traktują wywołania funkcji realizujących przydzielanie i
zwalnianie obszarów za czarne skrzynki --- nie wiedząc, że wewnątrz tkwią często
zaawansowane algorytmy. Z reguły są one dość dobrze przetestowane i sprawują
się dobrze w większości przypadków. Niestety bywają sytuacje kiedy działają
skrajnie nieefektywnie.  Słowo \textit{efektywnie} w kontekście alokatorów
pamięci może być rozumiane na kilka sposóbów.

Algorytm może być \textit{efektywny} pamięciowo, co znaczy że:
\begin{itemize}
\item zużywa niewiele pamięci na własne wewnętrzne pomocnicze struktury danych,
\item charakteryzuje się niewielką fragmentacją wewnętrzą i zewnętrzną.
\end{itemize}
Tematyka efektywności wykorzystania pamięci została szczegółowo omówiona w
przekrojowej pracy na temat alokatorów pamięci \cite{paul95dynamic}.

Alokator może być \textit{efektywny} obliczeniowo, co znaczy że:
\begin{itemize}
\item program z niego korzystający spędza mało czasu rezerwując i zwalniając
pamięć,
\item rzadko korzysta z wywołań systemowych celem pobrania lub zwolnienia stron
pamięci,
\item w przypadku programów wielowątkowych wątki rzadko się nawzajem blokują
wykorzystując zarządcę pamięci --- alokator charakteryzuje się niską
rywalizacją o blokady (ang. \textit{lock contention}) niezbędne do utrzymania
spójności wewnętrznych struktur.
\end{itemize}

Celem tego rodziału jest przedstawienie podstawowych koncepcji związanych z
algorytmami zarządzania pamięcią niezbędnych do zrozumienia treści kolejnych
rozdziałów. 

\subsection{Intuicyjna definicja problemu}

Algorytm zarządzania pamięcią to algorytm \textit{on-line}. Oznacza to, że dane
wejściowe traktuje on jak żądania, które należy obsłużyć natychmiastowo. Nie
może odwlekać ich obsłużenia --- w szczególności zacząć obsługiwać następnego
żądania przed spełnieniem bieżącego. Algorytmy \textit{on-line} charakteryzują
się również tym, że nie znają one przyszłości --- w sensie nie znają danych
jakie będą przetwarzać w następnym kroku. Optymalizacja takich algorytmów może
bazować tylko i wyłącznie na wiedzy, którą zdołały posiąść --- czyli na
podstawie żądań, które obsłużyły.

Menedżer pamięci to algorytm, który zarządza zasobem jakim jest pewien obszar
pamięci. W szczególności obszar ten może być niespójny. Poszczególne części
takiej przestrzeni pamięci mogą mieć różne właściwości wynikające z
architektury sprzętowej. Zarządzany obszar może dynamicznie zmieniać swój
rozmiar czy strukturę dostosowując się do wymagań pamięciowych aplikacji
korzystającej z alokatora. Menedżer sterty odpowiada za wykorzystanie całej
pamięci, którą posiada w przydzielonym mu obszarze.

Program korzystający z alokatora pobiera i zwalnia obiekty zwane
\textit{blokami pamięci}. Do obowiązków menedżera należy utrzymywanie listy
bloków i pamiętanie, które są zajęte, a które wolne. Algorytm wyznacza
położenie danego bloku tylko raz --- tj. nie może go przemieszczać, ani zmieniać
danych w nim zawartych, jeśli blok został już przydzielony.

Blok jest spójnym obszarem pamięci o następujących właściwościach:

\begin{tabularx}{\textwidth}{@{\hspace{4ex}}lX@{}}
	\texttt{położenie}	& adres pamięci, w którym się zaczyna \\
	\texttt{wielkość}	& ilość zajmowanej przestrzeni mierzona w bajtach \\
	\texttt{narodziny}	& kwant czasu, w którym zarządca oddaje blok na użytek programu \\
	\texttt{śmierć}		& kwant czasu, w którym program oddaje blok na użytek zarządcy \\
	\texttt{właściciel}	& proces lub wątek, któremu ten blok został przypisany \\
\end{tabularx}

Zarządca odpowiada na co najmniej dwa typy żądań programu:

\begin{tabularx}{\textwidth}{@{\hspace{4ex}}lX@{}}
	\texttt{malloc} & które zwraca adres bloku pamięci o żądanym
	rozmiarze lub informuje, że żądanie nie mogło zostać spełnione. \\

	\texttt{free} & które oddaje obszar zajmowany przez blok pamięci o
	podanym adresie do ponownego użycia przez algorytm zarządcy. \\
\end{tabularx}

Taka definicja odpowiada temu, co znane jest większości programistom
używającym języków imperatywnych takich jak \verb#C#, \verb#C++# czy
\verb#Pascal#.

\subsection{Fragmentacja}

Fragmentacja jest zjawiskiem wynikającym z nieefektywnego zarządzania pamięcią.
Jest miarą ilości przestrzeni, której nie można wykorzystać do obsłużenia żądań
programu. Innymi słowy jest to pamięć, która jest wolna, ale z jakiś powodów
nie może być oddana na użytek programu.

Fragmentacja wewnętrzna jest mniej groźna, lecz trudniejsza w minimalizacji. W
większości przypadków jest ona wynikiem poczynienia pewnych założeń w działaniu
alokatora. Rezerwowane bloki pamięci są z reguły większe, niżby wynikało to z
wartości przekazywanej do funkcji \texttt{malloc}. Procesory działają
wydajniej, a czasami wręcz wymagają\footnote{Procesory \texttt{PowerPC} przy
próbie odczytu słów danych o parzystej długości spod nieparzystych adresów
zgłaszają przerwanie sprzętowe.}, by słowa danych były odczytywane z adresów
podzielnych przez ich długość. Większość menedżerów pamięci za jednostkę
allokacji przyjmuje $8$ bajtów, co odpowiada rozmiarowi najdłuższej danej
całkowitej oznaczanej w języku \verb+C+ jako \verb+long long int+. W związku z
tym każdy blok ma adres początku podzielny przez $8$, co implikuje również 
podzielność rozmiaru bloku przez~$8$.

Wydaje się, że fragmentacja wewnętrzna jest nie do uniknięcia. Algorytm
zarządzania pamięcią nie wie nic na temat struktur, które będzie przechowywał w
blokach. Nie może zatem wiedzieć nic na temat tego przez jaką liczbę ma być
podzielny adres bloku. Na szczęście fragmentacja wewnętrzna nie jest dużym
problemem, gdyż dotyczy niewielkich objętościowo fragmentów pamięci.

Znacznie poważniejszym problemem jest fragmentacja zewnętrzna. Powstaje ona na
skutek wykonania pewnego ciągu operacji, które skutkują powstaniem wolnych
bloków o rozmiarach nie pozwalających na ich użycie przy obsłudze kolejnych
żądań.

\begin{figure}[ht]
\centering
\includegraphics[width=0.75\textwidth]{frag-ext}
\caption{Powstawanie fragmentacji zewnętrznej.}
\end{figure}

Na przedstawionym wyżej rysunku ostatnia operacja zakończyła się niepowodzeniem
mimo, że łączna ilość wolnej pamięci wynosi $64$. Rezerwując obszar o wielkości
$8$ alokator nie wiedział nic na temat przyszłych operacji. Nie mógł zatem
przewidzieć, że lepiej będzie umiejscowić ten blok w adresie \verb+@64+.
Niestety nie istnieje algorytm zapobiegający takim sytuacjom. Okazuje się, że
dla każdego algorytmu zarządzania pamięcią istnieje taki ciąg operacji
\texttt{malloc} i \texttt{free}, że fragmentacja pochłonie stosunkowo duże
obszary pamięci czyniąc z nich nieużytki. Na szczęście w praktyce fragmentacja
zewnętrzna nie osiąga tak niepokojących rozmiarów --- głównie dzięki temu, że
zachowania programów są dość regularne i często powtarzalne, co uwzględnia się
przy budowie algorytmów.

Na początku lat 70 przeprowadzono szereg badań mających na celu określić jaka
ilość pamięci jest potrzebna na wykonanie dowolnego ciągu operacji
\texttt{malloc} i \texttt{free}. W~pracy \cite{robson74bounds} (będącej
kontynuacją \cite{robson71estimate}) Robson pokazał, że górna granica ilości
użytej pamięci na wykonanie dowolnego ciągu operacji przydziału oraz zwolnienia
bloku dla strategii \textit{First-Fit}\footnote{Z listy wolnych bloków
wybierany jest pierwszy satysfakcjonujący żądanie.} wynosi $O(M \cdot
\log_{2}(n))$, gdzie $n$~to długość największego bloku, a $M$~to maksymalna
liczba zajętych bloków. W kolejnej swojej pracy \cite{robson77worst} Robson
pokazał górne ograniczenie na ilość zużytej pamięci przez strategię
\textit{Best-Fit}\footnote{Z listy wolnych bloków wybierany jest najmniejszy
możliwy blok satysfakcjonujący żądanie.}, która okazuję się być znacznie
większa niż w przypadku \textit{First-Fit} i wynosi $O(M \cdot n)$. Analiza
oszacowania górnej granicy ilości zużytej pamięci dla metody \textit{First-Fit}
działającej w środowisku wielowątkowym ukazała się pracy \cite{luby94tight} i
jej wynik jest taki sama jak dla przypadku jednowątkowego.

\subsection{Wersje problemu zarządzania pamięcią}

Z problemem zarządzania pamięcią analogicznym to zdefinowanego w poprzednim
paragrafie można się spotkać na wielu szczeblach działania systemu
operacyjnego. W jądrze Linuksa są co najmniej dwa menedżery pamięci o rożnych
zastosowaniach i właściwościach. Istnieje cała gama alokatorów działających w
przestrzeni użytkownika.

\paragraph{Standardowa biblioteka POSIX.}

Najbardziej znany programistom interfejs zarządcy pamięci wywodzi się z języka
\verb+C+. Jest to alokator ogólnego przeznaczenia dla procesów i wątków
działających w przestrzeni użytkownika. Posiada pewien z góry ustalony
interfejs, który został dokładnie omówiony w rozdziale \ref{PosixMalloc}.
Ponieważ jest to najczęściej wykorzystywany alokator istnieje wiele projektów
mających na celu zwiększenie wydajności tego mechanizmu.

W~chwili obecnej standardowa biblioteka \verb+C+ dla systemu Linux korzysta z
alokatora \textit{Doug Lea's Malloc} (w skrócie \textit{dlmalloc}) opisanego w
pracy \cite{douglea96malloc}. W trakcie swojego instnienia alokator ten
przeszedł szereg modyfikacji: zwiększenie lokalności odwołań do pamięci,
usprawnienie heurystyk przygotowujących bloki na potrzeby przyszłych wywołań,
odroczone scalanie bloków, intensywne sprawdzanie spójności zarządzanej pamięci
celem znajdywania błędów popełnionych przez programistę i ograniczone wsparcie
dla wielowątkowości (znane jako \textit{ptmalloc}).

Lukę w wydajnych alokatorach dla programów wielowątkowych wypełnił
\textit{Hoard} opisany w pracy \cite{berger00hoard}. Opisano tam efektywny
sposób na zmniejszenie konkurencji między wątkami, poprzez przypisanie im
prywatnych obszarów pamięci. Zwrócono tam uwagę na zjawisko fałszywego
współdzielenia pamięci przez różne procesory i podano sposób na poradzenie
sobie z tym problemem. Alokator o podobnych właściwościach do \textit{Hoard}
został zaimplementowany na potrzeby projektu systemu operacyjnego
\textit{FreeBSD} --- \textit{jemalloc} został opisany w pracy
\cite{evans06scalable}.

Ideę prywatnych stert z alokatora \textit{Hoard} rozwinięto w
\textit{tcmalloc} wykonanym przez pracowników firmy Google opisanym w pracy
\cite{ghemawat07tcmalloc}. Zamiast semaforów, korzystających z systemu
operacyjnego, zastosowano tam blokady pętlowe (ang.  \textit{spin locks}).
Zaprezenowano tam efektywniejszą organizację wolnych obszarów pamięci
minimalizującą ilość odwołań do systemu operacyjnego.  Obecnie
\textit{tcmalloc} wydaje się być najwydajniejszym publicznie dostępnym
alokatorem pamięci ogólnego przeznaczenia.

\paragraph{Zarządzenie stronami pamięci.}

Większość ówczesnych komputerów ma pewne mechanizmy zarządzania pamięcią
zaimplementowane sprzętowo. Tworzono je z myślą o systemach operacyjnych i
zwiększeniu wydajności programów. Jądro systemu nadbudowuje nad tymi
mechanizmami warstwę abstrakcji uwalniając zwykłego programistę od pewnych
ograniczeń, ale również pułapek wydajnościowych.

Jądro systemu uniksowego nie udostępnia procesom przestrzeni użytkownika
mechanizmu zarządzania pamięcią dla bloków różnej długości. Dostarcza zamiast
tego nieco bardziej niskopoziomowy interfejs pobierania lub zwalaniania pewnej
ilości całych stron pamięci (najczęściej są to bloki 4\verb+KiB+). Z punktu
widzenia procesora taki blok to najmniejsza jednostka pamięci, której
właściwości jest w stanie kontrolować. Jądro systemu zarządza pamięcią fizyczną
tworząc wirtualną przestrzeń adresową na potrzeby procesu --- do tego celu
najczęściej używa się zmodyfikowanych systemów partnerskich (ang. \textit{buddy
systems}). Szczegółowy opis zarządzania pamięcią fizyczną w systemie
\textit{Linux} został zawarty w dostępnej publicznie książce
\cite{gorman04linuxvm}.

\paragraph{Zarządzenie obiektami w jądrze.}

Jądro systemu wykorzystuje na swoje potrzeby pewne struktury danych o ustalonej
wielkości rekordów. Wydzielenie funkcji jaką jest rezerwacja bloków
ustalonej długości, z ogólnego alokatora pamięci daje możliwość wielu
optymalizacji. Znając dobrze architekturę sprzętową można zadbać wtedy o
zwiększenie szybkości dostępu do poszczególnych bloków pamięci.

W pracy \cite{bonwick94slab} skupiono się na efektywnym wykorzystaniu pamięci
podręcznej do konstrukcji rekordów. Opis bazuje na wewnętrznym menedżerze
pamięci systemu operacyjnego \textit{SunOS 5.4}, będącego przodkiem systemu
\textit{Solaris}. W pracy tej przedstawiono zastosowanie kolorowania stron
pamięci do równomiernego obciążenia szyny pamięci. Zaprezentowano strukturę
danych \textit{slab} służącą do przechowywania obiektów ustalonej długości.
Alokator o podobnej strukturze został zaimplementowany w systemie
\textit{Linux} i zaprezentowany w pracy \cite{fitzgibbons00linux}.

\newpage

% --=[ Podstawy architektury pamięci ]=-----------------------------------------

\section{Podstawy architektury pamięci}
\hypertarget{Architektura}{}

Przed przystąpieniem do realizacji jakiegokolwiek algorytmu zarządzania stertą
należy dokładnie przeanalizować strukturę pamięci. Struktura pamięci to pojęcie
bardzo ogólne określające kilka aspektów --- począwszy od sprzętowych po
wywołania systemowe umożliwiające pobieranie oraz zwalnianie obiektów. Dopiero
mając na uwadze wszystkie zagadnienia związane z organizacją pamięci można
planować efektywny pod względem szybkości jak i zajmowanego miejsca menedżer
pamięci.

W tym rozdziale zostaną omówione podstawy i pojęcia związane z:
\begin{itemize}
\item organizacją sprzętową pamięci dla architektury sprzętowej \textit{Intel x86},
\item przestrzeni adresowej programu i jej obłożenia w systemie Linux,
\item interfejsem rezerwacji i zwalnianiem stron w systemach uniksowych,
\item zagadnieniami wydajności pamięci w systemach jedno- i wieloprocesorowych,
\item metodami synchronizacji dla programów wielowątkowych.
\end{itemize}

Część z tych zagadnien w przystępny sposób opisuje praca \cite{pas02memory}
skierowana do programistów kodujących aplikacje korzystające w intensywny
sposób z pamięci RAM.

\subsection{Stronicowanie}

Pamięć fizyczna jest to rodzaj pamięci RAM widziany bezpośrednio przez
procesor. Podstawową jednostką zarządzania tym rodzajem pamięci jest strona,
będąca obszarem o następujących własnościach:

\begin{itemize}
\item pewnej z góry ustalonej wielkości (w przypadku procesorów \textit{Intel
x86} jest to 4KiB lub 4MiB),
\item adres jej początku jest podzielny przez długość strony,
\item posiada zestaw uprawnień (do odczytu, do zapisu, itd.)
\end{itemize}

Nad pamięcią fizyczną system operacyjny --- korzystając z jednostki MMU (ang.
\textit{Memory Management Unit}) procesora --- buduje warstwę zwaną pamięcią
logiczną. Zadanie to jest realizowane przez mechanizm translacji adresów ---
często określany także mechanizmem stronicowania. Do translacji adresów
procesor wykorzystuje opis pamięci logicznej składający się na wielopoziomowe
tablice deskryptorów stron.

\begin{figure}[ht]
\centering
\includegraphics[width=0.75\textwidth]{paging}
\caption{Schemat translacji adresu dla architektury \textit{Intel x86}.}
\end{figure}

Procesor posiada rejestr PDBR, w którym składuje wskaźnik do katalogu stron o
adresie wyrównanym do granicy 4096 bajtów. Każda pozycja w katalogu stron to 32
bitowe słowo. Zawiera ono 20 starszych bitów określających fizyczny adres
początku tablicy stron i 12 młodszych bitów na dodatkowe dane.  Analogicznie
jest z deskryptorem strony, przy starsze 20 bitów podaje fizyczny adres
początku strony.

Kiedy program odwołuje się do pamięci logicznej procesor wykonuje następujące kroki:
\begin{enumerate}
\item rozbija adres na 3 części: 10-bitowy indeks w katalogu stron (PDE), 10-bitowy
indeks w tablicy stron (PTE) i 12 bitowy indeks wewnątrz strony (PO),
\item wyszukuje deskryptor katalogu zestawiając górne 20 bitów rejestru PDBR z
indeksem PDE --- wyznaczając adres fizyczny początku katalogu stron,
\item wyszukuje deskryptor strony zestawiając górne 20 bitów wyznaczające
początek tablicy stron z indeksem PTE --- adres fizyczny początku strony,
\item zestawia górne 20 bitów adresu fizycznego strony z indeksem PO i
realizuje operację odczytu lub zapisu danych.
\end{enumerate}

Przy pomocy młodszych 12 bitów w deskryptorze strony realizuje się w systemach
różne mechanizmy. Najbardziej znanymi mechanizmami są:
\begin{itemize}
\item \textit{ochrona pamięci} --- deskryptory stron przechowują bity uprawnień do
czytania, pisania, wykonywania zawartości --- procesor sprawdza te bity w
trakcie translacji adresu i w przypadku błędu dostępu generuje błąd
stronicowania (ang. \textit{Page Fault}),
\item \textit{pamięć wirtualna} --- dodatkowe bity w deskryptorze oznaczają czy
strona znajduje się w pamięci fizycznej --- system operacyjny może dane strony
przemieszczać do pamięci zewnętrznej i na odwrót, obsługując odpowiednio błąd
stronicowania,
\item \textit{mapowanie pamięci} --- mechanizm analogiczny do pamięci wirtualnej
może służyć do mapowania plików na strony, dzięki temu programista może mieć
swobodny dostęp do pliku,
\item \textit{pamięć dzielona} --- system operacyjny umieszcza w pamięci logicznej kilku
procesów te same strony pamięci fizycznej.
\end{itemize}

Zasadniczo dwóch terminów: \textit{pamięć logiczna} i \textit{pamięć wirtualna}
mówiąc o mechaniźmie stronicowania często się nie rozróżnia i będę ich używać
zamiennie.

Nie sposób też pominąć istotnej przewagi stronicowania nad innymi metodami
sprzętowego zarządzania pamięcią. Mechanizm ten umożliwia systemowi
operacyjnemu organizowanie rozrzuconych w pamięci fizycznej stron w jeden
spójny obszar w pamięci logicznej.

\subsection{Pamięć podręczna}
\label{CacheMemory}

W tematyce związanej z architekturami systemów komputerowych często pojawia się
termin \textit{piramidy pamięci}. Porusza on zależność ilości pamięci od jej
wydajności. I tak najszybsze są w podanej kolejności: rejestry procesora,
pamięć cache, pamięć RAM, pamięć zewnętrzna (np. twarde dyski). W wyżej
wymienionej kolejności rośnie ilość danych, które te źródła pamięci mogą
przechowywać.

Pamięć podręczna (ang. \textit{cache}) jest kilkukrotnie szybsza od procesora.
Przechowuje najczęściej używane obszary, zakładając, że program przetwarzając
dane wykazuje pewną lokalność dostępów do poszczególnych komórek.

Pamięć podręczna przechowuje fragmenty pamięci RAM zwane liniami, którym
przyporządkowane są dodatkowe informacje niezbędne do funkcjonowania pewnych
szczególnych operacji dostępu. Kontroler szyny sprowadza i wyrzuca z pamięci
podręcznej całe linie.

Podstawowymi właściwościami pamięci podręcznej są:
\begin{itemize}
\item szybkość --- ile cykli trzeba czekać na sprowadzenie danych jednostki
obliczeniowej procesora,
\item architektura --- bezpośrednio mapowana, wielodrożna, w pełni asocjacyjna,
\item ilość --- im szybsza pamięć podręczna tym jej mniej. 
\end{itemize}

Pamięć cache jest dla programisty do pewnego stopnia przezroczysta. Nie jest to
obszar bezpośrednio dostępny, a raczej bufor dla danych z pamięci RAM. Stosując
odpowiednie instrukcje można wymusić na kontrolerze szyny by sprowadził do
pamięci podręcznej linie o określonych adresach, bądź też wymusił wydalenie do
pamięci pewnych linii. Metody te w języku angielski noszą nazwę
\textit{prefetching} i \textit{cache invalidation}.

Zjawiskiem niepożądanym z punktu widzenia wydajności są sytuacje, kiedy
procesor próbuje korzystać z danych, które nie są w żadnej linii pamięci
podręcznej --- w języku angielskim nazywa się je \textit{cache miss}. W takim
przypadku procesor zamraża wykonywanie instrukcji do momentu kiedy dane będą
dostępne --- może się to wiązać z koniecznością wymiany pewnej linii tzn.
zapisania jej wartości do pamięci RAM, a następnie sprowadzenia w to miejsce
innego obszaru. Pesymistyczny wariant to wiele cykli mocy obliczeniowej
procesora zmarnowanych na oczekiwanie.

Powrócmy na chwilę do stronicowania. Jeśli dobrze się przypatrzeć mechanizmowi
to widać, że jest on kosztowny w sensie ilości operacji na pamięci. Każdy zapis
czy odczyt wymusza na procesorze dodatkowe dwie operacje dostępu do pamięci
celem obliczenia adresu fizycznego. Strony przechowujące katalogi i tablice
deskryptorów mogą być buforowane i z reguły umożliwia się ich składowanie w
pamięci podręcznej. Sytuacja, w której każdy odczyt pamięci przechowującej
deskryptory generuje \textit{cache miss} powoduje jeszcze większy spadek
wydajności. Dlatego jednostka zarządzania pamięcią posiada własną pamięć
podręczną nazywaną \textit{Table Lookaside Buffer}. Przechowuje ona pewną ilość
(z reguły kilkaset) deskryptorów stron umożliwiających natychmiastowe
obliczenie adresu fizycznego. Sytuacja, w której TLB nie przechowuje informacji
o stronie, do której odwołanie jest potrzebne, by dostarczyć dane dla
instrukcji, nazywa się \textit{TLB miss}.

\subsection{Przestrzeń adresowa w Linuksie}

Przestrzeń adresowa procesu to wszystkie komórki pamięci, które można
zaadresować w jednej chwili, ale niekoniecznie mieć do nich dostęp (w takim
przypadku wystąpi przerwanie naruszenia ochrony pamięci). W systemach
32-bitowych proces dysponuje przestrzenią adresową 4GB. Oznacza to nie ilość
pamięci fizycznej jaka maksymalnie może być dostępna dla procesu, a wielkość
danych, do których procesor może mieć dostęp w sposób bezpośredni, adresując
komórki pamięci. To rozróżnienie jest istotne, gdyż mechanizm stronicowania
jest bardzo elastyczny i umożliwia odwzorowanie przestrzeni adresowej na pamięć
zewnętrzną, pliki, pamięć urządzeń wejścia-wyjścia, itd.

\begin{figure}[ht]
\centering
\includegraphics[height=0.5\textwidth]{linux-layout}
\caption{Obłożenie przestrzeni adresowej procesu w systemie Linux}
\end{figure}

Najnowsze systemy komputerowe mimo ograniczenia na przestrzeń adresową potrafią
umożliwić procesowi dostęp do większej ilości pamięci fizycznej niż wynosi
wielkość przestrzeni adresowej. Oczywiście mechanizm ten nie jest przezroczysty
dla programisty i wymusza używanie techniki zwanej przesuwającym się oknem
(ang. \textit{sliding window}) lub przełączaniem banków (ang. \textit{bank
switching}) --- kawałkiem przestrzeni adresowej, w którym widać fragment jakiejś
większej pamięci.

W systemach uniksowych oczywiście nie cała przestrzeń adresowa jest dostępna
dla procesu, jej część zajmuje jądro systemu. W tym fragmencie przestrzeni
jądro udostępnia swoje publiczne struktury, może mapować bufory, dane otrzymane
od urządzeń wejścia-wyjścia, itd.

Na przestrzeń adresową procesu użytkownika w systemie Linux składają się
następujące obszary:

\begin{center}
\begin{tabular}{|ccc|p{0.5\linewidth}|}
\hline
\textsc{początek} & & \textsc{koniec} & \textsc{znaczenie} \\
\hline
\hline
\texttt{0x00000000} & --- & \texttt{0x07ffffff} & Obszar wyłapywania złych wskaźników --- dostęp zawsze zabroniony.\\
\hline
\texttt{0x08000000} & --- & \texttt{0x08xxxxxx} & Tu wczytywana jest sekcja \texttt{text}\footnotemark pliku ELF. Miejsce na kod i zainicjalizowane dane.\\
\hline
\texttt{0x08xxxxxx} & --- & \texttt{?}          & Obszar sterty. Może zmieniać rozmiar przy pomocy procedury brk.\\
\hline
\texttt{?}          & --- & \texttt{0xBFxxxxxx} & Obszar dla wywołania systemowego mmap. Tu będą mapowane pliki i inne obiekty.\\
\hline
\texttt{0xBFxxxxxx} & --- & \texttt{0xBFFFFFFF} & Stos programu.\\
\hline
\texttt{0xC0000000} & --- & \texttt{0xFFFFFFFF} & Przestrzeń na użytek jądra systemu --- do komunikacji z procesem.\\
\hline
\end{tabular}
\footnotetext{Fragment pliku formatu ELF (ang. \textit{Executable and Linking Format}) przechowujący kod programu.}
\end{center}

\subsection{Metody rezerwacji stron w Linuksie}

Jądro linuksa nie udostępnia programom wywołań systemowych pełniących rolę
funkcji \texttt{malloc} i \texttt{free}. Zarządzanie ma o wiele bardziej
niskopoziomową postać. Linux umożliwia wyłącznie pobieranie i zwracanie pewnej
ilości stron poprzez umieszczanie ich w przestrzeni adresowej w obszarach do
tego zarezerwowanych. Menedżer pamięci musi być zatem zaimplementowany przez
pewną bibliotekę wgrywaną przez program w czasie startu.

\subsubsection{Wywołanie systemowe \texttt{brk}}

Pierwszym i historycznie najstarszym wywołaniem jądra do przydzielania pamięci
procesowi jest procedura \texttt{brk} i nakładka \texttt{sbrk}.

\vspace{4ex}

\begin{lstlisting}[caption={Prototypy procedur \texttt{brk} i \texttt{sbrk}.}]
int   brk(void *end_data_segment);
void *sbrk(intptr_t increment);
\end{lstlisting}

Procedura \texttt{brk} zmienia położenie wierzchołka sterty na zadany adres, o
ile ma on sens --- w przypadku sukcesu zwraca $0$, w przeciwnym razie zwraca $-1$.

Procedura \texttt{sbrk} przesuwa położenie wierzchołka sterty o zadaną ilość
bajtów przy czym wielkość ta może być ujemna. Zwraca nowy adres wierzchołka
sterty lub adres o wartości $-1$ w przypadku błędu.

Obie funkcje są dostępne w większości systemów uniksowych. Zostały jednak
usunięte ze standardu POSIX.1 i nie należy ich używać, jeśli kod ma być
przenośny między różnymi platformami. Innymi słowy tą metodę pozyskiwania
pamięci uważa się z przestarzałą i nie zaleca jej używania.

Wywołanie \texttt{brk} ma też oczywistą wadę, powodującą nieefektywne
wykorzystanie pamięci. Przypuścmy, że program wykonuje ciąg operacji:

\begin{enumerate}
\item zarezerwuj obszar $A$ o rozmiarze $n$,
\item zarezerwuj obszar $B$ o rozmiarze $m$ o wiele mniejszym niż $n$,
\item zwolnij obszar $A$,
\item zarezerwuj obszar $C$ o rozmiarze $n + m$.
\end{enumerate}

Widać, że każda rezerwacja obszaru będzie musiała przesunąć wierzchołek sterty.
Strony związane z obszarem $A$ nie mogą być zwrócone do systemu i ponownie
wykorzystanie do utworzenia obszaru $C$. Używanie tego mechanizmu do rezerwacji
dużych bloków jest nieefektywne i może powodować powstawanie nieużytków.

\subsubsection{Wywołanie systemowe \texttt{mmap}}

Historycznie nowszą, a jednocześnie zalecaną, metodą rezerwacji i zwalniania
spójnego obszaru stron pamięci stanowią wywołania \texttt{mmap} i
\texttt{munmap}. Zaletą tej metody pobierania pamięci z systemu operacyjnego
jest możliwość skonstruowania lepszej metody radzenia sobie z nieużytkami.
Zmapowany spójny obszar pamięci może być odmapowany fragmentarycznie. Jeśli
tylko pojawi się wystarczająco długi niewykorzystywany obszar rozpoczynający
się w adresie podzielnym przez rozmiar strony, program może go zwrócić do
systemu. 

Poniżej zostaną przedstawione i wyjaśnione parametry procedur dla przypadku
przydziału i zwalniania pamięci wirtualnej.

\vspace{4ex}
\begin{lstlisting}[caption={Prototypy procedur \texttt{mmap} i \texttt{munmap}.}]
void *mmap(void *start, size_t length, int prot,
           int flags, int fd, off_t offset);
int munmap(void *start, size_t length);
\end{lstlisting}

Argumenty procedury \texttt{mmap} posiadają następujące znaczenie w przypadku
żądania o przydział stron procesowi:
\begin{center}
\begin{tabular}{|l|p{0.75\linewidth}|}
\hline
\textsc{argument} & \textsc{znaczenie} \\
\hline
\hline
\verb+start+  & Adres, pod który powinny być zmapowane nowe strony. Jeśli równy
\texttt{NULL}, jądro samo wybierze odpowiednie miejsce w przestrzeni adresowej.
W przeciwnym wypadku będzie starało się wykorzystać ten argument jako początek
mapowania. Zaleca się ustawienie na \texttt{NULL}.\\
\hline
\verb+length+ & Rozmiar bloku pamięci --- musi być podzielny przez długość strony. \\
\hline
\verb+prot+   & Uprawnienia określające dostęp do stron. Jeśli proces chce
czytać i zapisywać do tego obszaru, argument musi mieć wartość
\verb+PROT_READ|PROT_WRITE+. \\
\hline
\verb+flags+  & Flaga \verb+MAP_ANONYMOUS+ powoduje zmapowanie pamięci
wirtualnej zamiast pliku. Zawartość pamięci będzie wyzerowana. \\
\hline
\verb+fd+     & Uchwyt pliku --- obowiązuje jedynie w przypadku mapowania pliku.
Ustawić na $-1$ dla zgodności z innymi systemami. \\
\hline
\verb+offset+ & Wartość ignorowana. \\
\hline
\end{tabular}
\end{center}

W zależności od wartości \texttt{flags} wywołanie \texttt{mmap} może
przydzielać strony o różnych właściwościach. Objawiają się one w momencie
wywołania procedury systemowej \texttt{fork}, która tworzy potomków procesu.

\begin{center}
\begin{tabular}{|l|p{0.75\linewidth}|}
\hline
\textsc{flaga} & \textsc{znaczenie} \\
\hline
\verb+MAP_PRIVATE+ & Mapowanie prywatne. Proces posiada zmapowane strony na
własność. Wykorzystywany jest mechanizm \texttt{copy-on-write}. Jeśli
którykolwiek z potomków lub rodzic będzie chciał zmodyfikować stronę, to
dostanie jej prywatną kopię na własny użytek. \\
\hline
\verb+MAP_SHARED+  & Mapowanie dzielone. Proces dzieli zmapowany obszar pamięci
między wszystkie procesy potomne stworzone. Wszystkie procesy widzą ten sam
obszar pamięci wirtualnej i mogą się przez ten fragment pamięci komunikować. \\
\hline
\end{tabular}
\end{center}

Poniżej zamieszczono listing prostego programu pobierający stronę pamięci z
systemu operacyjnego na własny użytek.

\vspace{2ex}
\begin{lstlisting}[caption={Przykład pobrania i zwolnienia jednej strony.},xleftmargin=3ex,xrightmargin=3ex]
void *area = mmap(NULL, getpagesize(), PROT_READ|PROT_WRITE,
                  MAP_ANONYMOUS|MAP_PRIVATE, -1, 0);

if (area != NULL)
    munmap(area, getpagesize());
\end{lstlisting}

Ważną przewagą wywołania systemowego \texttt{mmap}, w stosunku do \texttt{brk},
jest to, że korzystanie z tej metody pobierania pamięci nie powoduje konfliktów z
menedżerem pamięci znajdującym się w bibliotece \texttt{libc}. Dzięki temu
można w obrębie jednej przestrzeni adresowej korzystać z wielu niezależnych
algorytmów rezerwacji bloków.

\subsection{Fałszywe współdzielenie}

Mikroprocesor wielordzeniowy nie jest już dziś niczym egzotycznym. Kiedyś były
składnikami wyłącznie maszyn pełniących rolę serwerów bądź stacji roboczych do
obliczeń naukowych. Większość architektur wieloprocesorowych lub
wielordzeniowych zakłada dostęp do pamięci systemowej, która jest dzielona
między procesorami. Procesory wykorzystują część pamięci na własne obliczenia,
część przeznaczają na wymianę danych między sobą, czy komunikację i synchronizację.
Każdy procesor posiada również własną pamięć podręczną.

Może się zdarzyć, że procesory będą chciały się ze sobą skomunikować przy
pomocy pewnego fragmentu pamięci. Proces taki pociąga za sobą wymianę linii
pamięci podręcznej między rdzeniami. Dostęp przez dwa procesory do komórki
pamięci $n$, która przechowuje pewną strukturę, może mieć następującą postać:

\begin{enumerate}
\item procesory $A$ i $B$ przechowują we swoich pamięciach podręcznych
bieżącą zawartość $n$,
\item procesor $A$ przygotowuje dane dla $B$ i aktualizuje zawartość $n$,
\item protokół uspójniania pamięci podręcznej informuje $B$, że posiada
nieaktualną wersję linii zawierającej $n$,
\item $B$ żąda odczytu komórki $n$,
\item $A$ synchronizuje zawartość linii przechowującej $n$ z pamiecią
systemową,
\item $B$ pobiera linię przechowującą $n$ do swojej pamięci podręcznej,
\item $B$ posiada aktualną wersję linii przechowującej $n$ i może operować na
jej zawartości.
\end{enumerate}

Proces ten jest dość czasochłonny, ale w przypadku komunikacji
międzyprocesorowej niezbędny.

Może się jednak zdarzyć, że jedna linia pamięci podręcznej przechowuje kilka
struktur, lecz nie służą one do wymiany danych między procesorami --- są
prywatnymi danymi pewnych wątków obliczeń działających na odrębnych procesorach.
Zjawisko takie określa się mianem fałszywego współdzielenia (ang. \textit{false
sharing}). Jest ono bardzo niepożądane, a w przypadku kiedy obejmuje duże
obszary pamięci, prowadzi do poważnego obniżenia wydajności związanego z
masowym przepływem danych między pamięciami podręcznymi procesorów. Sytuację
taką określa się mianem zaśmiecania pamięci podręcznej (ang. \textit{cache
trashing}), które, w dosłownym tego słowa sensie, rujnuje wydajność programu
działającego na architekturze wieloprocesorowej.

\subsection{Synchronizacja}

Sposób synchronizacji między poszczególnymi ścieżkami wykonania kodu może być
realizowany na wiele sposobów. Używane do tego instrumenty mogą się różnić
wydajnością i elastycznością. Podstawowym środkiem służącym do synchronizacji
wątków czy procesów są blokady, które mogą nakazywać systemowi operacyjnemu
wywłaszczenie programu i tym samym użycie mocy obliczeniowej na inne zadania.
Blokady używa się do obrony zasobów przed modyfikacją przez więcej niż jedną
ściężkę wykonania kodu. Zwrócenie sterowania do jądra systemu jest opłacalne,
jeśli przewiduje się, że program będzie oczekiwał na zwolnienie blokady przez
dłuższy moment czasu. Odpowiedni dobór środków synchronizacji przy konstrukcji
alokatora mającego działać w środowisku wielowątkowym może mieć dużym wpływ na
jego wydajność.

\paragraph{Semafory POSIX.} Są środkiem do synchronizacji wielu procesów w
systemach zgodnych ze standardem \texttt{POSIX}. Występują w dwóch formach --
jako semafory z nazwą i semafory anonimowe. Druga forma może posłużyć jako
forma synchronizacji między procesami tylko, jeśli semafor anonimowy umieści
się w pamięci dzielonej. Pełna implementacja tego mechanizmu jest dostępna w
systemie \texttt{Linux} od wersji 2.6. Semafory \texttt{POSIX} w przypadku
wykrycia blokady wywłaszczają program.

\paragraph{Semafory binarne dla wątków POSIX.} (ang. \textit{pthread mutexes})
Są środkiem synchronizacji między wątkami. W systemie \texttt{Linux} są
zaimplementowane przy użyciu wywołania systemowego \verb+futex(7)+ --- podobnie
jak semafory \texttt{POSIX}. Dzięki temu część operacji (np.: sprawdzenie stanu
blokady) przebiega w przestrzeni użytkownika i jest stosunkowo szybka. W
przypadku blokady sterowanie jest kierowane do systemu operacyjnego. 

\paragraph{Blokady pętlowe.} (ang. \textit{spin locks}) Są używane tam, gdzie
programista spodziewa się szybkiego zwolnienia blokady. Taka sytuacja może się
często zdarzać dla systemów wieloprocesorowych, kiedy chronione zasoby są
niewielkich rozmiarów. W takim przypadku opłaca się przeczekać kilkadziesiąt
nawet do kilkuset cykli procesora w przestrzeni użytkownika. Koszt
wywłaszczenia programu jest o wiele większy. Blokady pętlowe są bezużyteczne w
przypadku systemów z jednym procesorem i należy ich unikać.

\paragraph{Atomowe instrukcje procesora.} Do realizacji blokad pętlowych
niezbędne są instrukcje procesora, które dają gwarancję wyłącznego dostępu do
wybranych lokacji w pamięci. Najczęściej spotykanymi atomowymi operacjami są:
\texttt{test-and-set}, \texttt{compare-and-swap}, \texttt{fetch-and-add}.
Znajdują one także zastosowanie przy budowie równoległych struktur danych bez
blokad (ang. \textit{lock free}).

\paragraph{Mechanizm konstruowania obiektów synchronizacji w przestrzeni
użytkownika.} Celem zwiększenia wydajności operacji na semaforach programiści
systemu \texttt{Linux} wprowadzili w wersji 2.6 nowe wywołanie systemowe
\verb+futex(7)+ (ang. \textit{Fast Userspace muTexes}). Główną motywacją do
stworzenia tego wywołania było przerzucenie odpowiedzialności na program
użytkownika za obsługę części operacji na semaforach --- a tym samym
zmniejszenie ilości wywołań systemowych, które są stosunkowo kosztowne. Przy
okazji \texttt{Linux} zyskał potężne narzędzie do konstrukcji dowolnych
obiektów służących do synchronizacji wątków i procesów. Przy pomocy procedury
\verb+futex(2)+ można np.: napisać hybrydową wersję blokowania, która przez
pewien okres czasu czeka na zwolnienie zasobu w przestrzeni użytkownika i w
przypadku przekroczenia limitu czasowego oddaje sterowanie do przestrzeni
jądra.

\newpage

% --=[ Omówienie klasycznych mechanizmów ]=-------------------------------------

\section{Klasyczne mechanizmy}
\hypertarget{Klasyka}{}

Istnieje szereg schematów zarządzania pamięcią o dobrze zbadanych
właściwościach. Można je potraktować jako punkt wyjściowy do tworzenia
hybrydowych menedżerów pamięci.

Do głównych zadań algorytmu alokatora należy wyznaczanie pozycji bloków przy
próbie minimalizacji efektu fragmentacji. Wybór adresu początku bloku jest
jedyną decyzją jaką może podejmować menedżer pamięci. Sposób w jaki to robi
nazywa się \textit{polityką wyznaczania położenia bloku}. Projektowanie
menedżera pamięci składa się z trzech etapów:

\begin{description}

\item[Nakreślenie strategii.] \textit{Strategia} określa cele jakie mają być
spełnione w ramach pewnej \textit{polityki}. \textit{Strategia} może być
idealistyczna i brzmieć np.: ``wyznaczaj pozycję bloków w takich sposób, by ich
rezerwacja nie indukowała fragmentacji w trakcie kolejnych operacji
alokatora'', co z natury \textit{on-line} algorytmu zarządzania pamięcią jest
nieosiągalne.  \textit{Strategia} może powstać w wyniku obserwacji
rzeczywistych ciągów operacji dla alokatora.

\item[Określenie polityki.] \textit{Polityka} jest w pewnym sensie
skonkretyzowaną instancją starającą się zaspokoić cele wyznaczone przez
\textit{strategię}. Może być to pseudokod lub inna forma myśli dająca się
przekształcić bezpośrednio w \textit{mechanizm}. W wyniku skonkretyzowania
pewne właściwości \textit{strategii} mogą zostać porzucone, jako zbyt kosztowne
lub zbyt skomplikowane by zawrzeć jej koncepcje w \textit{polityce}.

\item[Implementacja mechanizmu.] \textit{Mechanizmem} można określić kompletny
algorytm spełniający specyfikację wyznaczoną przez pewną \textit{politykę
wyznaczania pozycji bloku}. \textit{Mechanizm} to zbiór struktur danych i
operacji na nich służących do przydzielania i zwalniania bloków pamięci.
Programista wykorzystuje \textit{mechanizm} odwołując się do niego poprzez
pewien określony interfejs.

\end{description}

\subsection{Listy wolnych bloków}

Najczęściej wykorzystywanym mechanizmem wśród menedżerów pamięci są warianty
listy wolnych bloków. Z reguły listy są organizowane w pamięci używając
techniki znaczników granicznych (ang.  \textit{boundary tags}) opisane przez
Knutha w książce \cite{knuth73fundamental}. Znaczniki są częścią bloku --- leżą
bezpośrednio przed adresem zwracanym przez procedurę rezerwującą blok.
Znaczniki to rekord przechowujący co najmniej wielkość bloku i flagę zajętości.
Kiedy blok jest wolny bezpośrednio za zacznikami, a czasem również na samym
końcu, przechowywane są pola struktury utrzymującej porządek wolnych bloków
według zasad określonych przez pewną politykę. Najczęściej wykorzystywaną
strukturą danych jest lista dwukierunkowa, która niestety wypada bardzo źle pod
względem wydajności. Ponieważ znaczniki poszczególnych bloków są od siebie
znacznie oddalone, lokalność odwołań do pamięci jest dość znikoma --- powodując
znacznie obciążenie przepustowości szyny danych. Dodatkowo menedżer używający
listy może wymagać liniowego czasu względem ilości wszystkich bloków do
wykonania operacji przydziału lub zwolnienia.

Celem poprawienia czasu działania poszczególnych żądań zamiast list
dwukierunkowych stosuje się np. drzewa kartezjańskie opisane w pracy
\cite{vuillemin80unifying}. Są to drzewa, które są uporządkowane dwuwymiarowo.
Utrzymują porządek kopcowy ze względu na wielkość bloku, a porządek
\textit{in-order} ze względu na adres początku bloku. Pierwszy alokator
wykorzystujący te drzewa został opisany w pracy \cite{stephenson83fastfits}.

Tam gdzie porządek względem adresów nie jest konieczny, interesującym wydaje
się być wykorzystanie zbalansowanych drzew. Przemawia za tym niewielka
pesymistyczna złożoność czasowa operacji wyszukiwania i tym samym zmniejszenie
ilości odwołań do komórek, które z dużym prawdopodobieństwem znajduje się poza
pamięcią podręczną. Słabo zbadaną strukturą danych pod względem wykorzystania w
alokatorach pamięci jest \textit{splay tree}, która może się bardzo dobrze
sprawować w praktyce.

\paragraph{Podział i scalanie.} Są to techniki, które służą kontroli do
fragmentacji. Przypuśćmy, że znaleziony przez algorytm wolny blok jest dużo
większy od żądanego rozmiaru. Alokator może wtedy podzielić blok na dwie
części. Pierwszą część może wtedy zwrócić jako żądany blok, a drugą wstawić na
listę wolnych bloków. Kiedy menedżer dostaje pewien blok do zwolnienia, może
zadecydować, aby scalić go z okolicznymi wolnymi blokami. \textit{Podział i
scalanie} są przedmiotem rozmaitych polityk np.:

\vspace{-1ex}

\begin{description}
\item[Polityka buforowania.] Wynika z następującej strategii: ``jeśli program
zwolnił obszar o rozmiarze $n$, to być może zaraz będzie potrzebował bloku o
identycznym rozmiarze''. Strategia ta może się przyczynić do zwiększenia
wydajności alokatora w przypadku operacji intensywnie modyfikujących
dynamiczną strukturę danych, a wymagającą użycia menedżera pamięci. Polityka do
zrealizowania tej strategii polega na zorganizowania bufora, do którego na
jakiś okres czasu trafiają zwolnione bloki. Jeśli blok nie został w określonym
czasie zarezerwowany to trafia na listę wolnych bloków i zostaje scalony.
Polityka taka gwarantuje zapobiega swego rodzaju ``czkawce'' polegającej na
częstym scalaniu i podziale tego samego bloku. Dodatkowo polityka ta sprzyja
lokalności odwołań do pamięci, gdyż z dużym prawdopodobieństwem ostatnio
zwolnione bloki znajdują się w pamięci podręcznej procesora.
\vspace{1ex}

\item[Polityka gorliwego podziału.] Motywowana jest strategią brzmiącą: ``jeśli
program zrezerwował blok o niewielkim rozmiarze $n$, to najprawdopodobniej
zaraz będzie żądął bloku o podobnym rozmiarze''. Strategia taka sprawdza się w
przypadku, kiedy program szybko buduje dużą strukturę danych. Polityka
relizująca tą strategię zapewnia, że przy żądaniach o odpowiednim rozmiarze
(dla struktur o rozsądnym rozmiarze rekordu) zostanie znaleziony odpowiednio
większy wolny blok pamięci. Zostanie on podzielony na pewną ilość wolnych
bloków o żądanym rozmiarze. Pierwszy z tych bloków zostanie zwrócony jako
rezultat operacji \texttt{malloc}, a reszta trafi do podręcznego bufora
alokatora, omówionego w \textit{polityce buforowania}. Technika ta została
użyta w dlmalloc \cite{douglea96malloc} i określana jest tam mianem
\textit{pre-splitting}. Dokładniejszy opis implementacji takiej strategii można
znaleźć w pracy \cite{weinstock88quickfit}.
\vspace{1ex}

\item[Polityka leniwego scalania.] Może być wynikiem stosowania następującej
strategii: ``wykorzystuj moc obliczeniową tylko wtedy, kiedy jest to
rzeczywiście potrzebne''. Polityka wynikająca z tej strategii może np. scalać
tylko wtedy, kiedy uzna że wolne bloki po scaleniu mogą posłużyć do spełnienia
żądania. Może też po prostu odraczać scalanie bloków do kolejnej operacji
przydziału pamięci, które być może musi przejrzeć wszystkie pozycje na liście.
\end{description}

\paragraph{Best-fit.}

Polityka \textit{best-fit} --- czyli polityka najlepszego dopasowania --- polega
na przydzielaniu takiego bloku, którego rozmiar jest najmniejszym możliwym
spełniającym żądanie \texttt{malloc}. Mimo, że teoretycznie jest to polityka
powodująca największą fragmentację, to w praktyce nie obserwuje się takich
anomalii. Na dodatek jej stosowanie często powoduje mniejszą fragmentację niż
\textit{first-fit} o lepszych teoretycznie właściwościach. Polityka
\textit{best-fit} wynika z następujących dwóch strategii:
\vspace{-1ex}

\begin{description}
\item[Strategia minimalizacji pozostałości.] Mimo, że brzmi mało konkretnie i
nie jest jasne czemu dokładnie ma służyć, to przyczyniła się do powstania wielu
istotnych polityk. \textit{Best-fit} spełnia założenia tej strategii. Zauważmy,
że wybór najmniejszego możliwego bloku, a następnie jego podział na część
mającą posłużyć jako rezultat operacji \texttt{malloc}, implikuje powstanie
pewnego obszaru za przydzielonym blokiem (o ile znaleziony wolny blok nie jest
dokładnie tych samej wielkości co żądany). Obszar ten, będący pozostałością po
podziale, jest najmniejszym z możliwych jakie mogły powstać. Zatem jeśli się
okaże, że został nieużytkiem, to będzie miał minimalny rozmiar.
\vspace{1ex}

\item[Strategia ochrony dużych obszarów.] Służy polityce, która preferuje
dzielić bloki w obszarach, które w przyszłości nie będą mogły być elastycznie
używane.
\end{description}

\paragraph{First-fit.}

Polityka pierwszego dopasowania (ang. \textit{first-fit}) polega na
przydzieleniu pierwszego bloku, który spełnia rozmiar żądania. Reszta powstała
w wyniku podziału znalezionego bloku zostaje wstawiona na listę wolnych bloków.
Wadą tej polityki jest tendencja do generowania dużej ilości małych bloków na
samym początku listy i w efekcie długi czas wyszukiwania dużych bloków.

\paragraph{Polityka, a porządek listy wolnych bloków.}

W przypadku obu polityk wyboru położenia bloku (tj. \textit{best-fit} i
\textit{first-fit}) fregmentacja, którą powstaje w wyniku działania alokatora
w istotny sposób zależy od tego, w jaki sposób zorganizowany jest porządek na
liście wolnych bloków. W pracy \cite{johnstone98memory} przeprowadzono
gruntowne badania nt.  fragmentacji dla porządku \texttt{AO} (ang.
\textit{address ordered}), \texttt{FIFO}\footnote{Porządek kolejkowy --
pierwszy na wejściu, pierwszy na wyjściu.} (ang.  \textit{first in, first
out}), \texttt{LIFO}\footnote{Porządek stosowy --- ostatni na wejściu, pierwszy
na wyjściu.} (ang.  \textit{last in, first out}). Okazuje się, że praktycznych
zastosowaniach polityka \textit{best-fit} w połączeniu z listą uporządkowaną
względem adresów lub stosowo charakteryzuje się najmniejszą fragmentacją.
\vspace{-1ex}

\begin{description}

\item[Porządek LIFO.] Lista bloków przechowuje na początku ostatnio zwolnione
bloki. W łatwy sposób można rozszerzyć ten pomysł o właściwości
\textit{polityki buforowania}, jeśli tylko nie będzie się scalać pewnej ilości
bloków z początku listy. Polityka ta charakteryzuje się dużą lokalnością
odwołań. Ponieważ na czele listy znajdują się ostanio używane bloki, to z dużym
prawdopodobieństwem znajdują się one również w pamięci podręcznej procesora.

\vspace{1ex}

\item[Porządek FIFO.] Ostatnio zwolnione bloki będą umiejscawiane na końcu
kolejki. Cały zarządzany obszar będzie cyklicznie przeglądany. Trudno
stwierdzić praktyczną przydatność takiej polityki. Wydaje się ona być mało
interesująca ze względu na niską lokalność odwołań i empirycznie udowodnioną
dużą fragmentację.

\vspace{1ex}

\item[Porządek AO.] Lista jest uporządkowana w naturalny sposób --- względem
adresu początku bloków. Polityka ta zdradza tendencję do umieszczania zajętych
bloków w obrębie początku zarządzanego obszaru. Charakteryzuje się dobrym
zachowaniem lokalności i małą fragmentacją w przypadku, kiedy zwalnianie bloki
tworzą spójny obszar pamięci. Oszacowanie fragmentacji w przypadku śmierci
dużej ilości obiektów nierównomiernie rozmieszczonych w pamięci nie jest dobrze
zbadane.
\end{description}

\subsection{Posegregowane listy wolnych bloków}

Prostym i efektywnym rozszerzeniem mechanizmu omówionego w poprzednim punkcie
jest tablica list. Każdy element takiej tablicy przechowuje wskaźnik do listy
wolnych bloków o określonej wielkości. Kiedy blok jest zwalniany umieszcza się
go na liście odpowiadającej rozmiarowi zwalnianiego bloku. Kiedy program chce
zarezerwować pamięć, wtedy bloków o żądanej wielkości szuka się na odpowiedniej
liście. Jeśli lista jest pusta, to alokator przy pomocy odpowiednich działań
musi pobrać wolną pamięć, stworzyć nowe bloki i uzupełnić pustą listę.  Należy
jeszcze zauważyć, że o ile bloki z danej listy są uporządkowane względem
wielkości, to wcale nie muszą zajmować spójnego obszaru pamięci.

Z oczywistych względów tablica przechowująca wskaźniki nie może być zbyt duża.
Dlatego ogranicza się liczbę dopuszczalnych wielkości bloków. Do danej listy
przyporządkowuje się wszystkie żądania z danego przedziału wielkości,
zaokrąglając żądany rozmiar w górę. Niestety, przyczynia się to do zwiększenia
fragmentacji wewnętrznej. Z tego względu mechanizmu tego nie stosuje się do
obsługi wszystkich żądań, a tylko z zadanego przedziału wielkości --- z reguły
od kilkudziesięciu bajtów do kilkunastu kilobajtów.

\begin{description}
\item[Wersja uproszczona.] Nie angażuje ona procedur podziału i scalania
bloków do ograniczania problemu fragmentacji. Gdy na danej liście zabraknie
bloków, to alokator pobiera spójny obszar o długości kilku stron od systemu
operacyjnego, dzieli je na wolne bloki i wstawia na listę. Warto zauważyć, że
takie działanie zwalnia alokator z obowiązku pamiętania długości bloku w
obszarze przez niego zajmowanym. Zamiast tego, wielkość można przypisać do
obszaru okupowanego przez bloki o danym rozmiarze. Jest w miarę oczywiste, że
polityka taka prowadzi do implementacji szybkiego algorytmu --- zarówno w
trakcie przydziału jak i zwalniania pamięci koszt jest stały. Wadą tego
podejścia jest potencjalnie duża fragmentacja, która nie podlega kontroli.
Pewnym podejściem do ograniczenia problemu fragmentacji jest sprawdzanie, czy w
obszarze zajmowanym przez bloki danej wielkości istnieje co najmniej jedna
nieużywana strona. Można ją wtedy wyciągnąć z tego obszaru i użyć do
uzupełnienia listy bloków o innym rozmiarze.
\vspace{1ex}

\item[Wersja pełna.] Zasadnicza różnica między wersją pełną, a uproszczoną,
tkwi w metodzie tworzenia nowych bloków. Kiedy lista przechowująca bloki o
rozmiarze z danego zakresu jest pusta, przeszukuje się listę dla bloków o
większym rozmiarze. Jeśli tam znajdzie się blok to zostaje on podzielony.
Powstałe w wyniku podziału mniejsze bloki umieszcza się na odpowiednich
listach. W trakcie zwalniania bloku następuje jego scalenie z sąsiadami i
umieszczenie na odpowiedniej liście. Łączenie jest operacją kosztowną i może
prowadzić do tzw. ``czkawki'', dlatego zazwyczaj stosuje się \textit{politykę
leniwego scalania}. W przeciwieństwie do wersji uproszczonej, bloki o
określonym zakresie rozmiaru mogą zajmować dowolne obszary pamięci.  Warto
zauważyć, że mechanizm ten aproksymuje politykę \textit{best-fit}, niezależnie
od polityki stosowanej względem poszczególnych list.

\end{description}

\subsection{Inne algorytmy}

Wiele algorytmów zarządzania pamięcią jest efektem modyfikacji mechanizmów
przedstawionych w poprzednich punktach. Często dokonywanymi zmianami jest
stosowanie struktur danych pozwalających skrócić czas poszukiwania bloku o
określonych właściwościach. Istnieją jeszcze dwa mechanizmy istotnie różne od
omówionych wcześniej i warte komentarza:

\begin{description}

\item[Systemy partnerskie.] Znane jako \textit{buddy system}, są szczególnym
wariantem list wolnych bloków implementujących efektywną, lecz ograniczoną
formę scalania i podziału. Na $i$-tej liście przechowywane są bloki, których
długość jest sumą wielkości bloków z poprzednich list --- zazwyczaj z
$(i-1)$-tej. Szybki podział i scalanie opierają się na prostym sposobie
wyznaczania pozycji bloków, operującym jedynie na wartości adresów.  Bloki o
danej wielkości muszą mieć adres podzielny przez określoną wielkość.  Scalanie
odbywa się jedynie na przyległych blokach o takim samym rozmiarze --
określanych mianem partnerów lub bliźniaków. Adres pierwszego bloku musi być
podzielny przez rozmiar bloku, który powstałby w wyniku scalenia bliźniaków.
Intuicyjnie patrząc --- przestrzeń zarządzana przez \textit{buddy system} jest w
rekurencyjnie podzielona na dwie części o ustalonych rozmiarach --- najczęściej
są to potęgi dwójki. Efektywną implementację binarnych systemów bliźniaczych
zaprezentowano w pracy \cite{demaine99fast}.

\vspace{1ex}

\item[Mapy bitowe.] Mapa bitowa (ang. \textit{bitmap}) jest wektorem bitów.
Każdemu bitowi można przypisać odpowiedzialność za stan danego bloku z obszaru
odpowiadającemu wektorowi. Metodę tą rzadko się spotyka w alokatorach pamięci
mimo, że w niektórych przypadkach mogłyby pomóc redukować fragmentację
wewnętrzną. Mapy bitowe mogłyby też posłużyć do zwiększania lokalności
odwołań, poprzez umieszczenie informacji o zajętości bloków w jednym
obszarze pamięci.

\end{description}

\newpage

% --=[ Testowanie właściwości ]=------------------------------------------------

\section{Testowanie}
\hypertarget{Testowanie}{}

W trakcie omawiania alokatorów w poprzednich rozdziałach często padało
stwierdzenie, że pewnych teoretycznych właściwości menedżerów pamięci nie
obserwuje się w praktyce. Istnieje duża rozbieżność między tym w jaki sposób
zachowują się alokatory w rzeczywistych zastosowaniach i pesymistycznymi
przypadkami określonymi przez teorię. Warto zwrócić uwagę na to, że często
proste modyfikacje, czy dodatkowe heurystyki, potrafią całkowicie zmienić
właściwości teoretyczne menedżera pamięci. Trudno powiedzieć z czego wynika tak
duża rozbieżność. Może to mieć źródło w fakcie, że w istocie alokatory są zbyt
skromnie przebadane od strony teoretycznej. Może to wynikać z braku dobrze
zdefiniowanych środków do modelowania pewnych zachowań.  Menedżery pamięci to z
reguły algorytmy hybrydowe inaczej traktujące poszczególne wielkości bloków --
ze względu na to ich teoretyczna analiza może okazać się bardzo kłopotliwa i
nader skomplikowana. Ostanim i najbardziej prawdopodobnym wyjaśnieniem rozważanej
rozbieżności jest to, że przekrój programów wykorzystujących menedżery pamięci
zachowuje się w mało losowy sposób, za który odpowiadają pewne wzorce
programistyczne.

\subsection{Badane właściwości}

Menedżery pamięci warto i należy intensywnie badać. Istnieje duża gama zachowań
programów korzystających z alokatorów. Można się spodziewać, że będą istotne
różnice we wzorcach wykorzystania tych algorytmów w przypadku: aplikacji z
interfejsami graficznymi, serwerów usług sieciowych, programów do obliczeń
naukowych, aplikacji do modelowania geometrii, itd. Dobry ogólny menedżer
pamięci powinien sprawować się dobrze w każdym z tych przypadków.

Złą wiadomością jest to, że algorytmy alokatorów są bardzo ciężkie do analizy
w~praktyce. Fragmentację należy mierzyć na pewnym zbiorze programów. Niestety
nie ma ustalonego korpusu, który byłby standardem do porównywania wyników.  W
artykułach poruszających tematykę wydajności i fragmentacji często pojawiają
się te same programy służące do pomiarów, jednak część z nich nie jest
publicznie dostępna lub jest płatna. Trudno też uznawać ten zbiór za
reprezentatywny.

Kolejnym problemem jest fakt, że badanie alokatorów ze względu na wydajność
traci sens, jeśli wydzielić je ze środowiska lub programu, w którym działają.
Efektywność aplikacji w dużym stopniu zależy od tego, jak alokator rozmieści
bloki w pamięci. Lokalność referencji to na tyle istotne zagadnienie, że
programista świadomie i poprawnie posługujący się mechanizmami współczesnych
procesorów jest w stanie przyśpieszyć swój program nawet o rząd wielkości.
Menedżer pamięci powinen maksymalizować lokalność odwołań, zwalniając
programistę z pamiętania o niskopoziomowych aspektach związanych z hierarchią
pamięci.

Przed wdrożeniem kompletnego menedżera pamięci do szerszego zastosowania należy
go gruntownie przetestować pod względem poszczególnych właściwości:

\paragraph{Poprawność.} Alokator w pełni odpowiada za bloki pamięci, które
przydziela i zwalnia. Każdy błąd w menedżerze bezpośrednio oddziałuje na
program, który z niego korzysta. W związku z tym algorytm musi być intensywnie
przetestowany względem wszystkich przypadków na jakie pozwala semantyka
operacji rezerwowania i zwalniania bloku. Niedopuszczalne jest, by narażać
programy korzystające z menedżera na utratę danych. Alokatory są klasą
algorytmów, którą wyjątkowo ciężko się odpluskwia. Nie można zdać się na
narzędzia do znajdowania błędów odwołań do pamięci, bo w większości przypadków
działają one jako nakładka przechwytująca wywołania procedur \texttt{malloc} i
\texttt{free}. Poprawność można badać przy pomocy testów losowych --- jest wtedy
pewność, że w dość krótkim czasie zostaną osiągnięte stany, które w praktyce
zdarzają się niezwykle rzadko. Taki typ błędów jest szczególnie niebezpieczny,
gdyż za usterkę z reguły obwinia się wtedy nie alokator, a~program z niego
korzystający.

\paragraph{Fragmentacja.} Pamięć RAM w dzisiejszych czasach jest zasobem
stosunkowo tanim. Niemniej trzeba go wykorzystywać z rozsądkiem --- wydaje się,
że straty większe niż 10\% --- 15\% są już martnorawstwem. Fragmentacja była
zawsze głównym celem badań alokatorów i często minimalizowano ją kosztem
wydajności. Ze względów ekonomicznych w dzisiejszych czasach można już kłaść na
to mniejszy nacisk. Istnieje dość szeroki wachlarz publicznie dostępnych
programów, którymi porównuje się menedżery pamięci --- aplikacje te zostaną
omówione w kolejnym podrozdziale. Fragmentację można mierzyć na różne sposoby:

\begin{enumerate}

\item Wyznacza się stosunek największego wolnego bloku do sumy wszystkich
wolnych bloków. Podaje się minimum tej wartości na przestrzeni czasowej
wykonania programu. Im bliższy jedności ten stosunek, tym większa część wolnej
pamięci jest skumulowana w pojedynczym bloku.

\vspace{1ex}

\item Na całej przestrzeni czasowej programu wyznacza się stosunek dwóch
wartości --- maksymalnej wielkości bloków będących w użyciu i maksymalnej ilości
pamięci używanej przez alokator. Obliczane maksima mogą przypadać na różne
chwile. Wyznaczona wartość daje orientacyjne pojęcie o efektywności użycia
pamięci w najbardziej obciążającym momencie.

\end{enumerate}

Inne sposoby mierzenia fragmentacji, wraz z argumentacją na temat ich
użyteczności, zostały dokładnie omówione w pracy \cite{johnstone98memory}.
Problem fragmentacji w systemach komputerowych ze stronicowaniem ma nieco inną
specyfikę niż w rozważaniach teoretycznych. Najmniejszą jednostką pamięci jaką
otrzymuje alokator od systemu to strona --- obszar o długości 4\texttt{KiB}.
Dopóki istnieje co najmniej jeden używany blok wewnątrz strony, to nie może być
ona zwolniona.  Dochodzi wtedy do sytuacji, gdzie pojedynczy nawet bardzo mały
blok powstrzymuje alokator przed zwolnieniem całkiem dużego obszaru. Warto
rozszerzyć testy uwzględniając właśnie takie anomalie. W pracy na temat
menedżera pamięci \texttt{jemalloc} \cite{evans06scalable} zastosowano ciekawą
metodę wizualizacji użycia przestrzeni adresowej programu przez alokator
pamięci.

\paragraph{Wydajność.} W inżynierii oprogramowania często spotyka się
stwierdzenie, że za 90\% czasu wykonania programu odpowiada 10\% kodu. Nie musi
być to prawdą, jednak słaba wydajność menedżera pamięci może przyczyniać się do
powstawania tak negatywnego efektu. Dzisiejsze programy wykorzystują alokatory
bardzo intensywnie --- wywołując procedury \texttt{malloc} i \texttt{free} setki
tysięcy, czy nawet miliony razy na sekundę. Optymalizacja szybkości menedżera
pamięci wymaga głębokiej wiedzy na temat architektury sprzętowej pamięci oraz
systemu operacyjnego. Wydajność można mierzyć kierując się różnymi kryteriami:

\begin{enumerate}

\item Czas poświęcony na wykonanie procedur \texttt{malloc} i \texttt{free}.
Można mierzyć czas zamortyzowany, minimalny i maksymalny. Sensowna wydaje się
być też klasyfikacja wyników w zależności od wielkości przetwarzanych bloków.
Niestety takie pomiary dają jedynie zgrubny obrazu wydajności menedżera, gdyż
jak zostało wspomniane wcześniej, alokator ma wpływ na szybkość działania
programu również poprzez wybór rozmieszczenia przydzielanych bloków. Zostanie
to dokładniej wyjaśnione przy testowaniu lokalności.

\vspace{1ex}

\item Ilość czasu spędzanego na obsługę blokad w przypadku środowisk
wielowątkowych. Cykle procesora zużyte w oczekiwaniu na zwolnienie blokady to
zmarnowana moc obliczeniowa. Jeśli wątek poprosi system operacyjny o
wywłaszczenie, to czas poświęcony na przełączenie kontekstu jest również czasem
zmarnowanym. Powinno się go mierzyć i w miarę możliwości minimalizować poprzez
zwiększenie separacji wątków oraz implementację struktur danych bez blokad tam,
gdzie współbieżność jest nie do uniknięcia.

\vspace{1ex}

\item Ilość wywołań systemowych i spędzony w nich czas. Kiedy program
gwałtownie zaczyna rezerwować lub zwalniać pamięć może zachodzić potrzeba
pobierania lub oddawania stron do systemu operacyjnego. Każde wywołań takich
jak \texttt{mmap} lub \texttt{munmap} jest kosztowne i w niewielkim stopniu
zależy od ilości stron, którymi się zajmuje. Alokator powinien minimalizować
ilość wywołań systemu operacyjnego gorliwie rezerwując nowe strony i leniwie
zwalniająć nieużywane.

\vspace{1ex}

\item Czas wykonania ustalonego zbioru programów używających danego alokatora.
Jest to najlepszy sposób na sprawdzenie wydajności menedżera pamięci. Takie
testy mają oczywiście tylko wtedy sens, jeśli programy intensywnie używają
procedur \texttt{malloc} oraz \texttt{free} wykorzystując szeroką gamę wzorców
zachowań.

\end{enumerate}

\paragraph{Lokalność.} Współczesne procesory pod względem wydajności faworyzują
dostęp do danych będacych w zbitkach. Paradoksalnie może się zdarzyć, że
program wykorzystujący wolniejszy, ale staranniej wybierający bloki alokator,
może działać szybciej niż menedżer nie wykorzystujący zjawiska lokalności
referencji. Testowanie omawianej właściwości opiera się na uruchomieniu
programów testowych w środowisku wirtualnej maszyny, która będzie badać dostępy
do pamięci symulując działanie pamięci podręcznych, mechanizmu stronicowania,
itd. Takim narzędziem dla procesorów \textit{Intel x86} może być program
\texttt{valgrind} z nakładką \texttt{cachegrind}, działający pod kontrolą
systemu \texttt{Linux}. 

\begin{description}

\item[Pamięć podręczna.] Efektywność wykorzystania pamięci podręcznej mierzy
się zliczając ilość \textit{cache miss}, które wymagają komunikacji procesora z
wolniejszą pamięcią RAM. Minimalizację tego parametru można osiągnąć poprzez
umieszczanie często wykorzystywanych bloków w możliwie jak najmniejszej ilości
linii. W szczególności nie można pozwolić na to, by małe rekordy leżały na
granicy dwóch linii. Warto zwrócić uwagę na to, że współczesne procesory mają z
reguły dwa rodzaje pamięci podręcznej różniące się długością \textit{cache line} i
organizacją danych.

\vspace{1ex}

\item[Stronicowanie i warunki niskiej dostępności pamięci fizycznej.] W
rozdziale \ref{CacheMemory} zostało omówione zjawisko \textit{TLB miss}.
Występuje ono rzadziej niż \textit{cache miss} jednak ma o wiele większy wpływ
na wydajność. Lokalność w wykorzystaniu stron nabiera szczególnego znaczenia w
przypadku, kiedy system operacyjny posiada mało pamięci fizycznej i często musi
korzystać z pamięci zewnętrznej wyrzucając lub sprowadzając strony. Jeśli
aplikacja intesywnie operuje na pewnej strukturze danych, a alokator
niepotrzebnie ją rozrzuci po pamięci, to czas spędzony na wymianę stron może
drastycznie ograniczyć wydajność. Zagadnienie to zostało dokładniej omówione w
pracy \cite{feng05localityimproving}.

\end{description}

\paragraph{Skuteczność w wykrywaniu błędów.} Wiszące wskaźniki, próba dostępu
do zwolnionych już bloków, wyjechanie poza granice tablicy, czy inne błędy
związane z dostępem do pamięci, to jedne z najczęściej spotykanych usterek w
programach. Dobry alokator pamięci powinen wykrywać lub ułatwiać wykrycie
takich nieprawidłowych zachowań. Menedżer pamięci może udostępniać procedury
sprawdzające spójność jego struktur danych. Celem uniknięcia błędów w trakcie
zwalniania lub rezerwacji bloku menedżer może wykonywać ograniczone sprawdzanie
poprawności przeglądanych obszarów pamięci. Warto, żeby umiał wykrywać próby
kilkukrotnego zwolnienia tego samego bloku. Często spotykaną dodatkową funkcją
menedżera pamięci jest czyszczenie zwolnionych, a jeszcze nie oddanych do
systemu operacyjnego obszarów ustaloną wartością np.  \verb+0xDEADC0DE+.
Ułatwia to wykrycie sytuacji, gdzie programista odczytuje zawartość zwolnionego
bloku. Podsumowując --- menedżer pamięci powinien być nie tylko zbiorem
procedur, ale również posiadać cechy narzędzia programistycznego.

\subsection{Narzędzia wspomagające testowanie.}

\paragraph{Valgrind.} Jest to wirtualna maszyna z kompilacją \texttt{JIT} (ang.
\textit{just-in-time}) stworzona z myślą o analizie dynamicznej programów.
\textit{Valgrind} tłumaczy kod programu do postaci pośredniej, niezależnej od
procesora. Następnie przekształca kod pośredni w odpowiedni sposób, a następnie
kompiluje to do kodu maszyny. Przekształcanie odbywa się przy pomocy
odpowiednich wtyczek. Każda z nich analizuje kod pośredni i wstrzykuje w niego
instrukcje realizujące odpowiednie funkcje. Jednymi z najbardziej znanych
wtyczek do programu \textit{Valgrind} są: \texttt{memcheck} -- sprawdzający
błędne odwołania do pamięci i nieprawidłowe używanie alokatora pamięci,
\texttt{cachegrind} --- analizujący wykorzystanie pamięci podręcznej procesora,
\texttt{helgrind} --- lokalizujący usterki typu \textit{race condition} w
programach wielowątkowych. Elastyczna architektura \textit{Valgrinda} może
posłużyć jako podstawa budowy wtyczek analizujących wpływ alokatora na
aplikacje z niego korzystające.

\paragraph{Zegary o dużej rozdzielczości.} Systemy uniksowe oferują pomiar
czasu w ograniczonym zakresie. Linux domyślnie dysponuje licznikami o
dokładności $1-10$ ms. Do mierzenia wydajności niezbędne są źródła czasu o
większej rozdzielczości, liczące z dokładności do mikrosekund, nanosekund lub
cykli procesora. Procesory \textit{Intel x86} dysponują instrukcją
\texttt{RDTSC} zwracającą $64$-bitową wartość reprezentującą ilość cykli.
które upłyneły od ostatniego restartu. Jest to najdokładniejsze i jednocześnie
najmniej kosztowne pod względem odczytu źródło czasu. Niestety posiada też
liczne wady --- przede wszystkim jest ograniczone do architektury \textit{Intel
x86}, po drugie nie jest gwarantowane, że w systemach wieloprocesorowych
wszystkie liczniki będą ze sobą zsynchronizowane. Alternatywą do instrukcji
\texttt{RDTSC} jest sprzętowy zegar o dużej rozdzielczości \texttt{HPET} (ang.
\textit{High Precision Event Timer}).

\paragraph{Benchmarki.} Poniżej przedstawiono publicznie dostępne programy do
mierzenia wydajności alokatorów. Programy te są dostępne w katalogu
\texttt{src/benchmarks} i zostały przystosowane do kompilacji w systemie
\textit{Linux} z użyciem kompilatora \texttt{gcc 4.2}.

\begin{tabularx}{\textwidth}{|l|X|}
\hline
\textsc{program} & \textsc{opis} \\
\hline
\hline
\verb+cfrac+ & Program dokonujący faktoryzacji dużych liczb. Rezerwuje bardzo
duże ilości bloków o wielkości 16 i 32 bajtów. \\
\hline
\verb+espresso+ & Aplikacja do optymalizacji programowalnych macierzy
logicznych. Dane do testów to plik \texttt{largest.espresso}. \\
\hline
\verb+larson+ & Symulacja stworzona na podstawie obserwacji wielowątkowych
serwerów. W każdej rundzie wątek rezerwuje i zwalnia bloki o zadanym rozmiarze.
Przed zakończeniem działania przekazuje on zajęte bloki do innego wątku. Dane
wejściowe podaje się z wiersza poleceń i są nimi kolejno: czas działania, rozmiar
min. i max. bloku, min. i max.  ilość wątków, ilość bloków rezerwowanych przez
wątek, ilość rund i ziarno generatora liczb pseudolosowych. \\
\hline
\verb+lindsay+ & Symulacja przenoszenia komunikatów w sieci o topologii
hiperkostki. Przykładowy plik wejściowy to \texttt{scirpt.mine}. \\
\hline
\verb+linux-scalability+ & Wielowątkowy test dołączany do biblioteki
\texttt{glibc}. Dostępne parametry z linii poleceń: wielkość bloków, ilość
iteracji i wątków.\\
\hline
\verb+mallocperf+ & Benchmark udostępniany przez firmę \textit{Cherrystone
Software Labs}. Wiele wątków losowo przydziela i zwalnia pamięć. Parametry
podaje się z linii poleceń.\\
\hline
\verb+p2c+ & Konwerter źródeł w języku \texttt{Pascal} do źródeł w języku
\texttt{C}. Do programu dostarczono dane wejściowe --- plik \texttt{mf.p}. \\
\hline
\verb+roboop+ & Bibiloteka do symulacji ruchów robotów --- bardzo intensywnie
korzystająca z alokatora. Dostarczona wraz z programem \texttt{bench} służącym
do pomiaru szybkości operacji. \\
\hline
\verb+sh6bench+ & Benchmark o otwartych źródłach dostarczany wraz z komercyjnym
alokatorem \textit{SmartHeap}. Powtarza w rundach następujące czynności:
rezerwuje grupy obiektów o tej samej wielkości, następnie zwalnia losowo część
spośród wszystkich bloków. \\
\hline
\end{tabularx}

\subsection{Narzędzie \texttt{traces}.}

Motywacją do stworzenia narzędzia \texttt{traces} była potrzeba analizy
zachowań programów, również tych wielowątkowych, pod względem wykorzystania
alokatora. W tym celu utworzono zestaw składający się z:
\begin{itemize}
\item programu zbierającego ślady --- w plikach \texttt{ptmalloc3/traces.c} i
\texttt{ptmalloc3/traces.h} zaimplementowano uniwersalne funkcje służące
do przechwytywania wywołań \texttt{malloc}, \texttt{free}, itd. Szczegóły
zostaną omówione poniżej.
\item publicznie dostępnego alokatora \textit{ptmalloc3} zmodyfikowanego z
użyciem funkcji określonych w pliku \texttt{ptmalloc3/traces.h},
\item analizatora śladów \texttt{traces-analyze} napisanego w
\textit{Pythonie}, generującego wykresy wizualizujące wykorzystanie alokatora.
\end{itemize}
Wszystkie pliki znajdują się w katalogu \texttt{src/traces} w dołączonym do
pracy archiwum.

\paragraph{Impementacja.} Założeniami przy tworzeniu programu zbierającego ślady
były: możliwie jak najmniejszy narzut mocy obliczeniowej, maksymalna
przezroczystość dla aplikacji działającej pod jego kontrolą, możliwość
stosowania w programach bez ich rekompilacji, obługa wielu wątków i wielu
procesów.

Pierwsze założenie otrzymano implementując gromadzenie logów operacji do
statycznego bufora o dużym rozmiarze. Algorytmy użyte celem relizacji funkcji
dostępu do tego bufora działają bez blokad i zapewniają bardzo dobrą wydajność
w przypadku wielowątkowych programów. Ślady są zapisywane na dysk w dużych
paczkach minimalizując obciążenie spowodowane operacjami wejścia-wyjścia.
Jedyne wywołanie, które może powodować istotny spadek wydajności to pobieranie
czasu dla każdej operacji alokatora.

Przezroczystość została osiągnięta poprzez zintegrowanie programu zbierającego
ślady z bardzo dobrze znanym i przetestowanym alokatorem \textit{ptmalloc3}
używanym w standardowej bibliotece języka \verb+C+ w systemie \textit{Linux}.

Dzięki elastycznemu konsolidatorowi \texttt{ld.so} w systemach uniksowych
istnieje możliwość przesłaniania symboli bibliotecznych. W trakcie wczytywania
dynamicznie skonsolidowanego programu z pliku \texttt{ELF}\footnote{Executable
and Linking Format --- standardowy typ dla plików wykonywalnych, bibliotek i
modułów w systemach uniksowych.}, \texttt{ld.so} pobiera tablicę symboli
(funkcji) i listę bibliotek. Następnie wgrywa poszczególne biblioteki
uzupełniając tablicę symboli o adresy procedur bibliotecznych. Zanim jednak to
zrobi sprawdza zawartość zmiennej systemowej \texttt{LD\_PRELOAD} i jeśli
zawiera ona ścieżki do zestawu bibliotek, to najpierw uzupełnia listę symboli
na ich podstawie. Używając tego mechanizmu można pod dowolny dynamicznie
skonsolidowany program podczepić bibliotekę zawierającą alokator pamięci
uzupełniony o funkcje zbierania śladów. Odpowiednie funkcje z biblioteki
podanej w zmiennej \texttt{LD\_PRELOAD} zostaną wykorzystane do uzupełnienia
symboli w pierwszej kolejności, przesłaniając symbole funkcji alokatora z
biblioteki \texttt{libc}.

Obsługę wielowątkowości i wieloprocesorowości osiągnięto przez przypisanie
identyfikatora wątku i procesu do każdej operacji menedżera pamięci. Dodatkowo
wszyscy potomkowie utworzeni przez dany proces przy pomocy wywołania
\texttt{fork(2)} zapisują ślad do tego samego pliku. Procesy utworzone przy
pomocy wywołania \texttt{system(3)} lub \texttt{exec*(3)} jako osobne instacje
procesów zapisują ślady do innych plików.

\paragraph{Sposób wykorzystania.} Poniższe polecenie uruchamia program
\texttt{aplikacja}, a ślad wykonania zapisuje do pliku
\texttt{aplikacja-trace-log}. Symbole alokatora zostaną przesłonięte
biblioteką \texttt{libptalloc3-traces.so}, którą znajduje się w katalogu
\texttt{src/traces/ptmalloc3}.
\begin{center}
\begin{verbatim}
$ MALLOC_TRACE_LOG=aplikacja-trace-log \
  LD_PRELOAD=libptmalloc3-traces.so  \
      aplikacja arg1 arg2 ...
\end{verbatim}
\end{center}

\paragraph{Struktura śladu.} Ślad to plik binarny z rekordami o długości 24
bajtów. Struktura rekordu została zamieszczona poniżej:

\vspace{1ex}

\begin{lstlisting}[caption={Struktura śladu.}]
struct traces_log {
    uint32_t msec;
    uint16_t opcode;
    uint16_t pid;
    uint32_t thrid;
    uint32_t result;
    uint32_t args[2];
};
\end{lstlisting}

\vspace{-1ex}

Wartość \texttt{msec} określa moment czasu względem początku działania
programu, w którym wykonano operację, \texttt{opcode} jest numeryczną wartością
kodującą rodzaj operacji (\texttt{free}, \texttt{malloc}, \texttt{realloc},
\texttt{memalign}), \texttt{pid} i \texttt{thrid} to odpowiednio numer
śledzonego procesu/wątku, \texttt{result} to wynik operacji, a \texttt{args}
argumenty procedury określonej przez \texttt{opcode}. Format ten jest
wystarczający do analizy większości programów, niewątpliwie jednak wymaga kilku
optymalizacji.

Jeśli program wykonuje dziesiątki czy setki milionów operacji przydziału lub
zwalniania bloków, to istotnym aspektem staje się oszczędność przestrzeni
dyskowej używanej do przechowywania śladu. Pierwszym i najprostszym pomysłem
jest zastosowanie zmiennej długości rekordu w zależności od rodzaju operacji --
dla najczęściej wykonywanych operacji \texttt{malloc} i \texttt{free} nie
wykorzystuje się drugiego elementu tablicy \texttt{args}, a dla \texttt{free}
dodatkowo pola \texttt{result}. Następnie można by było skrócić pole
\texttt{opcode}, które koduje cztery operacje, a zatem wymaga tylko dwóch
bitów. Mniej oczywistym pomysłem jest skrócenie rekordów poprzez nałożenie
ograniczenia na maksymalną ilość ścieżek wykonania programu. Wydaje się, że
śledzenie więcej niż kilkuset wątków jest już zadaniem karkołomnym, zatem można
rozważyć połączenie pól \texttt{pid} i \texttt{thrid} przy pomocy wartości
wyliczonej pewną funkcją haszującą. Wtedy informację kodująca parę
identyfikator programu i identyfikator wątku można by ograniczyć do $14$ bitów
($16384$ różnych ścieżek). W trakcie zapisu rekordów do pamięci zewnętrznej
można zastosować uproszczony i efektywny wariant kompresji słownikowej
\texttt{LZO} bazującej na algorytmie \texttt{LZ77}.

Usprawnienia może wymagać też pomiar czasu. W obecnej implementacji jest on
mierzony dość zgrubnie ---  można rozważyć zwiększenie dokładności do
mikrosekund czy nawet nanosekund, rozszerzając pole \texttt{msec} do $64$
bitów.

W pracy \cite{chilimbi00designing} omówiono efektywny objętościowo sposób
składowania śladów. Przedstawiono format rekordów dający możliwie jak
największą ekspresję zdarzeń istotnych z punktu analizy śladów oraz metody
efektywnej wydajnościowo kompresji.

\paragraph{Analiza śladów.} Celem graficznej wizualizacji śladów, należy je
przetworzyć programem \texttt{traces-analyze.py}. Program ten generuje plik
\textit{EPS} przechowujący trzy wykresy.

Pierwszy z nich jest histogramem rozmiarów wszystkich bloków zarezerwowanych na
przestrzeni działania programu. Rozmiary bloków są zaokrąglane do odpowiednich
przedziałów o proporcjonalnych wielkościach. Wykres ten pozwala przeanalizować
zależności między wielkością bloków przydzielonych na przestrzeni działania
całego programu, a ich liczbą.

Kolejny wykres przedstawia ilość zużywanej pamięci w danej chwili działania
programu. Zastosowano podział na bloki o wielkości nie większej niż długość
linii pamięci podręcznej (kolor zielony), nie większej niż strona pamięci
(kolor czerwony), nie większej niż wielkości kilku stron (kolor pomarańczowawy)
i zużycie całkowite (kolor ciemnoniebieski). Dzięki takim informacjom można
obserwować jak wygląda zużycie pamięci w poszczególnych etapach działania
programu.

Ostatni wykres wizualizuje ilość używanych bloków w określonym momencie
działania progamu. Podobnie jak w poprzednim wykresie zastosowano podział
wielkości bloków. Wykres pozwala oszacować na jakie bloki było największe
zapotrzebowanie w danym okresie działania programu.

Na następnej stronie zaprezentowano wizualizacje śladów dla programów:
\texttt{espresso} dla danych z pliku \texttt{Input/largest.espresso} i
\texttt{p2c} dla danych z pliku \texttt{Input/mf.p}.

\begin{figure}%
\centering
\includegraphics[width=0.75\textwidth]{src/benchmarks/espresso-log}
\caption{Ślad wykonania programu espresso.}

\vspace{0.5in}

\includegraphics[width=0.75\textwidth]{src/benchmarks/p2c-log}
\caption{Ślad wykonania programu p2c.}
\end{figure}

\newpage

% --=[ Implementacja ]=---------------------------------------------------------

\section{Implementacja}
\hypertarget{Implementacja}{}

Implementacja menedżera pamięci składa się z następujących elementów:
\begin{itemize}
\item trzech alokatorów podrzędnych -- \verb+eqsbmgr+, \verb+blkmgr+, \verb+mmapmgr+;
\item zarządcy stron -- \verb+areamgr+;
\item warstwy abstrakcji nad przydziałem stron -- \verb+sysmem+;
\item programu testującego -- \verb+tst-random+;
\item warstwy zgodności ze standardem POSIX -- \verb+ldwrapper+.
\end{itemize}
Wszystkie te elementy zostaną opisane w kolejnych podrozdziałach.

\vspace{1ex}

Hybrydowy zarządca pamięci --- będący tematem pracy --- ewoluował w trakcie
implementacji.  Kilkukrotnie wymagał wprowadzenia nowych warstw abstrakcji w
kodzie. Autor zdaje sobie sprawę, że momentami powiązania między modułami są
zbyt duże i należało by możliwie jak najbardziej rozdzielić poszczególne
moduły.

\paragraph{Napotkane problemy.} Zdaniem autora implementacja zarządcy pamięci
to zadanie ciężkie i pracochłonne. W trakcie implementacji napotkano wiele
trudności, których przyczyny opisano poniżej.

Ponieważ kod powinien być portowalny, a jednocześnie dawać dużą
kontrolę nad maszyną, implementacja autora jest napisana w języku \verb+C+.
Niestety jest to język powszechnie uważany za mało bezpieczny i wymagający
bardzo defensywnej strategii pisania kodu. Dlatego w źródłach zostało
zaszyte mnóstwo mechanizmów sprawdzających temporalne stany struktur
menedżera pamięci.
	
Często występującymi błędami w programach napisanych w języku \verb+C+ są
nieprawidłowe odwołania do pamięci. Istnieje mnóstwo narzędzi, które pomagają
wyłapywać te usterki. Niestety, w przypadku kiedy zarządzamy pamięcią sami
narzędzia te stają się bezużyteczne. Abstrahują nad alokatorem zakładając jego
poprawność, zamiast ją badać. Ze względu na to, w trakcie implementacji błędy
odwołań do pamięci były często bardzo trudne do wykrycia. Czasami pomocne było
użycie programu do analizy dynamicznej odwołań do pamięci \verb+valgrind+, a
także śledzenie stosu wywołań funkcji przy pomocy debugera \verb+gdb+.

Założenie o możliwości prawidłowego obsłużenia wielu wątków wewnątrz alokatora
przysparza wiele problemów. Trzeba ustalić, które struktury zarządcy są
chronione i ustalić strategię zakładania blokad tak, aby uniknąć zakleszczeń
czy wyścigów. Z pomocą przychodzi tutaj element programu \verb+valgrind+ o
nazwie \verb+helgrind+. Przeprowadza on dynamiczną analizę programu pod kontem
zakładania blokad i wykorzystania dzielonych zasobów. Program ten był bardzo
użyteczny mimo dużej ilości fałszywych alarmów (ang. \textit{false positives}).

Niedeterminizm systemu operacyjnego był elementem utrudniającym testowanie
procedur alokatora. Program stworzony na potrzeby testów zarządcy wykonuje
pewien ciąg operacji zależny tylko od parametrów podanych z wiersza poleceń.
Problem wynikał z tego, że jądro systemu nie ma obowiązku mapowania stron
zawsze na te same miejsca przestrzeni adresowej nawet, jeśli wzór wykonania
programu jest identyczny.  Szczęśliwie niedeterminizm jądra systemu objawia się
w takich przypadkach rzadko, zapewne dzięki deterministyczności wewnętrznych
mechanizmów jądra.
	
Niedeterminizm przełączania wątków przysparzał najwięcej problemów w trakcie
testowania, gdyż często uniemożliwiał odtworzenie błędu. Jest to powszechny
problem przy pisaniu programów wielowątkowych, którego uniknięcie jest raczej
niemożliwe.

\subsection{Założenia i cele}

Naturalnymi oczekiwaniami wobec implementacji alokatora pamięci są: małe
zużycie pamięci, niska fragmentacja, wysoka wydajność. Są to uniwersalne cele,
które są realizowane za pomocą różnych środków. Korzystając z wiedzy zawartej w
poprzednich rozdziałach, a także obserwacji zachowania się programów przy
pomocy analizatora śladów, można założyć poczynić pewne założenia.

\paragraph{Eksploatacja zależności między rozmiarem, a liczbą bloków.} Wiemy
już, że w praktyce obserwuje się malejącą liczbę bloków względem rosnącej ich
długości. Pierwszym założeniem jakie zostało obrane jest podział menedżera
pamieci na podmenedżery specjalizujące się obsłudze bloków określonej
wielkości. Podalokatory będą posiadały różne właściwości (np. fragmentację,
efektywność działania) w zależności od klasy bloku. Opłaca się włożyć dużo
wysiłku w podmenedżer zajmujący się małymi blokami, gdyż to on będzie
najmocniej rzutował na działanie całego alokatora.

\paragraph{Eksploatacja zależności między rozmiarem, a długością życia bloku.}
W praktyce również spotyka się taką zależność. Duże bloki są przeważnie
rezerwowane na potrzeby buforów. Przydziela się je rzadko, co wynika choćby z
tego, że są po prostu duże i zapewne program będzie chciał co najmniej raz
zajrzeć do każdej komórki takiego bloku. Z drugiej strony małe bloki często
bywają częścią jakiejś dużej dynamicznej struktury danych. Elementy tej
struktury często powracają do menedżera pamięci. Warto poświęcić trochę czasu
na badanie lokalności odwołań podalokatora zajmującego się małymi blokami, gdyż
może to znacząćo poprawić ogólną wydajność zarządcy pamięci jak i programu z
niego korzystającego.

\paragraph{Minimalizacja odwołań do systemu operacyjnego.} Pobieranie i
zwalnianie stron pamięci przy pomocy wywołania systemowego jest zadaniem
czasochłonnym. Wymaga ono przebudowania pewnych struktur jądra oraz
przeładowania katalogów i tablic deskryptorów. W systemach wieloprocesorowych
taki proces może trwać wiele setek tysięcy cykli, gdyż wiąże się dodatkowo z
uspójnieniem zawartości bufora \texttt{TLB}. Taki zabieg może w rezultacie
wymagać kilkudziesięciu tysięcy dostępów do obszarów składujących tablice
deskryptorów. Dodatkowo nie ma gwarancji, że obszary te znajdują się w pamięci
podręcznej, a ponieważ są rzadko używane najprawdopodobniej trzeba będzie je
sprowadzić z pamięci RAM. Każdą nieużywaną stronę warto przchowywać w jakiejś
podręcznej strukturze danych, zamiast odsyłać od razu do systemu operacyjnego.
Bez udziału systemu można wtedy powtórnie przydzielić nieużywane strony na
potrzeby kolejnych operacji.

\paragraph{Minimalizacja operacji na blokadach.} Przestrzeń adresowa i pamięć
wirtualna należąca do procesu jest wspólna dla wszystkich wątków działających w
jego obrębie. Zatem struktury menedżera pamięci będzie dzielona między wątki.
Dostęp do nich będzie musiał angażować pewne środki synchronizacji tj. semafory
binarne lub blokady pętlowe. Pożądane jest by interakcja wątków była
ograniczona do minimum. Duża konkurencja do zasobów alokatora może przyczyniać
się do słabej skalowalności aplikacji, które z niego korzystają.

\paragraph{Abstrakcja nad źródłem stron pamięci.} Jednym z czynników
motywujących do napisania własnej implementacji alokatora pamięci był brak
wydajnych alokatorów, które posiadają warstwę abstrakcji nad sposobem
pobierania stron z systemu operacyjnego. Wszyscy przeanalizowani zarządcy pamięci
mieli głęboko zaszyte zależności od określonych mechanizmów jądra systemu.
Dzięki takiej abstrakcji implementacja autora stała się uniwersalniejsza i daje
się zastosować nie tylko jako zastępnik standardowego alokatora, ale co było
ważniejsze --- jako alokator pamięci dzielonej.

\paragraph{Zgodność ze standardem POSIX.} Najlepiej znany interfejs alokatorów
jest określony przez standard POSIX, który opisuje dokładnie działanie
poszczególnych funkcji zarządcy pamięci. Programiści są przyzwyczajeni do tego
interfejsu, zatem należy go udostępnić. Niestety funkcje \verb+memalign+ i
\verb+realloc+ wprowadzają dodatkowy stopień złożoności w trakcie projektowania
i implementacji alokatora. Menedżer pamięci oprócz dobrej semantyki interfejsu
powinien również unikać wywołań funkcji nie będących częścią interfejsu POSIX w
celu zachowania przenośności.

\paragraph{Kopie procesów.} Interakcja alokatora ze specyfiką funkcji
udostępnianych przez standard POSIX komplikuje przypadek, kiedy proces tworzy
procesy potomne i chce w nich zachować spójność środków synchronizacji.  Chodzi
dokładnie o zachowanie się blokad biblioteki \texttt{pthreads} po wywołaniu
systemowym \texttt{fork}. Procedura ta klonuje proces, w obrębie którego może
działać wiele wątków. Proces potomny posiada kopię przestrzeni adresowej i
większości struktur rodzica, lecz niestety wątki nie są klonowane w stanie
aktywnym. Do procesu potomnego przechodzi tylko ten wątek, który wywołał
funkcję \verb+fork+. Rodzi to dość subtelny problem --- blokady założone w
przestrzeni adresowej rodzica nie mogą być zwolnione w dziecku, gdyż wątki
odpowiedzialne za to zadanie nie istnieją. Do rozwiązania tej kłopotliwej
sytuacji służy procedura \verb+pthread_at_fork+, przy pomocy której można
zarejestrować wywołania, które nastąpią bezpośrednio przez wykonaniem
\verb+fork+ w procesie rodzica i bezpośrednio po wykonaniu \verb+fork+ w
procesie potomka.

\paragraph{Wykrywanie błędów.} Usterki związane z błędami wykorzystania
alokatora pamięci są bardzo częste. Programista powinien być możliwie jak
najwcześniej informowany o tym, że jego program zachowuje się nieprawidłowo.
Często stosowanym zabiegiem jest czyszczenie nowo zarezerowanej pamięci pewną
ustaloną wartością np. \texttt{0xDEADC0DE}. Błędny program przeczytawszy
zawartość tak ustawionej komórki, która w wyniku fragmentacji wewnętrznej nie
należy do bloku, najprawdopodobniej ulegnie awarii. Może to ułatwić wykrycie
usterek, które wiążą się z odczytem danych z tablicy w przypadku błędnych
indeksów. Innym zabiegiem, który powinno się wykonywać by wcześnie wykrywać
usterki, jest sprawdzanie poprawności prywatnych struktur danych alokatora.
Można to robić na dwa sposoby, albo manualnie ze strony programu --- poprzez
wywołanie procedury \texttt{mcheck} --- albo automatycznie w trakcie
przetwarzania żądań przez zarządcę pamięci. W drugim przypadku nie zaleca się
sprawdzania poprawności wszystkich struktur, a jedynie tych, które trzeba
przejrzeć w trakcie obsługi danej operacji.

\subsection{Idea alokatora}

Zaimplementowany alokator pamięci jest algorytmem hybrydowym o hierarchicznej
strukturze. Pozwala to na jego łatwą modyfikację i dostosowywanie do potrzeb
programisty.

\begin{figure}[ht]
\centering
\includegraphics[width=0.60\textwidth]{schemat}
\caption{Schemat zależności między modułami alokatora.}
\end{figure}

Pierwsza warstwa znajdująca się najbliżej systemu operacyjnego to mechanizm
pobierania i zwalniania stron pamięci --- \texttt{sysmgr}. Interfejs ten
abstrahuje nad źródłem stron, którym może być wywołanie systemu operacyjnego
\texttt{mmap}, \texttt{sbrk} lub spójny obszar pamięci dzielonej.

Następną warstwą jest manadżer obszarów --- \texttt{areamgr}. Obszar to
niezerowa liczba przylegających do siebie stron, może być oznaczony jako wolny
lub używany przez dany alokator niższego rzędu. Menedżer stron odpowiada za
następujące operacje:
\begin{itemize}
\item tworzenie i niszczenie obszarów,
\item scalanie i podział obszarów,
\item utrzymywanie listy obszarów zajętych i wolnych,
\item odczepianie i dołączanie stron do istniejących obszarów,
\item przydział obszarów na potrzeby manadżerów niższego rzędu,
\item powiększanie, zmniejszanie istniejących obszarów,
\item odpowiadanie na zapytania: "Który alokator odpowiada za blok o podanym
adresie?", "Do którego obszaru należy dany adres?".
\end{itemize}

Menedżery niższego rzędu to wyspecjalizowane pod kątem wielkości bloku
algorytmy przydziału i zwalniania pamięci. Korzystają z obszarów, w których
organizują własne struktury danych do utrzymywania listy wolnych i zajętych
bloków.

Pierwszym menedżerem niższego rzędu jest alokator bloków równej długości ---
\texttt{eqsbmgr}.  Odpowiada on za przydział bloków o długości nie większej niż
$32$ bajty.  Zarządzany obszar dzieli na superbloki długości $1024$ bajtów. Na
początku każdego superbloku znajduje się nagłówek. Przechowuje on informacje o
długości zarządzanych bloków, a także bitmapę określającą, które bloki
są zajęte, a które wolne.

Za zarządzanie bloków długości większej niż $32$ bajty, ale nie dłuższych niż
$32$ kilobajty, odpowiada manadżer utrzymujący listę bloków posortowanych
względem adresu -- \texttt{blkmgr}. Jest to modyfikacja standardowego algorytmu
znaczników granicznych. Zmiany obejmują możliwość powtórnego określenia rozmiaru
zarezerwowanego bloku, przydział bloku o adresie podzielnym przez liczbę będącą
potęgą dwójki, podział, scalanie, powiększanie i zmniejszanie list bloków.

Utrzymywaniem informacji o blokach długości większej niż $32$ kilobajty zajmuje
się manadżer obszarów bezpośrednio mapowanych --- \texttt{mmapmgr}. Blok w tym
przypadku jest tożsamy z obszarem. Zarządca podobnie jak w przypadku
\texttt{blkmgr-ao} potrafi wykonywać operacje \texttt{realloc} i
\texttt{memalign}.

Nad wszystkimi trzema menedżerami pracuje ogólny zarządca pamięci ---
\texttt{memmgr}. Odpowiada za obsługę wszystkich operacji rozdzielając
żądania między alokatory niższego rzędu.

Do procedur ogólnego zarządcy pamięci ma dostęp warstwa emulująca interfejs
\texttt{POSIX}. Implementuje ona wszystkie te funkcje, które są określone przez
wspomniany standard, a nie są częścią podległego manadżera.

\newpage

\subsection{Interfejs standardowego alokatora}

\label{PosixMalloc}

Programiści, korzystający z menedżera sterty w standardowej bibliotece języka
C, są przyzwyczajeni do tego, że posiadają pewien dobrze znany mechanizm
udostępniający pewną funkcjonalność.

W związku z tym implementacja ogólnego menedżera pamięci powinna być możliwie
jak najbardziej zbliżona pod względem zachowania do tej określonej w
standardzie \texttt{POSIX}.

\subsubsection{Zgodność ze standardem \texttt{POSIX}}

\paragraph{Procedura malloc.}

Funkcja \texttt{malloc} zwraca wskaźnik do bloku pamięci o rozmiarze
\texttt{size} bajtów lub wartość \texttt{NULL} w przeciwnym wypadku.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{malloc}.}]
void * malloc (size_t size);
\end{lstlisting}

Zwrócony wskaźnik w systemach $32$-bitowych musi być podzielny przez $8$, a w
systemach $64$-bitowych przez $16$. W przypadku błędu zmienna systemowa
\texttt{errno} musi być ustawiona na wartość \texttt{ENOMEM}. Zarezerwowana
pamięć ma nieokreśloną zawartość. Nadpisanie obszaru znajdującego się
bezpośrednio przed jak i za przydzielonym blokiem najprawdopodobniej uszkodzi
prywatne struktury danych alokatora pamięci --- co doprowadzi do nieokreślonego
zachowania menedżera pamięci.

\paragraph{Procedura calloc.}

Funkcja \texttt{calloc} zwraca wskaźnik do wyzerowanego bloku pamięci będącego
w stanie pomieścić tablicę \texttt{count} elementów o rozmiarze
\texttt{eltsize} lub wartość \texttt{NULL} w przeciwnym wypadku.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{calloc}.}]
void * calloc (size_t count, size_t eltsize);
\end{lstlisting}

Procedura ta zachowuję się podobnie jak \texttt{malloc}, poza gwarancją
zainicjalizowania obszaru zerami. Implementacja tego wywołania może, ale nie
musi, korzystać wewnętrznie z wywołania \texttt{malloc}.

\paragraph{Procedura realloc.}

Funkcja \texttt{realloc} zmienia rozmiar bloku wskazywanego przez argument
\texttt{ptr} na \texttt{newsize} bajtów. Jeśli zwrócony adres jest równy
\texttt{ptr} oznacza to, że zarządcy pamięci udało się zmienić rozmiar bloku w
miejscu. W przeciwnym wypadku procedura \texttt{realloc} rezerwuje nowy blok o
rozmiarze \texttt{newsize}, kopiuje do niego zawartość bloku wskazywanego przez
\texttt{ptr} po czym zwalnia stary obszar.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{realloc}.}]
void * realloc (void *ptr, size_t newsize);
\end{lstlisting}

Jeśli \texttt{realloc} zwróci wskaźnik równy \texttt{NULL}, wtedy stary obszar
wskazywany przez \texttt{ptr} zostaje w nienaruszonym stanie, a zmienna
systemowa \texttt{errno} ma wartość \texttt{ENOMEM}.

Funkcja \texttt{realloc} działa jak \texttt{malloc(newsize)}, jeśli argument
\texttt{ptr} jest równy \texttt{NULL}, lub jako \texttt{free(ptr)}, jeśli
argument \texttt{newsize} jest równy $0$.

\paragraph{Procedura posix\_memalign.}

Funkcja \texttt{posix\_memalign} rezerwuje blok pamięci o adresie podzielnym
przez argument \texttt{alignment} (liczba ta musi być potęgą dwójki) oraz przez
\texttt{sizeof(void *)} i o rozmiarze \texttt{size}. Zarezerwowany blok pamięci
umieszczany jest w komórce pamięci wskazywanej przez \texttt{memptr} i funkcja
zwraca $0$. W przypadku błędu funkcja zwraca: \texttt{EINVAL} jeśli
\texttt{alignment} nie spełnia zadanych kryteriów lub \texttt{ENOMEM} jeśli nie
ma wystarczającej ilości pamięci.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{posix\_memalign}, \texttt{memalign} i \texttt{valloc}.},xleftmargin=0cm,xrightmargin=0cm]
int posix_memalign (void **memptr, size_t alignment, size_t size);
void * memalign (size_t boundary, size_t size);
void * valloc (size_t size);
\end{lstlisting}

Funkcja \texttt{memalign} działa analogicznie do \texttt{posix\_memalign} --
przy czym adres jest podzielny tylko przez \texttt{boundary} (będące potęgą
dwójki), a początek zarezerwowanego bloku jest zwracany przez wartość funkcji.
W przypadku błędu adres jest równy \texttt{NULL} i ustawiana jest zmienna
systemowa \texttt{errno}.

Funkcja \texttt{valloc} jest prostą nakładką na \texttt{memalign}, gdzie
wartość argumentu \texttt{boundary} jest równa długości strony, którą można
sprawdzić używając funkcji \texttt{getpagesize()}.

Warto również zauważyć, że w systemach \textit{BSD} pamięć rezerwowana przez te
procedury nie może być zwalniania przez procedurę \texttt{free}.

\paragraph{Procedura free.}

Funkcja \texttt{free} zwalnia blok pamięci, czyniąc przestrzeń przez niego
wykorzystywaną zdatną do ponownego użycia.

\vspace{2ex}
\begin{lstlisting}[caption={Prototyp procedury \texttt{free} i \texttt{cfree}.}]
void free (void *ptr);
void cfree (void *ptr);
\end{lstlisting}

Funkcja \texttt{cfree} jest synonimem \texttt{free} i istnieje wyłącznie ze
względów historycznych --- dla kompatybilności z systemem \textit{SunOS}.

Dostęp do bloku pamięci po jego zwolnieniu mimo, że jest operacją błędną to
często jest możliwy. Istnieją narzędzia wykrywające takie anomalie. Deallokacja
bloku pamięci uszkadza jego zawartość.

Program nie musi zwalniać wszystkiej pamięci przed zakończeniem swego
działania. Automatyczne zarządzanie zasobami odda wykorzystaną przez proces
pamięć na użytek systemu operacyjnego.

Jeśli wskaźnik \texttt{ptr} nie podaje początku bloku pamięci, czyli wartości
zwróconej przez jakieś wywołanie \texttt{malloc}, lub podaje obszar już raz
zwolniony, to zachowanie menedżera pamięci jest nieustalone i może
zakończyć się przerwaniem działania programu.

Procedura \texttt{free} nie wykonuje żadnej operacji, jeśli wskaźnik
\texttt{ptr} jest równy wartości \texttt{NULL}

\subsubsection{Rozszerzenia \texttt{GNU}}

\vspace{2ex}
\begin{lstlisting}[caption={Prototypy pozostałych procedur i zmiennych.}]
int mallopt (int param, int value);
struct mallinfo mallinfo (void);
int mcheck (void (*ABORTFN)(int STATUS));
int mprobe(void *POINTER);
\end{lstlisting}

Wywołanie \texttt{mallopt} służy do zmieniania parametrów pracy alokatora i
jest ściśle powiązane z jego implementacją. Funkcja ta nie powinna być używana.

Funkcja \texttt{mallinfo} udostępnia informacje na temat wewnętrznego stanu
alokatora tj.: 
\begin{itemize}
\item liczbę wszystkich używanych stron,
\item liczbę przydzielonych wywołaniem \texttt{mmap} i \texttt{sbrk},
\item liczbę bajtów pamięci zajmowanych przez wszystkie przydzielone bloki,
\item liczbę bajtów pamięci, które są wolne i gotowe do użycia przez alokator.
\end{itemize}

Procedura \texttt{mcheck} instruuje alokator by dokonywał okresowego
sprawdzenia spójności własnych struktur danych. Funkcja musi być uruchomiona
przed pierwszym wywołaniem procedury \texttt{malloc}. W przypadku kiedy
zarządca znalazł błąd, wywołuje funkcję przekazaną przez parametr
\texttt{ABORTFN} wraz z odpowiednim kodem błędu oznaczającym:
\begin{itemize}
\item uszkodzenie danych przed początkiem bloku,
\item uszkodzenie danych za końcem bloku,
\item podwójne zwolnienie bloku.
\end{itemize}

Funkcja \texttt{mprobe} sprawdza poprawność wewnętrznych struktur alokatora
związanych z zarządzaniem bloku o adresie \texttt{POINTER}. Procedurę tą można
wywoływać tylko, jeśli \texttt{mcheck} został prawidłowo zainicjowany.

\newpage

\subsection{Menedżer stron --- \texttt{SYSMEM}}

Zarządca stron jest interfejsem najbliższym systemowi operacyjnemu. Służy do
przydzielania stron na użytek menedżera obszarów i zwalniania niepotrzebnych
zasobów. Moduł ten bezpośrednio korzysta z wywołań systemu operacyjnego.
Implementacja autora składa się z trzech części. Każda z nich wykorzystuje inny
mechanizm komunikacji z jądrem systemu. 

\vspace{2ex}
\begin{lstlisting}[caption={Prototypy funkcji menedżera stron ($X \in \{sbrk, mmap, shm\}$).}]
void pm_X_init();
void *pm_X_alloc(void *hint, uint32_t n);
bool pm_X_free(void *area, uint32_t n);
\end{lstlisting}

Moduł \texttt{sysmem-sbrk} wykorzystuje wywołanie systemowe \texttt{sbrk}. Z
powodu ograniczeń stawianych przez wykorzystywaną procedurę systemową
\texttt{pm\_shm\_alloc} nie wykorzystuje parametru \texttt{hint}. Zwracany
adres jest zawsze równy adresowi końca sterty sprzed wywołania. Zwalniany
obszar musi przylegać do końca sterty. Jeśli programista nie zadba o to,
funkcja \texttt{pm\_shm\_free} zwróci błąd.

Moduł \texttt{sysmem-shm} wykorzystuje ustalonej wielkości blok pamięci
dzielonej, o długości \texttt{PM\_PAGES}, zarezerwowanej wywołaniem
\texttt{mmap}. Na procedury \texttt{pm\_shm\_alloc} i \texttt{pm\_shm\_free} są
nałożone podobne ograniczenia jak w przypadku modułu \texttt{sysmem-sbrk}, przy
czym zwolnione strony de facto nie wracają do systemu operacyjnego.

Moduł \texttt{sysmem-mmap} używa procedury \texttt{mmap}. Właściwości tego
wywołania pozwalają na aktywne używanie w \texttt{pm\_mmap\_alloc} parametru
\texttt{hint}, który jest preferowanym adresem początku nowego obszaru --- tj.
procedura ta powinna, ale nie musi, zarezerwować strony poczynając od adresu
\texttt{hint}. W przeciwieńswie do wcześniejszych modułów na funkcję
\texttt{pm\_mmap\_free} nie są nałożone ograniczenia, więc zawsze powinna
zwrócić podane strony do systemu. Jest to najuniwersalniejszy moduł i pozwala
najefektywniej korzystać z pamięci przydzielonej przez system.

\newpage

\subsection{Menedżer obszarów --- \texttt{AREAMGR}}

Menedżer stron udostępnia nadrzędnym zarządcom abstrakcję nad mechanizmem
pobierania i zwalniania stron pamięci. Zasadniczym jego zadaniem jest
utrzymywanie i operowanie na globalnej liście obszarów. 

\paragraph{Rekord obszaru} jest zdefinowany przez strukturę \verb+area_t+ i
oprócz długości oraz początkowego adresu ma kilka innych właściwości:
\begin{itemize}
\item flagi, określające czy dany obszar jest używany lub zainicjalizowany do
użycia,
\item numer alokatora, który zarządza pamięcią w obrębie obszaru,
\item typ obszaru, określający który menedżer zarezerwował strony
składające się na ten obszar,
\item wskaźniki struktury danych utrzymującej globalną listę wszystkich obszarów,
\item wskaźniki struktury danych utrzymymywanej na potrzeby alokatorów,
\item sumę kontrolną, umożliwiającą weryfikację pól zawartych w rekordzie.
\end{itemize}

Rekord określający właściwości obszaru zawiera się w nim i przylega do jego
końca. Odpowiednie procedury służą do obliczania jego początku i końca na
podstawie pól zawartych w rekordzie. Istnieje także funkcja wyliczająca adres
rekordu obszaru z adresu jego początku i jego długości. Należy skomentować po
pierwsze czemu rekord leży wewnątrz obszaru, a po drugie czemu na jego końcu, a
nie początku.

Gdyby rekord nie był przechowywany wewnątrz obszaru, wymagałoby to
implementacji dodatkowego wyspecjalizowanego alokatora działającego wyłącznie
na potrzeby \texttt{areamgr}. Tworzy to paradoks kury i jajka --- obszary mają
służyć do organizacji pierwszego alokatora, tymczasem \texttt{areamgr}
wymagałby już istniejącego zarządcy bloków. Na szczęście implementacja
specjalistycznego menedżera rekordów obszarów jest możliwa i wydaje się, że
niesie ze sobą pewne zalety --- zostanie to dokładniej opisane w podpunkcie
dotyczącym optymalizacji. 

Motywacją tkwiąca za umieszczeniem rekordu na końcu obszaru jest uproszczona
implementacja procedury \texttt{memalign}. Adres początku obszaru jest zawsze
podzielny przez długość strony. 

\paragraph{Rekord listy} jest zdefiniowany strukturą \verb+arealst_t+, która
posiada blokadę, służącą do izolacji wątków, oraz licznik składowanych
elementów. Wszystkie obszary są trzymane na dokładnie dwóch listach. Pierwsza z
nich to globalna lista obszarów. Druga może pomagać w wyszukiwaniu wolnych
obszarów danego rozmiaru albo służyć menedżerowi bloków do pamiętania używanych
obszarów. Oprócz oczywistych operacji dodawania, usuwania i wyszukiwania
względem adresu lub rozmiaru, można również dokonywać podziału i scalania
obszarów. Podział rozbija obszar na dwa mniejsze, scalanie zlewa dwa przyległe
obszary w jeden spójny.

\paragraph{Rekord menedżera obszarów} zawiera globalną listę wszystkich
obszarów, licznik używanych i wolnych stron pamięci oraz kubełki do
przechowywania wolnych obszarów ustalonej długości --- dalej zwanych
nieużytkami.

\begin{figure}[ht]
\centering
\includegraphics[width=0.70\textwidth]{areamgr}
\caption{Graficzna reprezentacja struktury danych \texttt{areamgr\_t}.}
\end{figure}

Zarządca obszarów udostępnia innym modułom niżej wymienione operacje:

\textit{Dodanie nieużywanego obszaru do menedżera stron} polega na dodaniu go do
globalnej listy obszarów i wrzuceniu go do kubełka dla obszarów odpowiedniej
długości. Istnieje ograniczona ilość kubełków --- dokładnie 64. Ostatni z nich
przechowuje wszystkie obszary większe niż 64 strony.

\textit{Usunięcie obszaru z menedżera stron} wymaga wcześniejszego oznaczenia
go jako używanego, co można osiągnąć alokując go.  Usuwanie polega na wyjęciu
obszaru z globalnej listy.

\textit{Przydzielenie obszaru} przeszukuje kubełek wolnych obszarów o podanej
wielkości. Jeśli w kubełku nie zostanie znaleziony żaden odpowiedni obszar
wtedy następuje wyszukiwanie w kubełkach dla obszarów o większych rozmiarach.
Jeśli nie zostanie znaleziony żaden odpowiedni obszar wtedy menedżer stron żąda
od systemu operacyjnego przydzielenia nowych stron.  Jeśli przydzielony obszar
jest za długi to zostanie skrócony do żądanego obszaru, a powstały nieużytek
zostanie wrzucony do odpowiedniego kubełka.

\textit{Zwolnienie obszaru} na użytek menedżera pamięci polega na oznaczeniu go
wolnym i wrzuceniu go do odpowiedniego kubełka. Jednak zanim zostanie to zrobione,
algorytm sprawdza czy nie da się połączyć obszaru z innym do niego przyległym.

\textit{Prealokacja obszaru} gwarantuje, że po jej wywołaniu istnieje wolny
obszar o podanej długości. Innymi słowy --- sprawdza czy odpowiednie kubełki są
niepuste, a jeśli są puste to tworzy nowy obszar.

\textit{Poszerzanie obszaru} może być użyte, gdy menedżerowi bloków brakuje
przestrzeni do spełnienia żądania. Może on wtedy zarządać by pewną liczbę stron
przyłączyć z lewej lub prawej strony do danego obszaru. Procedura poszerzająca
może dołączyć większą liczbę stron. Zarządca bloków może skrócić obszar jeśli
stwierdzi, że dołączono za dużo stron. Funkcja poszerzania sprawdza czy
przyległy obszar jest wolne i jeśli tak, to go rezerwuje i następnie przy pomocy
procedur dla struktury \verb+arealst_t+ łączy z podanym obszarem.

\textit{Zmniejszanie obszaru} dzieli go na dwa mniejsze, z których jeden będący
odpowiednio po lewej lub prawej stronie ma zadaną liczbę stron. Powstały
nieużytek jest wrzucany do odpowiedniego kubełka.

\subsubsection{Możliwe optymalizacje}

Ciekawym pomysłem wartym implementacji jest prosta i niewielka pamięć podręczna
przechowująca adresy ostatnio wyszukiwanych obszarów z globalnej listy.
Ponieważ każda operacja zwolnienia bloku wymaga podania, do którego obszaru on
należy, mogłoby to istotnie rzutować na wydajność alokatora.

Kolejną poruszoną wcześniej ideą jest zbudowanie alokatora na wewnętrzne
potrzeby zarządcy obszarów. Realizacja tego pomysłu mogłaby uprościć
implementację menadżerów korzystających z \texttt{areamgr}, tj. nie trzeba
uwzględniać obcych elementów (w tym przypadku rekordu \texttt{area\_t}) w
obsługiwanych obszarach. Wyeleminowałoby to zbędne powiązania między modułami.
Wewnętrzny alokator przyczyniłby się również do poprawy wykorzystania pamięci
podręcznych. W chwili obecnej przeszukiwanie globalnej listy obszarów jest
nieefektywne. Zauważmy, że każde przyczytanie rekordu \texttt{area\_t} jest
związane z dostępem do strony pamięci, która go przechowuje. Powoduje to duże
zaśmiecanie \textit{TLB cache} i ujemnie odbija się również na programie
korzystającym z alokatora. Oczywistym jest, że wartoby zebrać rekordy obszarów
i umieścić blisko siebie. Takie scalenie miejsca przechowywania miałoby też
pozytywny skutek na wykorzystanie pamięci podręcznej procesora. W jednej linii
możnaby zmieścić kilka rekordów obszaru.

Niewątpliwie menadżer obszarów mógłby skorzystać na wymianie struktury danych
służącej do przechowywania i wyszukiwania rekordów. W chwili obecnej listę
dwukierunkową możnaby było zastąpić strukturą \textit{Splay Tree}.
Zredukowałoby to złożoność operacji do oczekiwanego czasu $O(log n)$. Z
praktycznego punktu widzenia drzewa te mają dodatkową zaletę --- często używane
elementy znajdują się blisko korzenia drzewa. W przypadku osobnej implementacji
alokatora rekordów obszarów możnaby było się pokusić o implementację
zmodyfikowanego B-drzewa.  Ponieważ jeden wierzchołek B-drzewa mógłby
przechowywać wiele rekordów pozytywnie odbiłoby się to także na wykorzystaniu
pamięci podręcznej.

\newpage

\subsection{Zarządca małych bloków --- \texttt{EQSBMGR}}

Manadżer małych bloków odpowiada za utrzymywanie niewielkich bloków o równej
długości. W bieżącej implementacji występują cztery długości: $8$, $16$, $24$ i
$32$ bajtów. Bloki o długości $n \in [1,8]$ są zaokrąglane do rozmiaru $8$
bajtów, $n \in [9,16]$ do $16$ bajtów, $n \in [17,24]$ do $24$ bajtów i $n \in
[25,32]$ do $32$ bajtów. Bloki o różnych długościach nie sąsiadują ze sobą, a
są trzymane w grupach zwanych superblokami. Stąd też wynika nazwa manadżera ---
\texttt{eqsbmgr} (ang. \textit{equally sized blocks manager}).

Z przeprowadzonych wcześniej obserwacji spodziewamy się, że program
wykorzytujący nasz alokator będzie masowo przydzielał małe bloki pamięci ---
może to na przykład robić intensywnie operując na dynamicznych strukturach danych.
Wyobraźmy sobie aplikację wczytującą dane do zbalansowanego drzewa binarnego.
Zauważmy że, w trakcie konstrukcji dość rzadko będzie ona zwalniała rekordy
będące węzłami drzewa, o ile w ogóle będzie to robiła. Po wczytaniu rekordów
zostaną przeprowadzone obliczenia, po czym całe drzewo zostanie zwolnione, a
wynik działania przekazany do następnej fazy obliczeń. To czego możemy
oczekiwać to długie ciągi operacji \texttt{alloc} i \texttt{free}, być może
przeplatających się, operujące na rekordach o tym samym rozmiarze.

Ze względu na rozmiar bloków chcemy, by narzut pamięci na składowanie struktur
potrzebnych dla alokatora był znikomy. Dobrze by było, gdyby rezerwowane bloki
nie przechowywały żadnych informacji poza danymi użytkownika.

Rezerwowane bloki są najprawdopodobniej wielkości podzielnej przez $4$ lub $8$
bajtów. Jest to domyślna granica wyrównania adresów stosowana przez
kompilatory. W bieżącej implementacji przyjęto $8$--bajtową granicę.

Wszystkie bloki przydzielane na użytek aplikacji korzystającej z alokatora są
zarządzane przez jednostki zwane superblokami. Superblok jest to ciągły
fragment pamięci zaczynający się w adresie podzielnym przez 1024. Jego długość
może być zmienna, natomiast nie może ona przekraczać 1024 bajtów.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{eqsbmgr-sb}
\caption{Graficzna reprezentacja superbloku}
\end{figure}

W nagłówku superbloku znajdują się lista z 16--bitowymi wskaźnikami, których
znaczenie zostanie omówione w ramach opisu manadżera superbloków. Oprócz tego
składowane są tam następujące informacje:
\begin{itemize}
\item \texttt{fblkcnt} -- liczba wolnych bloków (7 bitów),
\item \texttt{blksize} -- rozmiar bloków (2 bity),
\item \texttt{size} -- rozmiar superbloku (7 bitów).
\end{itemize}

Bitmapa superbloku może mieć różną długość w zależności od wartości pól
\texttt{blksize} i \texttt{size}. Nigdy nie przekroczy jednak długości $(size +
1) / (blksize + 1)$ bitów, czyli 16 bajtów. Przechowuje ona informacje o
zajętości bloków zawartych w superbloku. Przydzielenie bloku polega na
ustawieniu odpowiedniego bitu w bitmapie, a zwolnienie odpowiednio zgaszenie
tego bitu. Warto zauważyć, że wyszukiwanie bloków w obrębie danego superbloku
nie wymaga przeczytania całej jego zawartości, a jedynie sprowadzenia linii
pamięci podręcznej pokrywającej nagłówek i bitmapę. Stanowi to podstawę
szybkości działania alokatora korzystającego z superbloków.

Warto wspomnieć, że faktyczny rozmiar superbloku jest równy $(size + 1) * 8$
bajtów, rozmiar przechowywanych bloków $(blksize + 1) * 8$ bajtów. Dodatkowo
jeśli fblkcnt ma wartość $127$ to superblok uznaje się za wolny niezależnie od
wielkości przechowywanych bloków. Powyższe ograniczenia wynikąją ze schematu
kodowania rekordu superbloku w możliwie najmniejszej przestrzeni pamięci.

Najważniejsze procedury operujące na superblokach to:
\begin{itemize}
\item \verb+sb_prepare+ -- inicjalizuje pola nagłówka oraz bitmapę
przygotowując superblok do dalszych działań,
\item \verb+sb_alloc+ -- sprawdza czy licznik wolnych bloków jest niezerowy i
jeśli tak do dekrementuje go; wyszukuje w bitmapie bitu oznaczającego wolny
blok, ustawia go, po czym na jego podstawie oblicza i zwraca adres bloku,
\item \verb+sb_free+ -- oblicza numer bitu w bitmapie na podstawie adresu
bloku; zeruje obliczony bit; inkrementuje licznik wolnych bloków,
\end{itemize}

Kolejną ważną jednostką zarządzania jest grupa superbloków, która składa się
zawsze z czterech superbloków zawartych na jednej stronie pamięci. Na następnym
rysunku grupy są otoczone grubą czarną ramką. O superblokach mówimy, że są
przyległe wtedy i tylko wtedy, gdy przylegają do siebie w obrębie jednej grupy.
Pełny superblok różni się od używanego tym, iż nie posiada żadnego wolnego bloku.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{eqsbmgr}
\caption{Graficzna reprezentacja obszaru zarządzanego przez manadżer superbloków}
\end{figure}

Manadżer superbloków wraz z rekordem \texttt{area\_t} przylega do końca
zarządzanego obszaru, zmniejszając rozmiar ostatniego superbloku, i posiada
następujące pola w swoim rekordzie\footnote{Pierwsze dwie pozycje widać na
rysunku, reszta została ukryta dla zachowania czytelności.}:
\begin{itemize}
\item \verb+nonempty[0..3]+ -- listy używanych superbloków, które przechowują
bloki o poszczególnych rozmiarach tj. $8$, $16$, $24$ i $32$ bajtów --- są
używane w trakcie alokacji bloków i służą do szybkiego wyszukiwania
odpowiedniego superbloku,
\item \verb+groups[0..3]+ -- listy przechowujące pierwszy superblok z grup
przylegających superbloków o odpowiedniej liczności --- są wykorzystywane gdy
brakuje niepełnych superbloków przechowujących bloki o zadanym rozmiarze,
\item \verb+full+ -- lista zajętych superbloków --- przydatna w trakcie
podziału menadżera superbloków na dwa mniejsze,
\item \verb+freecnt+ -- licznik wolnych superbloków,
\item \verb+allcnt+ -- licznik wszystkich superbloków.
\end{itemize}

Należy zwrócić uwagę na to, że w przypadku list superbloków zaimplementowane
wskaźniki nie są prawdziwymi adresami. Ze względu na oszczędność miejsca adresy
zostały zakodowane w 16--bitowych liczbach ze znakiem będących w rzeczywistości
relatywnymi indeksami. Dokładniej indeks $n$ znajdujący się w superbloku o
adresie $sb$ koduje adres o następującej wartości: $sb + n * 1024$. Narzuca to
ograniczenie na wielkość pojedyńczego obszaru zarządzanego przez manadżer
superbloków --- nie może on być większy niż $(2^{15} - 1) * 1024$ bajtów, czyli
dokładnie 8191 stron pamięci.

Następujący zestaw procedur umożliwia operowanie na manadżerze superbloków:
\begin{itemize}
\item \verb+sb_mgr_init+ -- przygotowuje nowy obszar umieszczając w nim rekord
manadżera superbloków i inicjując resztę miejsca wolnymi superblokami,
\item \verb+sb_mgr_alloc+ -- przegląda listy przyległych superbloków, od
znalezionej grupy odcina wolny superblok i przygotowuje go do użycia na
potrzeby przydziału bloków o zadanym rozmiarze, a dokładniej wywołuje procedurę
\verb+sb_prepare+,
\item \verb+sb_mgr_free+ -- oznacza dany superblok jako wolny i próbuje
dołączyć go do istniejących grup, jeśli mu się to uda powiększona grupa zostaje
przeniesiona na odpowiednią listę przyległych superbloków,
\item \verb+sb_mgr_expand+ -- jest wywoływana w przypadku powiększania
zarządzanego obszaru o dodatkowe strony, które zostają zainicjalizowane pustymi
superblokami i dodane do manadżera superbloków.
\end{itemize}

Wyżej wymienione mechanizmy są elementami wykorzystywanymi do zbudowania
alokatora \texttt{eqsbmgr}, którego rekord jest statyczny i jest przypisany
narzędnemu zarządcy \texttt{memmgr}. Przechowuje on listę zarządzanych
obszarów i implementuje następujące operacje:

\begin{itemize}
\item \verb+eqsbmgr_alloc+ -- wyszukuje obszar, w którym manadżer superbloków
posiada używany superblok przechowujący bloki odpowiedniego rozmiaru, jeśli
takiego nie znajdzie szuka pierwszego obszaru z wolnymi superblokami, w
ostateczności prosi manadżer \texttt{areamgr} o poszerzenie zarządzanych
obszarów lub przygotowanie nowego; po znalezieniu lub utworzeniu nowego
superbloku wywołuje procedurę \verb+sb_mgr_alloc+,
\item \verb+eqsbmgr_realloc+ -- wyszukuje manadżer superbloków, do którego
należy podany adres i sprawdza czy po zmianie wielkości, blok wymaga
przeniesienia w nowe miejsce,
\item \verb+eqsbmgr_free+ -- wyszukuje superblok, do którego należy
podany adres, wywołuje procedurę \verb+sb_free+, następnie sprawdza czy dany
superblok da się zwolnić i czy przypadkiem nie można zmniejszyć lub podzielić
obszaru zarządzanego przez manadżer superbloków na dwa mniejsze.
\end{itemize}

Procedura \verb+eqsbmgr_alloc+ niestety nie umożliwia alokacji bloków
wyrównanych do adresu podzielnego przez więcej niż 8. Implementacja tej funkcji
wymagałaby gruntownego przebudowania manadżera superbloków co wydaje się być
nieopłacalne.

\subsubsection{Możliwe optymalizacje}

Pewne fragmenty procedury \verb+eqsbmgr_free+ należałoby w wyniku
refaktoryzacji kodu wydzielić i umieścić w dodatkowych procedurach
\verb+sb_mgr_split+ i \verb+sb_mgr_shrink+.

Podobnie jak w \texttt{areamgr}, można by stworzyć dodatkowy manadżer dla
rekordów \verb+sb_mgr_t+. Dałoby to możliwość stworzenia blokad na poziomie
list, co w bieżącej implementacji jest niemożliwe. Wynika to ze zmian
położenia rekordu manadżera superbloków w trakcie działania alokatora.
Przenoszenie rekordu \verb+sb_mgr_t+ w obrębie obszaru wymaga blokady listy
utzymywanych obszarów, co kłóci się z wielowątkowością wewnątrz
\texttt{eqsbmgr}. Kolejnym problemem są tu własności blokad standardu
\texttt{POSIX}, które nie zachowują spójności w trakcie przenoszenia do innej
lokalizacji w pamięci. Podsumowując --- zabieg taki przyczyniłby się do
zmniejszenia ziarnistości blokad i w rezultacie zwiększenia skalowalności.

Ciekawą i jednocześnie efektywną metodą na zwiększenie skalowalności
\texttt{eqsbmgr} byłobo umożliwienie wielu wątkom równoległego korzystania z
superbloków.  Zadanie to można wykonać przy użyciu instrukcji procesora
\verb+CAS+ (ang. \textit{compare-and-swap} --- porównaj i zamień).  W trakcie
alokacji bloku możnaby wtedy atomowo dekrementować licznik wolnych bloków, a
następnie wyszukać i atomowo ustawić bit zajętości w bitmapie. Oczywiście nie
jest to wystarczające. Trzebaby również zadbać o wielowątkowość na poziomie
manadżera superbloków --- tworząc blokady do odpowiednich zasobów.

Być może warto byłoby uczynić długość superbloku nieco elastyczniejszą.
Dawałoby to możliwość lepszego przystosowania manadżera \texttt{eqsbmgr} do
zmian wynikających z architektury docelowego sprzętu.

Zmiana struktury danych przechowującej przyległe i używane superbloki z list na
\textit{Splay Tree} zwiększyłoby wydajność operacji podziału manadżera
superbloków. W chwili obecnej listy są nieposortowane, co wymaga liniowego
czasu na przejrzenie całej listy i podzielenia jej na dwie części względem
adresu superbloków. Identyczna operacja na \textit{Splay Tree} wykonuje się w
oczekiwanym czasie $O(log n)$.

Jeśli pozostać przy listach, należałoby przemyśleć strategie utrzymywania
używanych i wolnych superbloków. Nowe powinny powstawać w grupach z najmniejszą
licznością wolnych superbloków --- chcielibyśmy, żeby wykorzystanie pamięci w
obrębie stron było możliwie jak największe. Oprócz korzyści wynikających z
oszczędności zajmowanej przestrzeni, dodatkowo gwarantujemy mniejsze obciążenie
\textit{TLB cache}. Warto zauważyć, że nowe bloki powinno się przydzielać w
superblokach, do których niedawno się odwoływano --- niezależnie od tego czy
w ich obrębie zwalniano czy przydzielano bloki.

Można by również rozważyć dodanie niewielkiej pamięci podręcznej biorącą udział
w procesie odroczonego zwalniania bloków. Takie leniwe zachowanie mogłoby pomóc
algorytmom, które obliczają dużo tymczasowych wyników wymagających niewielkich
kawałków pamięci.

\subsection{Zarządca bloków średniego rozmiaru --- \texttt{BLKMGR}}

Manadżer bloków średniego obszaru jest alokatorem ogólnego przeznaczenia. Jego
implementacja bazuje w dużym stopniu na algorytmie \textit{boundary tags}
Knutha. Obszary zarządzane przez \texttt{blkmgr} przechowują bloki o
rozmiarach od 8 bajtów do 32 kilobajtów. Strategia przechowywania bloków na
liście to \textit{First Fit Address Ordered}.

Elementarną jednostką wykorzystywaną przez \texttt{blkmgr} jest blok. Każdy
rodzaj bloku posiada $8$--bajtowy nagłówek w postaci rekordu struktury
\texttt{mb\_t}. W rekordzie nagłówka przechowywany jest rozmiar bloku, flagi i
suma kontrolna. Każda zmiana pola struktury \verb+mb_t+ wymaga odświeżenia sumy
kontrolnej przy pomocy procedury \verb+mb_touch+. Przed każdą operacją na bloku
suma jest sprawdzana funkcją \verb+mb_valid+, która w razie błędu przerywa
działanie aplikacji. Mechanizm ten został wprowadzony celem ochrony przed
błędami wynikającymi z nadpisania nagłówka przez nieprawidłowe zachowanie
aplikacji.

W zależności od użycia przestrzeni pamięci za nagłówkiem można wyróżnić trzy
rodzaje bloków:
\begin{itemize}
\item \textit{zajęty} -- pozostała przestrzeń jest używana przez aplikację
korzystającą z alokatora; jest oznaczony ustawioną flagą \verb+MB_FLAG_USED+,
\item \textit{wolny} -- obszar za nagłówkiem ma co najmniej $8$--bajtów i
składowany jest tam rekord struktury służącej do wyszukiwania wolnych bloków
--- w bieżącej implementacji wolny blok jest zdefinowany strukturą
\verb+mb_free_t+; posiada wyzerowaną flagę \verb+MB_FLAG_USED+,
\item \textit{sztuczny} -- blok jest wolny, ale zbyt krótki by mógł
przechowywać strukturę przechowującą wolne bloki; przy najbliższej okazji
zostanie wchłonięty przez przyległe bloki; ma ustawioną flagę
\verb+MB_FLAG_PAD+.
\end{itemize}


\begin{figure}[ht]
\centering
\includegraphics[width=0.90\textwidth]{blkmgr}
\caption{Graficzna reprezentacja obszaru zarządzanego przez \texttt{blkmgr}}
\end{figure}

Rozszerzony nagłówek dla wolnego bloku dodatkowo przechowuje dwa adresy, które
wskazują kolejno na element poprzedni i następny w liście wolnych bloków
posortowanych względem adresu.

Do początku zarządzanego obszaru przylega rekord \verb+mb_list_t+. Przechowuje
on wartownik listy wolnych bloków oraz pola zliczające liczbę używanych i
wolnych bloków, oraz liczbę bajtów wolnej pamięci. W samym obszarze musi być
dokładnie jeden pierwszy i ostatni blok -- są one oznaczone odpowiednią flagą
\verb+MB_FLAG_FIRST+ i \verb+MB_FLAG_LAST+.

Poniższy zestaw procedur służy do operowania na pojedyńczych blokach wewnątrz
listy i jest podstawą całego alokatora, a w szczególności funkcji
przydzielających i zwalniąjących kawałki pamięci.
\begin{itemize}
\item \verb+mb_insert+ -- wstawia dany blok na listę posortowaną względem
wartości adresów,
\item \verb+mb_pullout+ -- wyjmuje dany blok z listy,
\item \verb+mb_split+ -- dzieli podany blok na dwa mniejsze i w zależności od
żądania zwraca pierwszy lub drugi z nch; szczególnym przypadkiem jest blok
oznaczony specjalną flagą \verb+MB_FLAG_FIRST+ lub \verb+MB_FLAG_LAST+, wtedy
procedura odpowiednio zmienia flagi w wynikowych blokach,
\item \verb+mb_coalesce+ -- iteracyjnie sprawdza czy przylegające bloki są
wolne lub są blokami sztucznymi, a następnie wchłania je tworząc jeden większy
blok; jeśli wchłonięty blok jest oznaczony specjalnymi flagami wtedy dołącza je
do własnych flag.
\end{itemize}

Poniższe operacje służą do implementacji procedur alokacji i zwalniania bloków
w ramach pojedyńczego obszaru:
\begin{itemize}
\item \verb+mb_alloc+ -- znajduje na liście blok większy lub równy pożądanemu
rozmiarowi; jeśli znaleziony blok jest zbyt duży wtedy zostaje podzielony przy
pomocy \verb+mb_split+; gotowy blok zostaje oznaczony jako zajęty,
\item \verb+mb_alloc_aligned+ -- wyszukiwane są bloki zawierające adresy
podzielne przez podaną liczbę \textit{alignment} i dodatkowo posiadające
wystarczająco dużo miejsca poczynając od wyrównanego adresu; jeśli odpowiedni
blok zostanie znaleziony, wtedy dzieli się go przy pomocy \verb+mb_split+ by
jeden z nowoutworzonych bloków miał początek równo w adresie podzielnym przez
\textit{alignment} minus rozmiar \verb+mb_t+; reszta procedury jest analogiczna
do działania \verb+mb_alloc+ po znalezieniu bloku,
\item \verb+mb_resize+ -- składa się z dwóch przypadków; w pierwszym nowy
rozmiar bloku jest zmniejszany --- wywołuje się \verb+mb_split+ celem odcięcia
nieużywanej części bloku, po czym nieużytek wstawia się na listę wolnych
bloków; drugi przypadek polega na zwiększaniu rozmiaru bloku --- jeśli za
podanym blokiem istnieje wolna przestrzeń o wystarczającej długości to odcina
się jej początek i włącza do powiększanego bloku, w przeciwnym wypadku
procedura zwraca informację o porażce,
\item \verb+mb_free+ -- dany blok jest oznaczany jako wolny i wstawiany na
listę przy pomocy procedury \verb+mb_insert+.
\end{itemize}

Niżej opisane procedury są funkcjami pomocniczymi przy zmianie rozmiaru,
podziale i scalaniu obszarów, w których umieszczono listy bloków:
\begin{itemize}
\item \verb+mb_list_can_shrink_at_begining+ -- na podstawie informacji o
pierwszym bloku zwraca ilość stron, które można odciąć od początku listy;
procedura może zwrócić niezerową wartość tylko, jeśli pierwszy blok jest wolny;
liczba odłączonych stron z obszaru nie może być większa niż rozmiar pierwszego
bloku,
\item \verb+mb_list_can_shrink_at_end+ -- analogicznie jak poprzednia
procedura, ale dotyczy ostatniego blok z danej listy,
\item \verb+mb_list_shrink_at_begining+ -- po uprzednim sprawdzeniu czy
operacja jest możliwa, na pierwszym bloku w obszarze wywołuje się procedurę
\verb+mb_split+ --- nowo utworzony drugi blok musi zaczynać się w adresie
podzielnym przez rozmiar strony plus wielkość \verb+mb_list_t+; następnie pola
listy wolnych bloków przenosi się w nowe miejsce i uaktualnia statystyki, po
czym odświeża się odpowiednie wskaźniki;
\item \verb+mb_list_shrink_at_end+ -- funkcja ta jest symetryczna w stosunku do
poprzedniej, oczywiście z wyjątkiem przenoszenia rekordu listy;
\item \verb+mb_list_find_split+ -- wyszukuje na liście pierwszy blok o adresie
podzielnym przez wielkość strony; podążającą ten adres wolna przestrzeń musi
mieć długość co najmniej jednej strony pamięci; jeśli na liście istnieje blok
spełniający takie warunki, to procedura zwraca obliczony adres i liczbę wolnych
stron pamięci, które za nim występują,
\item \verb+mb_list_split+ -- dokonuje podziału listy bloków na dwie mniejsze i
tym samym przygotowuje obszar do podziału; punktem przecięcia listy jest podany
adres podzielny przez długość strony --- ostatni blok przed tym adresem staje
się ostatnim blokiem pierwszej listy, pierwszy za nim staje się pierwszym
blokiem nowej listy; dodatkowo druga lista zostanie skrócona o liczbę podanych
stron pamięci,
\item \verb+mb_recalculate_statistics+ -- powtórnie oblicza pola listy:
\verb+blkcnt+, \verb+ublkcnt+ i \verb+fmemcnt+; musi zostać wywołana
na listach powstałych w wyniku działania funkcji \verb+mb_list_split+,
\item \verb+mb_list_merge+ -- łączy listy bloków z dwóch przyległych obszarów w
jedną większą listę; początek listy o starszym adresie zostaje dołączony do
końca pierwszej listy, a statystyki odpowiednio zescalone;
\end{itemize}

\subsubsection{Możliwe optymalizacje}

Manadżer \texttt{blkmgr} daje największe pole do popisu jeśli chodzi o
optymalizacje. Idea alokatora typu \textit{boundary tags} znacznie wyewoluowała
od pierwszego momentu opisania. Właściwie żaden liczący się ogólny manadżer
pamięci nie posiada tak prostej implementacji. Naturalną ścieżką rozwoju
\texttt{blkmgr} jest próba dogonienia osiągnięć manadżerów takich jak
\textit{Doug Lua's malloc}. Przy czym implementacja ta powinna za wszelką cenę
utrzymać uniwersalność i czytelność, tak by nie zamykać drogi do tego by w
pewnym momencie rozwój mógł się swobodnie odłączyć od pierwowzorów. Poniżej
zostanie wymienionych kilka optymalizacji, które zdaniem autora są kluczem do
poprawienia wydajności i stawienia podwalin pod dalszy rozwój.

Jednym z najprostszych pomysłów, który zmniejszyłby czas wykonania niektórych
operacji, byłoby umieszczenie w rekordzie \verb+mb_t+ długości poprzedniego
bloku. W szczególności mogłoby to skrócić czas poszukiwania ostatniego bloku
jeśli ten jest zajęty, bądź generalnie poszukiwania poprzedniego bloku
poczynając od zajętego.

Rozszerzeniem algorytmu \textit{boundary tags} często występującym pośród
współczesnych alokatorów są osobne kubełki do przechowywania wolnych bloków z
danych przedziałów wielkości. Dodatkowo kubełki takie mogłyby zamiast struktury
listy wykorzystywać zbalansowane drzewa binarne --- być może \textit{Splay
Tree} ze względu na dobre właściwości dotyczące lokalności referencji.
Oczywiście w takim przypadku należałoby zmienić porządek w strukturach
przetrzymujących wolne bloki --- z uporządkowania względem adresów na
uporządkowanie po wielkościach bloków.

Kolejnym pomysłem zaczerpiętym z bardziej dojrzałych projektów są listy
odroczonego scalania. 

\newpage

\subsection{Zarządca dużych bloków --- \texttt{MMAPMGR}}

Na podstawie obserwacji wiemy, że fragmenty pamięci o dużych rozmiarach
aplikacje często wykorzystują przez długi okres czasu. Dodatkowo takich
obiektów będzie stosunkowo niewiele w porównaniu z liczbą bloków o małym
rozmiarze. Gdyby w takim przypadku potraktować obszary typu \verb+area_t+ jako
bloki, narzut procentowy związany z generowanymi nieużytkami w wyniku
fragmentacji wewnętrznej można uznać za zaniedbywalnie mały. W przypadku bloków
o rozmiarach kilkuset kilkobajtów przestrzeń rzędu wielkości strony pamięci
jest stosunkowo mała. Stąd wniosek, że duże bloki, które z reguły wymagają
przestrzeni o rozmiarze co najmniej kilkudziesięciu stron pamięci, korzystnie
jest zarządzać nie absorbując zbędnej ilości środków, takich które widzieliśmy
w poprzednich alokatorach. Dlatego też \verb+mmapmgr+ jest najprostszym
alokatorem, wykorzystującym bezpośrednio obszary do przechowywania pojedyńczych
bloków.

Jest jeszcze jedna korzyść wynikająca z zarządzania dużych bloków niezależnie
od małych. Jeśli przypisujemy jakiemuś blokowi obszar możemy zarządać od
systemu operacyjnego stron innego rozmiaru niż standardowy --- np. architektura
\verb+x86+ udostępnia strony pamięci rozmiaru $2$ \verb+MiB+. Gdyby użyć takich
stron do zbudowania obszaru, zmniejszyło by się obciążenie \textit{TLB cache},
przyczyniając się do poprawy wydajności aplikacji.

Czasem zdarza się, że program żąda bloku pamięci o adresie podzielnym przez
określoną potegę dwójki przy pomocy funkcji \verb+memalign+. Implementacja tej
procedury przy pomocy zarządcy \texttt{mmapmgr} jest bardzo efektywna.
Wszystkie nowo zarezerwowane obszary mają początek w adresie podzielnym przez
rozmiar wielokrotności strony --- więc część funkcjonalności wywołania
\verb+memalign+ dostajemy za darmo. Resztę można osiągnąć rezerwując
odpowiednio większą ilość stron i odmapowując od początku obszaru te strony,
których początki nie dzielą się przez zadaną liczbę.

Jeśli obszarami o rozmiarze $<$ $32$ \verb+KiB+ zajmuje się osobny zarządca, to
wielkość pól będzie mógł składować w danej typu \verb+int16_t+. Zyskujemy więc
również na efektywności wykorzystania pamięci.

\begin{figure}[ht]
\centering
\includegraphics[width=0.75\textwidth]{mmapmgr}
\caption{Graficzna reprezentacja struktury danych \texttt{mmapmgr}.}
\end{figure}

Struktura danych dla zarządcy jest zwykłą listą dwukierunkową przechowującą w
każdym rekordzie dodatkowe dane --- między innymi adres początku okupowanego
obszaru. Lista ta jest posortowana pod względem rosnących adresów.

Nagłówek (czy raczej stopka) obszaru zawiera następujące informacje:
\begin{center}
\begin{tabular}{|m{0.15\linewidth}|p{0.75\linewidth}|}
\hline
\textsc{pole} & \textsc{znaczenie} \\
\hline
\hline
\verb+pages+ & Ilość stron zajmowanych przez obszar. \\
\hline
\verb+size+	 & Ilość bajtów zajmowanych przez blok wewnątrz obszaru. \\
\hline
\verb+prev+	 & Poprzedni nagłówek na liście zarządcy \texttt{mmapmgr}. \\
\hline
\verb+next+	 & Następny nagłówek na liście zarządcy \texttt{mmapmgr}. \\
\hline
\end{tabular}
\end{center}

\subsubsection{Opis operacji}

Rezerwacja bloku (\verb+alloc+) o rozmiarze $Size$ polega na pobraniu obszaru od
menedżera stron, zainicjalizowaniu nagłówka i wstawieniu go na listę. Rozmiar
rezerwowanego obszaru jest wyrównywany do wielkości podzielnej przez długość
strony pamięci. Trzeba zadbać też o to, by na końcu obszaru znalazło się
wystarczająco dużo przestrzeni by przechować nagłówek. Łączna ilość pamięci
zajmowanej przez ten obszar to:
$\left\lceil\frac{Size + HeaderSize}{PageSize}\right\rceil$ stron.

Rezerwacja bloku o początku w adresie podzielnym przez potęgę dwójki
(\verb+alloc_aligned+) nie różni się od \verb+alloc+ dla granicy wyrównania
mniejszej, bądź równej wielkości strony. Dla większej wartości pobiera się 
$\left\lceil\frac{Size + Alignment + HeaderSize}{PageSize}\right\rceil$
stron, gdyż nie mamy wpływu na to w jakim dokładnie adresie zostanie zaczepiony
nowy obszar. Wyżej podana ilość gwarantuje, że wewnątrz obszaru znajdziemy
odpowiednią ilość miejsca pod adresem podzielnym przez granicę wyrównania.
Następnie należy zwolnić niepotrzebne strony z początku oraz z końca obszaru,
zinicjalizować nagłówek i wstawić obszar na listę.

Operacja \verb+realloc+ może powiększyć zarezerwowany obszar o nieużytek
występujący między końcem bloku, a początkiem nagłówka. Jeśli menedżer stron
umożliwia określanie początku adresu pobieranego obszaru, to można
zaimplementować procedurę \verb+expand_at_end+. Próbuje ona znaleźć określoną
ilość wolnych stron zaczynających się bezpośrednio za naszym obszarem. Jeśli
tak, to nowe strony są doczepiane do obszaru, zawartość nagłówka jest
aktualizowana i przenoszona w nowe miejsce. Należy zaktualizować wskaźniki w
sąsiadach nagłówka by odzwierciedlały jego nową pozycję. Kiedy \verb+realloc+
pomniejsza dany blok, sprawdzane jest czy w obszarze jest nieużytek o rozmiarze
co najmniej jednej strony. Jeśli tak, to wykorzystuje się procedurę
\verb+shrink_at_end+. Przenosi ona nagłówek na koniec pierwszej strony,
należącej do nieużytku, która jest go w stanie pomieścić. Następnie aktualizuje
dane w nagłówku, zwalnia zbędne strony i aktualizuje wskaźniki w sąsiadach
nagłówka.

\subsubsection{Możliwe optymalizacje}

Zdaje się, że jedyna możliwa ścieżka zwiększenia wydajności to zastąpienie
listy nagłówków przy pomocy zbalansowanego drzewa. Ze względu na to, że ilość
dużych bloków jest stosunkowo niewielka, taka optymalizacja jest nieopłacalna
pod względem złożoności czasowej. Natomiast ciekawe jest to, że w przypadku
operacji \verb+alloc+ zmniejszy się ilość dostępów do pamięci do logarytmicznej
wielkości, w mniejszym stopniu obciążając pamięć podręczną.

\newpage

\subsection{Manadżer pamięci}

Oczywiście, nie można w nieskończoność kumulować nieużyków --- musi istnieć
jakieś zdarzenie generujące ich oddawanie do systemu. Takim wyzwalaczem może
być przekroczenie pewnej sumarycznej objętości nieużywanych stron np.: $2$
\verb+MiB+, albo próba rezerwacji dużego spójnego obszaru pamięci np.: powyżej
$64$ stron. Warto nadmienić, że zarządzanie stronami w systemie operacyjnym ma
istotną przewagę nad analogicznym zadaniem w przestrzeni użytkownika. W
szczególności, jądro systemu może z wielu nieprzylegających do siebie stron
utworzyć jeden spójny obszar --- o ile proces ma wystarczająco
niepofragmentowaną przestrzeń adresową.

By zmniejszyć rywalizację o dostęp do struktury zasobu można zastosować
dwupoziomowość --- rozbić listę nieużytków na jedną globalną i wiele lokalnych na
potrzeby allokatorów niższego rzędu.  Oba rodzaje list mają różne kryteria
odśmiecania. Lista globalna może je zmieniać w zależności od ilości
działających wątków. Kiedy jeden z wątków będzie wymagał przydzielenia nowej
strony najpierw odpytuje się wyznaczonej listy lokalnej, potem globalnej

Można się spodziewać, że w większości przypadków wątek budujący jakieś
dynamiczne struktury danych będzie sam na nich operował, co najwyżej
prezentując wyniki innym wątkom. Innymi słowy większość operacji \verb+free+
wątek będzie wykonywał na blokach, które sam zarezerwował. Oczywiście nie może
być to założeniem, ale praktyka pokazuje, że zachowanie sprzeczne z opisanym
wyżej przyczynia się do wielu błędów i programiści pisząc programy unikają
takich zachowań.

Kiedy wątek kończy swoje działanie powinien zadbać o to, by pamięć, którą
zarządza korzystając z prywatnych struktur, oddać na użytek globalnej listy
nieużytków lub menedżera osieroconych bloków --- takich, które nie posiadają
właściciela.

Istotnym zagadnieniem jest też dobór progów odśmiecania list nieużytków.
Należałoby przeprowadzić empiryczne badania programów i spróbować wyłowić
często spotykane wzorce zachowań mogące pomóc w oszacowaniu wartości.

\newpage

% --=[ Wnioski ]=---------------------------------------------------------------

\section{Podsumowanie i kierunek dalszych badań}
\hypertarget{Podsumowanie}{}

Śmieci i inne pomysły, o których lepiej nie zapomnieć, a trzeba gdzieś umieścić.

\newpage

% --=[ Bibliografia ]=----------------------------------------------------------

\nocite{berger00hoard}
\nocite{berger01composing}
\nocite{berger02reconsidering}
\nocite{bonwick94slab}
\nocite{chilimbi00designing}
\nocite{demaine99fast}
\nocite{douglea96malloc}
\nocite{evans06scalable}
\nocite{feng05localityimproving}
\nocite{fitzgibbons00linux}
\nocite{ghemawat07tcmalloc}
\nocite{gorman04linuxvm}
\nocite{iyengar96scalability}
\nocite{johnstone98memory}
\nocite{luby94tight}
\nocite{pas02memory}
\nocite{paul95dynamic}
\nocite{robson71estimate}
\nocite{robson74bounds}
\nocite{robson77worst}
\nocite{stephenson83fastfits}
\nocite{vuillemin80unifying}
\nocite{weinstock88quickfit}

\bibliographystyle{alpha}
\bibliography{mgr}

\end{document}
